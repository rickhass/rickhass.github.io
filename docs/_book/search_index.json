[["index.html", "Generalized Linear Mixed Models with R: A tutorial Overview", " Generalized Linear Mixed Models with R: A tutorial Rick Hass Overview Welcome to a series of tutorials originally made for an advanced regression and generalized linear modeling course, but now I’m attempting on making it more sharable. The content of this set of tutorials borrows from other excellent resources, most notably Julian Faraway’s excellent book Extending the Generalized Linear Model with R Brandon George’s wonderful approach to pedagogy and teaching John Fox’s An R Companion to Applied Regression Please give me a shout via email if you spot any errors or inconsistencies. This is a living document and it is made to help you! "],["r-basics.html", "1 R Basics 1.1 What is “coding” 1.2 R Console versus the RStudio Script 1.3 Working with data 1.4 Using a script to generate data, and computing the mean and standard deviation 1.5 Importing Data 1.6 Reading in an SPSS file 1.7 Frequencies and Contingency Tables 1.8 Descriptive statistics 1.9 Visualizing Data 1.10 Review", " 1 R Basics This Chapter is designed to help you with a few things, not limited to: Overcome any fear about learning to code Learn about data structures in R Type data into R (not fun!) Import data to R from Excel and SPSS (fun) Manipulate data in R Reference different variables and subsets Add and delete columns in a data frame View the spreadsheet Using the psych package for descriptive statistics Using the car package for exploratory visualization 1.1 What is “coding” Computer programming, or coding is the use of a specific language to execute commands on a computer. The commands are usually called functions, though there’s more to it than that. A function is simply a mapping between some input and some output. It specifies a procedure for turning input into output. For example, the sample mean is a function. The details are what the equation \\(\\frac{1}{N}\\Sigma X\\) says to do. This function has “arguments”, details to be passed to it and used. In this example, the arguments are N (the sample size) and the sum of the scores. At it’s essence, R is a procedural language, meaning that programming in R is very literal, and involves writing out calls to various functions in order to obtain the output that you’d like to have. It also has “object-oriented” properties in the background. We don’t need to know about those, but they’re great since they make R very flexible as an open source tool. Open source means that anyone in the world can add functions or procedures to R by writing new code in R. 1.2 R Console versus the RStudio Script In R, we have a choice of typing in commands at the console, which is just the command prompt or writing out many commands and statements in a file and running or executing some or all of them when we need them. The latter is basically the same as writing syntax in SPSS. Like syntax, R scripts can be written, saved, re-used, etc. In both cases, the idea is to be able to reconstruct your analysis exactly each time you re-do it. This saves time and energy, but also makes the analysis “reproducible” such that other scientists can check your work if they desire. We will use the RStudio Script window to write and save our code. But let’s start with the console. Type the following statements one by one in the console and see the output. You can actually copy each line one at a time and paste it in your console. Press ENTER to have the console return results. Note that any line that starts with # is not read by R. This is called a comment, or “commenting out” a line. These are handy in script files as they explain what is there to a person who doesn’t know what you were hoping to do (which is sometimes you!). It is good practice to include comments to describe what the code underneath does. # addition 100 + 100 # subtraction 100 - 100 # multiplication 100 * 100 # division 100 / 100 # Squaring 100^2 # Raising to any power 100^(1.23) # Using &quot;e&quot; (Euler&#39;s Number) exp(-1.2) 1.3 Working with data So at this point we can see that R is a calculator. More elaborate computations can be performed using parentheses and built-in functions. Let’s try it, but now I want you to open up a new Script file. You can do that by clicking File &gt; New File &gt; R Script (or by various other short-cut methods). The basic unit of data in R is a vector. Think of it like a row or column of data in Excel. Data objects aren’t very useful if we don’t save them to R’s Global Environment (this means the active datasets in R’s memory at any time). We “assign” data to an object in R using the assignment operator &lt;- . To type it you type the less than sign &lt; then the short dash -. We put data in a vector by using the c() syntax. c is short for concatenate, a fancy word meaning string a bunch of stuff together. When you assign data to an object (x below). It won’t print to the console. To see what’s in that object you can simply type it’s name at the console, or select the line in your script and click “Run.” x &lt;- c(1, 2, 3, 4) # assignment x # print ## [1] 1 2 3 4 1.4 Using a script to generate data, and computing the mean and standard deviation Let’s say you’ve got 10 scores from different patients rating the quality of their care on a 5-item scale. The data are averages across the 5 items. A score of 5 means the patient was very satisfied. Type in the following lines in your script window; you can omit the comments. When you are finished, click the button in your script window that says “Source.” This button sends all of your script to the console and runs it all. If instead you want to run one line at a time, highlight it with your cursor, or simply put your cursor at the beginning of the line and click the “Run” button. You can do this for the rest of the tutorial (that is, run each new line by itself rather than hitting source over and over again). # make a small dataset mydata &lt;- c(3.0, 2.0, 5.0, 2.5, 3.5, 4.5, 2.0, 3.80, 1.0, 4.0) # compute the mean using the sum of the scores divided by how many there are (the length of the vector holding them) mymean &lt;- sum(mydata) / length(mydata) # compute sum of squares using similar commands note the parentheses! mySS &lt;- sum(mydata^2) - ((sum(mydata)^2) / length(mydata)) # compute the sample standard deviation by taking the square root of the sample variance mysd &lt;- sqrt(mySS / (length(mydata)- 1)) Ok, you may be wondering where the output is. Look at the Environment tab in your RStudio pane. You’ll see a list of Values and the names you gave them along with the results. If you did it correctly you should have: ## [1] 3.0 2.0 5.0 2.5 3.5 4.5 2.0 3.8 1.0 4.0 ## [1] 3.13 ## [1] 14.221 ## [1] 1.257025 Let’s compare our results with R’s built in functions mean(mydata) ## [1] 3.13 sd(mydata) ## [1] 1.257025 Aha! We did it. As you can see, many things that you might be tempted to hard code are already functions or commands in R (those words are essentially interchangeable in R). We’ll see that this is true for many descriptive statistics in the next section. But first we need to start working with real data, and importing it into R. 1.5 Importing Data The types of files that are likely to contain data you already have are .sav files (SPSS) and either .csv or .xlsx files. I’m grouping the latter 2 together although they’re actually quite different. To make things easier, I’m going to show you how to import .csv files only and also SPSS files. SAS files and Stata files can also be imported into R, which is good if you’re working with government survey data. The best way to make sure the data file you’re importing is accessible is to make a folder on your computer, store the file in that folder, and then change the working directory to that folder You can change your working directory manually using the Files nagivator pane in RStudio. Simply click on the file folders until you find the one with your file. Then, click the gear icon that says “More.” From that drop-down menu, click “Set as working directory.” Figure 1.1: Set as working directory. Click the Gear icon to open this menu. 1.6 Reading in an SPSS file First, you’ll need to download the nurses.sav file from Canvas. Save it to your Downloads folder if it doesn’t automatically go there. Then set that folder as your working directory (alternatively, you can choose whatever folder you want). Here’s where it get’s a little tricky. To import SPSS data, we will use the “read.spss” command. That command asks you to give the full path to the file. On windows and PC it’s a bit different. I have a Mac so the following works for me. Before we run it, we have to load the add-on package that contains the command. It is called foreign. The following code loads the package (library(foreign)), then runs the command by specifying the path to the file in quotes. This assumes that you have already set the working directory to the folder that contains nurses.sav. Ignore any warnings about the package being built under any specific R build. library(foreign) nurses &lt;- read.spss(&quot;nurses.sav&quot;, to.data.frame = TRUE) Importantly, there is an option (called an argument) that says to.data.frame = TRUE. This needs to be in any read.spss call because the default reads the data into a format that won’t work for us. You can verify that your data was imported by looking at the Global Environment pane and clicking on the name of the dataset. It should pop up as a tab in RStudio and if you click on the tab you’ll see something that is very much like a spreadsheet. Also, you should see a blue circle with a little arrow back over by your dataset. It’s a quick way to view the columns in your data. Notice we have a NA at various places. This is R’s native missing data symbol and can be handled by various commands in various ways. One more thing, let’s get some more details about our data before we analyze it. Try this # get the &quot;structure&quot; of our data str(nurses) ## &#39;data.frame&#39;: 1000 obs. of 20 variables: ## $ hospital : num 1 1 1 1 1 1 1 1 1 1 ... ## $ ward : num 1 1 1 1 1 1 1 1 1 2 ... ## $ wardid : num 11 11 11 11 11 11 11 11 11 12 ... ## $ nurse : num 1 2 3 4 5 6 7 8 9 10 ... ## $ age : num 36 45 32 57 46 60 23 32 60 45 ... ## $ gender : Factor w/ 2 levels &quot;male&quot;,&quot;female&quot;: 1 1 1 2 2 2 2 2 1 1 ... ## $ experien : num 11 20 7 25 22 22 13 13 17 21 ... ## $ stress : num 7 7 7 6 6 6 6 7 7 6 ... ## $ wardtype : Factor w/ 2 levels &quot;general care&quot;,..: 1 1 1 1 1 1 1 1 1 2 ... ## $ hospsize : Factor w/ 3 levels &quot;small&quot;,&quot;medium&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ expcon : Factor w/ 2 levels &quot;control&quot;,&quot;experiment&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Zage : num -0.582 0.166 -0.914 1.162 0.249 ... ## $ Zgender : num -1.66 -1.66 -1.66 0.6 0.6 ... ## $ Zexperien: num -1.002 0.487 -1.664 1.315 0.818 ... ## $ Zstress : num 2.07 2.07 2.07 1.04 1.04 ... ## $ Zwardtype: num -1 -1 -1 -1 -1 ... ## $ Zhospsize: num 1.78 1.78 1.78 1.78 1.78 ... ## $ Zexpcon : num 0.992 0.992 0.992 0.992 0.992 ... ## $ Cexpcon : num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... ## $ Chospsize: num 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;variable.labels&quot;)= Named chr [1:20] &quot;id&quot; &quot;id&quot; &quot;unique ward id&quot; &quot;id&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;hospital&quot; &quot;ward&quot; &quot;wardid&quot; &quot;nurse&quot; ... ## - attr(*, &quot;codepage&quot;)= int 65001 What you’ve done here is basically print to the screen what you get with the toggle circle button. This is very helpful if you have factors labels (as with gender) which you will see are included with SPSS imports. The nurses data set has a special type called data frame. This is basically R’s version of a spreadsheet. It has different columns for variables, and different rows for cases. Each column is of a specific type: num for numeric, char for character (text), Factor for coded variables, int for integer, and logi for logical (True / False). 1.6.1 A quick note on indexing Another tricky part of R is that you have to tell R what column of a data frame you want to work with by referencing both the data name and the column. There are several ways to do this: # using the $ selector nurses$age # using matrix indexing nurses[ , 5] # using the column name and matrix indexing nurses[, &quot;age&quot;] 1.6.1.1 Selection operator The $ “selects” the age variable from nurses, and the result is a vector (the column of ages) 1.6.1.2 Matrix indexing Matrix indexing is really handy, but also tricky. It is common to all computer code. A single cell of a matrix or rectangular data array is accessed using it’s row number and column number in square brackets separated by a comma. For example, this will give me the age of the nurse in the 6th row. Six specifies the row, while 5 is there singe age is the 5th column in the dataset # the age of the nurse in the 6th row nurses[6,5] ## [1] 60 Usually however, we want a whole row or column. We do that simply by leaving either the row or column entry blank like so: # 5th column of the data nurses[ , 5] ## [1] 36 45 32 57 46 60 23 32 60 45 57 47 32 42 42 53 60 33 64 37 23 61 58 52 28 52 43 64 47 62 39 46 ## [33] 58 34 41 56 39 60 57 50 29 57 51 25 27 53 42 43 24 48 60 27 61 33 47 50 38 28 33 52 53 31 27 57 ## [65] 47 41 64 45 42 25 34 36 55 33 51 60 24 31 58 60 29 24 24 46 43 24 45 64 25 55 42 58 64 47 25 50 ## [97] 42 60 33 51 27 43 45 53 53 37 25 32 46 57 27 55 51 24 56 31 46 57 42 53 48 25 37 47 29 41 31 52 ## [129] 36 39 62 42 51 29 25 50 23 60 43 43 27 28 36 60 64 64 61 27 32 28 64 55 46 45 23 55 60 39 24 61 ## [161] 28 34 34 25 39 64 60 58 58 32 41 61 47 60 56 47 31 47 51 61 50 37 23 56 45 23 48 46 64 47 56 51 ## [193] 28 61 41 37 25 25 50 64 38 39 43 28 33 39 46 25 52 45 52 33 25 36 50 57 43 53 62 60 62 33 33 27 ## [225] 61 23 38 64 64 57 25 56 43 45 23 46 37 31 29 37 61 43 39 29 52 58 34 57 37 56 32 29 29 32 25 36 ## [257] 45 58 52 42 31 37 47 31 38 58 31 41 62 62 24 28 58 56 50 51 24 28 43 45 61 45 41 31 32 24 57 41 ## [289] 58 56 51 45 32 55 53 41 47 41 28 62 34 41 31 57 60 29 46 27 50 45 34 45 39 43 28 55 32 38 36 29 ## [321] 48 31 37 58 31 46 60 46 57 50 64 24 37 36 58 64 34 47 43 39 43 27 27 55 61 37 36 32 47 27 42 55 ## [353] 45 23 58 60 58 33 50 47 23 53 27 53 37 53 52 39 48 64 42 31 34 41 47 48 29 51 48 61 23 61 50 39 ## [385] 37 47 24 47 23 36 41 55 56 37 39 24 56 60 42 29 39 61 37 24 31 36 47 64 47 31 55 34 29 42 42 56 ## [417] 57 29 33 39 62 60 56 47 34 39 50 38 50 25 34 39 42 42 39 56 56 31 58 43 58 37 25 57 52 36 24 42 ## [449] 60 56 55 31 32 42 32 32 57 61 41 46 51 31 56 42 45 39 46 36 42 41 37 52 42 57 62 32 56 48 33 34 ## [481] 61 24 31 46 27 42 62 57 31 34 57 53 47 34 47 31 25 57 47 61 27 53 34 64 34 55 43 29 45 27 47 58 ## [513] 45 64 55 32 29 29 48 45 43 23 60 39 45 36 45 36 42 37 41 64 58 62 32 33 25 60 38 48 45 56 46 45 ## [545] 37 57 62 24 61 51 33 60 36 52 56 46 50 32 45 28 51 38 55 45 32 43 24 47 47 45 52 45 62 48 50 46 ## [577] 61 58 51 33 24 60 43 57 33 62 61 47 60 27 24 31 55 53 23 25 27 45 52 25 37 50 41 28 50 52 23 28 ## [609] 24 37 56 58 36 58 41 51 34 58 37 25 45 58 28 43 38 38 37 61 64 47 39 45 34 34 52 33 50 45 31 53 ## [641] 28 50 58 39 42 28 43 64 47 29 56 23 28 43 60 62 34 36 51 53 58 57 23 23 36 39 33 45 50 34 64 31 ## [673] 61 48 34 58 42 51 28 64 58 37 43 33 62 39 55 43 61 52 45 57 32 32 34 32 56 57 61 23 24 42 24 57 ## [705] 27 51 58 29 42 43 32 51 47 62 61 47 37 23 27 55 25 43 52 25 50 50 58 34 43 46 42 51 46 25 29 48 ## [737] 53 29 51 62 29 46 48 37 25 38 24 27 45 41 38 57 45 57 25 43 45 38 46 46 41 45 37 53 39 51 32 25 ## [769] 23 41 55 24 55 50 62 46 48 53 56 46 56 29 36 31 53 52 47 56 25 56 61 64 41 56 37 36 41 25 62 27 ## [801] 29 36 58 46 37 32 64 52 31 52 47 39 45 53 51 50 34 48 32 38 34 62 31 50 47 27 61 48 64 28 36 51 ## [833] 55 31 28 33 38 45 28 38 46 57 42 31 37 57 42 42 60 33 48 24 37 37 28 34 33 50 31 29 61 58 48 25 ## [865] 34 27 23 58 48 50 45 51 53 25 50 29 64 36 56 34 61 34 58 60 39 24 34 48 28 34 42 46 38 31 24 56 ## [897] 23 50 27 60 23 25 24 37 56 42 39 29 64 50 36 46 56 31 56 64 47 32 41 41 34 37 48 62 38 24 25 36 ## [929] 23 24 60 41 28 58 24 34 33 55 43 57 31 23 37 55 58 55 47 47 28 33 32 52 34 56 42 29 28 55 37 47 ## [961] 48 31 25 47 51 34 62 39 46 38 36 25 42 36 32 42 36 51 52 31 25 41 29 23 23 38 28 62 45 60 34 41 ## [993] 27 39 33 56 29 32 34 58 # 6th row of the data nurses[6, ] ## hospital ward wardid nurse age gender experien stress wardtype hospsize expcon Zage ## 6 1 1 11 6 60 female 22 6 general care large experiment 1.411358 ## Zgender Zexperien Zstress Zwardtype Zhospsize Zexpcon Cexpcon Chospsize ## 6 0.600153 0.8180786 1.044405 -1.001501 1.777279 0.9915356 0.5 1 If we want multiple rows or columns, we give a range or use a vector to name the columns: (note, I’m using the head command so that only 6 rows appear on the screen) head(nurses[, 5:7]) ## age gender experien ## 1 36 male 11 ## 2 45 male 20 ## 3 32 male 7 ## 4 57 female 25 ## 5 46 female 22 ## 6 60 female 22 head(nurses[, c(5,8)]) ## age stress ## 1 36 7 ## 2 45 7 ## 3 32 7 ## 4 57 6 ## 5 46 6 ## 6 60 6 head(nurses[, c(&quot;age&quot;,&quot;hospsize&quot;)]) ## age hospsize ## 1 36 large ## 2 45 large ## 3 32 large ## 4 57 large ## 5 46 large ## 6 60 large 1.7 Frequencies and Contingency Tables One of the most basic tasks of a statistician is to count stuff! Indeed, when we have categorical variables, that’s the only way we can summarize them. R has two basic functions for doing so, table and xtabs. Both can return counts of the number of cases in various categories, but xtabs is built specifically for cross-tabulation. They do not compute percentages, though. You need one more step that I’ll show you now. ## Single variable using table table(nurses$gender) ## ## male female ## 265 735 ## Single Variable using xtabs xtabs(~ gender, data = nurses) ## gender ## male female ## 265 735 ## Cross tabulate xtabs(~ gender + wardtype, data = nurses) ## wardtype ## gender general care special care ## male 134 131 ## female 365 370 ### Create a table and get proportions gentab &lt;- xtabs(~ gender + wardtype, data = nurses) # cell percentages... joint probability prop.table(gentab) ## wardtype ## gender general care special care ## male 0.134 0.131 ## female 0.365 0.370 # conditioning on gender, what is the percent of each ward type prop.table(gentab, margin = 1) ## wardtype ## gender general care special care ## male 0.5056604 0.4943396 ## female 0.4965986 0.5034014 # conditioning on ward type, what is the percent of each gender prop.table(gentab, margin = 2) ## wardtype ## gender general care special care ## male 0.2685371 0.2614770 ## female 0.7314629 0.7385230 1.8 Descriptive statistics Like everything else, there are many options for summarizing a bunch of variables. Here we’ll check one out from the psych package. For more on this type ?psych in the console. Actually do it! If successful, you’ll see the help page for psych come up in one of your panes. In that window, click on describe it will be underlined in the 3rd line of the text. 1.8.1 The describe function We’re going to use this function now. Note that in the “Usage” section of the help document, there’s lots of options for the describe function. They’re all default, so the only thing we need to do is simply specify what x is. As with foreign the psych package needs to be loaded with the library() command. In practice, it’s best to put all of your library() commands at the top of your script and load them simultaneously. That’s because you only need to load a library / package one time per R session. library(psych) # use the describe function from psych on nurses # name the columns you want describe(nurses[ , c(&quot;age&quot;,&quot;experien&quot;,&quot;stress&quot;) ]) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 1000 43.01 12.04 43 42.98 14.83 23 64 41 0.03 -1.18 0.38 ## experien 2 1000 17.06 6.04 17 17.06 5.93 1 38 37 0.03 -0.39 0.19 ## stress 3 1000 4.98 0.98 5 5.03 1.48 1 7 6 -0.45 0.25 0.03 # use column numbers describe(nurses[, c(5,7,8)]) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 1000 43.01 12.04 43 42.98 14.83 23 64 41 0.03 -1.18 0.38 ## experien 2 1000 17.06 6.04 17 17.06 5.93 1 38 37 0.03 -0.39 0.19 ## stress 3 1000 4.98 0.98 5 5.03 1.48 1 7 6 -0.45 0.25 0.03 # use columns 5 through 10 describe(nurses[ , 5:10]) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 1000 43.01 12.04 43 42.98 14.83 23 64 41 0.03 -1.18 0.38 ## gender* 2 1000 1.73 0.44 2 1.79 0.00 1 2 1 -1.06 -0.87 0.01 ## experien 3 1000 17.06 6.04 17 17.06 5.93 1 38 37 0.03 -0.39 0.19 ## stress 4 1000 4.98 0.98 5 5.03 1.48 1 7 6 -0.45 0.25 0.03 ## wardtype* 5 1000 1.50 0.50 2 1.50 0.00 1 2 1 0.00 -2.00 0.02 ## hospsize* 6 1000 1.78 0.69 2 1.72 1.48 1 3 2 0.32 -0.90 0.02 The column labels are pretty self explanatory, but your view in R studio may be different. For the most part, running something in the Script window will send output to the Console. 1.8.2 The describeBy function Often we want to compute descriptive statistics for different groups. To do so, we use the describeBy function, also in the psych package. It works the same as describe but now we have to give it a grouping variable. We do this using the group argument. Don’t forget, you have to use the $ operator. The grouping variable is converted to a factor, even if it is numeric. We can also analyze several variables per group at a time. Let’s look at age, experience, and stress by gender and then by ward type. Do you notice any differences between male and female nurses? They’re subtle, but one important one is the number of males and females. ## outcomes by gender describeBy(nurses[, c(&quot;age&quot;,&quot;experien&quot;,&quot;stress&quot;)], group = nurses$gender) ## ## Descriptive statistics by group ## group: male ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 265 43.55 11.80 43 43.59 14.83 23 64 41 0.01 -1.14 0.72 ## experien 2 265 17.49 6.19 17 17.44 5.93 4 38 34 0.15 -0.41 0.38 ## stress 3 265 5.32 0.93 5 5.35 1.48 3 7 4 -0.34 0.01 0.06 ## ----------------------------------------------------------------------------- ## group: female ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 735 42.81 12.13 43 42.75 14.83 23 64 41 0.03 -1.20 0.45 ## experien 2 735 16.90 5.98 17 16.91 5.93 1 36 35 -0.02 -0.42 0.22 ## stress 3 735 4.85 0.97 5 4.92 1.48 1 7 6 -0.50 0.26 0.04 Now let’s look across ward type (general care and special care). See any differences here? ## outcomes by ward type describeBy(nurses[, c(&quot;age&quot;,&quot;experien&quot;,&quot;stress&quot;)], group = nurses$wardtype) ## ## Descriptive statistics by group ## group: general care ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 499 42.99 12.28 42 42.97 14.83 23 64 41 0.05 -1.22 0.55 ## experien 2 499 17.16 6.35 17 17.05 5.93 3 38 35 0.16 -0.42 0.28 ## stress 3 499 4.94 1.05 5 4.99 1.48 1 7 6 -0.41 0.17 0.05 ## ----------------------------------------------------------------------------- ## group: special care ## vars n mean sd median trimmed mad min max range skew kurtosis se ## age 1 501 43.02 11.81 43 43.01 14.83 23 64 41 0.00 -1.14 0.53 ## experien 2 501 16.95 5.73 17 17.07 5.93 1 32 31 -0.14 -0.46 0.26 ## stress 3 501 5.02 0.91 5 5.08 1.48 2 7 5 -0.45 0.16 0.04 1.8.3 Computing a new variable and adding it to the dataframe Finally, let’s see how to make a new variable and add it to the data frame. We do this by using the $ and naming a new variable on the fly. Here I’m going make a new composite variable which is just age times experience. I’m naming it composite but I can call it anything I want, as long as it’s not already a variable, it doesn’t begin with a number, and it has no spaces (underscores and periods are ok). nurses$composite &lt;- nurses$age * nurses$experien This data set also has Z scores for a number of variables. Let’s get fancy and see if we can re-make them by computing our own Z-scores for age. They should be the same as what’s there. nurses$Zage2 &lt;- (nurses$age - mean(nurses$age)) / sd(nurses$age) head(nurses[, c(&quot;Zage&quot;,&quot;Zage2&quot;)]) ## Zage Zage2 ## 1 -0.5817336 -0.5817336 ## 2 0.1656757 0.1656757 ## 3 -0.9139156 -0.9139156 ## 4 1.1622216 1.1622216 ## 5 0.2487212 0.2487212 ## 6 1.4113581 1.4113581 Notice the liberal use of parenthesis. R respects order of operations very literally, so when doing computations like this, it is important to check your work. Here’s one more, a log transformation nurses$logAge &lt;- log(nurses$age) 1.9 Visualizing Data One place where R really excels is with data visualization. We will only scratch the surface here. There is much more you can learn in Hadley Wickham’s book. 1.9.1 Histograms and density plots For right now, we’ll use the base-R commands as well as similar ones from John Fox’s car package. Let’s first look at histograms for age, experience, and stress: # using base R hist(nurses$age) hist(nurses$experien) hist(nurses$stress) Now we’ll create density plots, which are smoothed histograms. This helps us infer the shape of the distribution, but can be misleading for discrete data. The cool thing here is that we can make plots for different groups. To do so, we’ll use the formula interface that’s common to more advanced R code. It uses the tilde ~. ## load car library(car) # all nurses densityPlot(~ experien, data = nurses) # by ward type densityPlot(experien ~ wardtype, data = nurses) 1.9.2 Boxplots Boxplots are useful for detecting outliers and comparing distributions that might have very different shapes. The box is the middle 50% of the data (stretching from the 25th percentile to the 75th), the “whiskers” extend out to the value that is 1.5 times the inter-quartile range, but sometimes to the min and max values. In the former situation, circles outside of the whiskers denote outliers. There is no single agreed upon definition of outlier, but the Boxplots here use Tukey’s definition, which is the one using the IQR. Also, there is a base R version of boxplot, and Boxplot, a function from the car package that prints the rows containing the outliers (if any) to the console. Again, we use the formula interface to see boxplots for different groups # regular boxplot boxplot(nurses$experien) boxplot(experien ~ wardtype, data = nurses) # boxplot printing the outlier cases Boxplot(nurses$experien) ## [1] 586 916 Boxplot(experien ~ wardtype, data = nurses) ## [1] &quot;586&quot; &quot;916&quot; 1.9.3 Scatterplots The last kind of visualization we often want is a scatterplot. Again, there are many options and we’ll look at two of them. R’s generic plot function is very flexible, but also requires a lot to make look good. That’s why there are many alternatives that we’ll see later in the course. Here, we’ll again contrast with one of the functions from the car package. Let’s see if age and experience are linearly related: plot(nurses$age, nurses$experien) scatterplot(experien ~ age, data = nurses) 1.10 Review Wow that was a lot. Our objectives were: Overcome any fear about learning to “code” Learn about data structures in R Type data into R (not fun!) Import data to R from SPSS Import data from Excel Using the psych package Transforming / computing variables Visualizing data "],["ordinary-linear-regression.html", "2 Ordinary Linear Regression 2.1 Our data 2.2 ANOVA and drop1 commands 2.3 Plots", " 2 Ordinary Linear Regression Note, make sure to load the faraway package: library(faraway) R uses the formula interface which consists of three parts: the left-hand side, the ~ (tilde), and the right-hand side The left-hand side of the model formula specifies the response variable Can be a variable name or a function like log(variable) The tilde is a separator: think of it as “regressed on” The right-hand side is the most complex part of the formula. It is a special expression it includes the names of the predictors, that R evaluates to produce the regressors for the model. The arithmetic operators, +, -, *, /, and ^, have special meaning on the right-hand side of a model formula 2.1 Our data For the tutorial, we’ll use the teengamb data that is in the faraway package. From the help page (type ?teengamb at the console): Data has 47 rows and 5 columns. It was a from a survey studying teenage gambling in the UK Variables: sex: 0 = male, 1 = female status: Socioeconomic status score based on parents’ occupation income: in pounds per week verbal: verbal score in words out of 12 correctly defined gamble: expenditure on gambling in pounds per year library(faraway) str(teengamb) ## &#39;data.frame&#39;: 47 obs. of 6 variables: ## $ sex : int 1 1 1 1 1 1 1 1 1 1 ... ## $ status : int 51 28 37 28 65 61 28 27 43 18 ... ## $ income : num 2 2.5 2 7 2 3.47 5.5 6.42 2 6 ... ## $ verbal : int 8 8 6 4 8 6 7 5 6 7 ... ## $ gamble : num 0 0 0 7.3 19.6 0.1 1.45 6.6 1.7 0.1 ... ## $ sex_fac: Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 2 2 2 2 2 2 2 2 2 2 ... 2.1.1 Converting from numeric to factor Many times we have data that are numerically coded and we need R to interpret them as factors / codes. The teengamb is a good example. Here, sex = 0 corresponds to male, and sex = 1 is female. So this is an indicator variable for female. You have two options in the binary situation, you can leave the codes if they are 0 / 1 and simply remember what they stand for, which is not good practice since that will likely lead to errors. Also, if you want to change the reference group, you have to change the data instead of the formatting. Here’s how to make a numeric variable a factor teengamb$sex_fac &lt;- factor(teengamb$sex, levels = c(0, 1), labels = c(&quot;Male&quot;,&quot;Female&quot;)) Let’s look at how this affects the model output ## model with numeric variable gamb.mod &lt;- lm(gamble ~ sex + status + income + verbal, data = teengamb) summary(gamb.mod) ## ## Call: ## lm(formula = gamble ~ sex + status + income + verbal, data = teengamb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.082 -11.320 -1.451 9.452 94.252 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.55565 17.19680 1.312 0.1968 ## sex -22.11833 8.21111 -2.694 0.0101 * ## status 0.05223 0.28111 0.186 0.8535 ## income 4.96198 1.02539 4.839 1.79e-05 *** ## verbal -2.95949 2.17215 -1.362 0.1803 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.69 on 42 degrees of freedom ## Multiple R-squared: 0.5267, Adjusted R-squared: 0.4816 ## F-statistic: 11.69 on 4 and 42 DF, p-value: 1.815e-06 And now with the factor ## model with numeric variable gamb.mod.fac &lt;- lm(gamble ~ sex_fac + status + income + verbal, data = teengamb) summary(gamb.mod.fac) ## ## Call: ## lm(formula = gamble ~ sex_fac + status + income + verbal, data = teengamb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.082 -11.320 -1.451 9.452 94.252 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.55565 17.19680 1.312 0.1968 ## sex_facFemale -22.11833 8.21111 -2.694 0.0101 * ## status 0.05223 0.28111 0.186 0.8535 ## income 4.96198 1.02539 4.839 1.79e-05 *** ## verbal -2.95949 2.17215 -1.362 0.1803 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.69 on 42 degrees of freedom ## Multiple R-squared: 0.5267, Adjusted R-squared: 0.4816 ## F-statistic: 11.69 on 4 and 42 DF, p-value: 1.815e-06 Results from all regression models in R using factors will print out the name of the indicator group appended to the variable name in the output So above, sex_facFemale is short hand for the indicator variable Female constructed using the sex factor. When there are more than 2 categories, you will get multiple indicator variables from the same factor (\\(k-1\\) for \\(k\\) categories). 2.1.2 Confidence Intervals v. p-values Reminder: A confidence interval is an estimated set of values that should “trap” the true parameter some “percentage” of time in repeated replications. We can be 95% confident in our interval, but that doesn’t mean there’s a .95 probability that the parameter is in that range confint() returns 95% confidence intervals by default, but you can specify the level manually Note, only the confidence limits are given, with some finagling, we can also get the coefficients to print too: confint(gamb.mod.fac, level = .95) ## 2.5 % 97.5 % ## (Intercept) -12.1489038 57.2602050 ## sex_facFemale -38.6890301 -5.5476301 ## status -0.5150722 0.6195399 ## income 2.8926538 7.0313047 ## verbal -7.3430703 1.4240833 cbind(coef(gamb.mod.fac),confint(gamb.mod.fac, level = .95)) ## 2.5 % 97.5 % ## (Intercept) 22.55565063 -12.1489038 57.2602050 ## sex_facFemale -22.11833009 -38.6890301 -5.5476301 ## status 0.05223384 -0.5150722 0.6195399 ## income 4.96197922 2.8926538 7.0313047 ## verbal -2.95949350 -7.3430703 1.4240833 2.1.3 Adding interaction terms Interaction terms can be added in 2 ways: using the * operator forming the actual product using the : operator multiplying to regressors together in a data-frame and adding that term with the + operator The principle of marginality says that the interaction is best interpreted when the two main effects are in the model 2.1.4 Interaction model for Gambling Here we use the * operator, which is equivalent to sex + income + sex:income Since sex is binary, we’ll only need one interaction term if specifying it with the :. This is another reason to use the asterisk, as it sets up the correct number of indicator interactions for multiple category predictors. gamb.mod2 &lt;- lm(gamble ~ sex_fac*income + status + verbal, data = teengamb) gamb.mod2a &lt;- lm(gamble ~ sex + status + income + verbal + sex:income, data = teengamb) 2.1.5 Interaction Output Coefficients and confidence intervals summary(gamb.mod2) ## ## Call: ## lm(formula = gamble ~ sex_fac * income + status + verbal, data = teengamb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -57.109 -6.162 -0.938 2.267 86.503 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 19.25943 15.79635 1.219 0.22972 ## sex_facFemale 4.06362 11.51612 0.353 0.72600 ## income 6.19885 1.02591 6.042 3.77e-07 *** ## status -0.04876 0.25978 -0.188 0.85203 ## verbal -2.60864 1.99386 -1.308 0.19805 ## sex_facFemale:income -6.43683 2.14337 -3.003 0.00454 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 20.79 on 41 degrees of freedom ## Multiple R-squared: 0.6121, Adjusted R-squared: 0.5647 ## F-statistic: 12.94 on 5 and 41 DF, p-value: 1.417e-07 confint(gamb.mod2) ## 2.5 % 97.5 % ## (Intercept) -12.6419453 51.1608038 ## sex_facFemale -19.1936466 27.3208960 ## income 4.1269732 8.2707189 ## status -0.5734002 0.4758751 ## verbal -6.6353263 1.4180392 ## sex_facFemale:income -10.7654601 -2.1081980 2.2 ANOVA and drop1 commands As illustrated in the Faraway book, it’s often better to examine model-comparison (likelihood-ratio) F-tests from nested models for inference about factors with multiple levels. This is an alternative to using the \\(t\\)-tests for the individual \\(\\beta\\)’s as well for numeric predictors. First, if we simply want to test the hypothesis that the addition of the interaction reduced the model residual \\(SS_{resid}\\) (i.e., improved fit), we can test that directly using anova(). anova(gamb.mod, gamb.mod2) ## Analysis of Variance Table ## ## Model 1: gamble ~ sex + status + income + verbal ## Model 2: gamble ~ sex_fac * income + status + verbal ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 42 21624 ## 2 41 17725 1 3898.9 9.0188 0.004538 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 However, it’s often convenient and helpful to have a test for each predictor of the reduction in \\(SS_{resid}\\), and the drop1 function does just that. The output is similar to what SPSS and SAS give for their general linear model commands: drop1(gamb.mod2, test = &quot;F&quot;) ## Single term deletions ## ## Model: ## gamble ~ sex_fac * income + status + verbal ## Df Sum of Sq RSS AIC F value Pr(&gt;F) ## &lt;none&gt; 17725 290.83 ## status 1 15.2 17740 288.87 0.0352 0.852032 ## verbal 1 740.0 18465 290.75 1.7117 0.198046 ## sex_fac:income 1 3898.9 21624 298.18 9.0188 0.004538 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Since all of our predictors use up only one degree of freedom each, the \\(F\\)-test results are identical to the individual \\(t\\)-test results in the model itself. This will not be the case when we introduce factors with more than 2 categories and/or interactions involving such factors. Notice also, that since there is an interaction in the model, drop1 will not provide a test of the main effects of income or sex. To get those, you’d have to use the first model: drop1(gamb.mod.fac, test = &quot;F&quot;) ## Single term deletions ## ## Model: ## gamble ~ sex_fac + status + income + verbal ## Df Sum of Sq RSS AIC F value Pr(&gt;F) ## &lt;none&gt; 21624 298.18 ## sex_fac 1 3735.8 25360 303.67 7.2561 0.01011 * ## status 1 17.8 21642 296.21 0.0345 0.85349 ## income 1 12056.2 33680 317.00 23.4169 1.792e-05 *** ## verbal 1 955.7 22580 298.21 1.8563 0.18031 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.3 Plots Again, we’ll talk more about checking residual assumptions in later weeks, but R has built in methods for making plots: plot(gamb.mod2) Finally, we have a few options for making “marginal plots”: plots of the effect of one predictor holding the others constant. We’ll hold off on these for now, but the effects package has some nice features and we’ll explore that in subsequent weeks. For now, we’ll make a simple scatterplot of income and gamble adding in the coefficient from the model (not an ideal way to make the plot…) plot(gamble ~ income, teengamb, xlab=&quot;Income in pounds per week&quot;, ylab=&quot;Gambling expenditure in pounds per year&quot;) abline(coef(gamb.mod)[c(1,4)], lty = 1) "],["logistic-regression.html", "3 Logistic Regression 3.1 An Example: Diabetes risk factors 3.2 Model Discrimination and Fit", " 3 Logistic Regression This is the first look at logistic regression in R along with some fun things we can do with the output. We will use data from the faraway package as well as functions from the pROC package. You’ll probably need to install the pROC package library(faraway) library(pROC) 3.1 An Example: Diabetes risk factors From Faraway Exercise 2, Chapter 2: The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate factors related to diabetes. Lets have a look at the data str(pima) ## &#39;data.frame&#39;: 768 obs. of 15 variables: ## $ pregnant : int 6 1 8 1 0 5 3 10 2 8 ... ## $ glucose : int 148 85 183 89 137 116 78 115 197 125 ... ## $ diastolic : int 72 66 64 66 40 74 50 0 70 96 ... ## $ triceps : int 35 29 0 23 35 0 32 0 45 0 ... ## $ insulin : int 0 0 0 94 168 0 88 0 543 0 ... ## $ bmi : num 33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ... ## $ diabetes : num 0.627 0.351 0.672 0.167 2.288 ... ## $ age : int 50 31 32 21 33 30 26 29 53 54 ... ## $ test : int 1 0 1 0 1 0 1 0 1 1 ... ## $ insulin_fix: int NA NA NA 94 168 NA 88 NA 543 NA ... ## $ bmi_fix : num 33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 NA ... ## $ glucose_fix: int 148 85 183 89 137 116 78 115 197 125 ... ## $ triceps_fix: int 35 29 NA 23 35 NA 32 NA 45 NA ... ## $ dbp_fix : int 35 29 0 23 35 0 32 NA 45 0 ... ## $ bmi_fac : Factor w/ 4 levels &quot;normal&quot;,&quot;underweight&quot;,..: 4 3 1 3 4 3 4 4 4 2 ... So we see we have 768 observations on 9 variables. This is a nice sized dataset for both inference and prediction. However, we want to first explore the number of events as that’s the true limiting factor for judging power and precision in logistic regression. table(pima$test) ## ## 0 1 ## 500 268 So our effective samples size is \\(N_{positive} = 268\\). Using the 15:1 rule of thumb: \\(\\frac{268}{15} \\approx 18\\) predictors would be ok, but we don’t even have that many Unfortunately, there are zero values in some of the predictors that ought to be coded as missing. Some simple code for that is: pima$insulin_fix &lt;- ifelse(pima$insulin == 0, NA, pima$insulin) This is also true for bmi, glucose, and triceps. So we’ll fix those: pima$bmi_fix &lt;- ifelse(pima$bmi == 0, NA, pima$bmi) pima$glucose_fix &lt;- ifelse(pima$glucose == 0, NA, pima$glucose) pima$triceps_fix &lt;- ifelse(pima$triceps == 0, NA, pima$triceps) pima$dbp_fix &lt;- ifelse(pima$diastolic == 0, NA, pima$triceps) Now, we’re also going to make bmi a factor using the CDC ranges: Underweight: Less than 18.5 Healthy Weight: 18.5 to less than 25 Overweight: 25 to less than 30 Obesity: 30 or greater # use cut to turn the numeric variable into categories pima$bmi_fac &lt;- cut(pima$bmi, breaks = c(0,18.5,25,30,Inf), include.lowest = T, right = F) # name the levels levels(pima$bmi_fac) &lt;- c(&quot;underweight&quot;,&quot;normal&quot;,&quot;overweight&quot;,&quot;obese&quot;) # change the reference group to normal pima$bmi_fac &lt;- relevel(pima$bmi_fac, ref = &quot;normal&quot;) # check the releveling contrasts(pima$bmi_fac) ## underweight overweight obese ## normal 0 0 0 ## underweight 1 0 0 ## overweight 0 1 0 ## obese 0 0 1 Let’s try predicting the test result given some of the predictors First we’ll start with basic stuff that should be related: Glucose concentration Diastolic blood pressure BMI (categorical) Age We’re deliberately not including the diabetes variable since it will likely be very associated with the outcome. It turns out insulin is not associated so for numerical stability, we exclude it for now. mod1 &lt;- glm(test ~ glucose_fix + dbp_fix + bmi_fac + age, family = binomial, data = pima) summary(mod1) ## ## Call: ## glm(formula = test ~ glucose_fix + dbp_fix + bmi_fac + age, family = binomial, ## data = pima) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -7.9008278 0.6867247 -11.505 &lt; 2e-16 *** ## glucose_fix 0.0349670 0.0035238 9.923 &lt; 2e-16 *** ## dbp_fix 0.0002151 0.0061522 0.035 0.97211 ## bmi_facunderweight 0.7440401 1.2477671 0.596 0.55098 ## bmi_facoverweight 1.2315584 0.4783102 2.575 0.01003 * ## bmi_facobese 2.2004434 0.4551304 4.835 1.33e-06 *** ## age 0.0310290 0.0081477 3.808 0.00014 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 936.6 on 727 degrees of freedom ## Residual deviance: 692.4 on 721 degrees of freedom ## (40 observations deleted due to missingness) ## AIC: 706.4 ## ## Number of Fisher Scoring iterations: 5 Note: our sample size goes down to \\(N = 728\\) and \\(m = 250\\) events, so we’re still doing very well in terms of the predictor to event ratio. Clearly there are some associations. Let’s get the odds ratios and \\(95\\%\\) CI’s: round(cbind(&quot;OR&quot; = exp(coef(mod1)), exp(confint(mod1))), 3) ## Waiting for profiling to be done... ## OR 2.5 % 97.5 % ## (Intercept) 0.000 0.000 0.001 ## glucose_fix 1.036 1.029 1.043 ## dbp_fix 1.000 0.988 1.012 ## bmi_facunderweight 2.104 0.093 18.513 ## bmi_facoverweight 3.427 1.414 9.415 ## bmi_facobese 9.029 3.941 23.938 ## age 1.032 1.015 1.048 Now often we’re interested in more than just 1 unit increase on numeric variables. What can we do to get the association between a 5 unit increase in glucose and odds of a positive test? Solution: Take the regular odds ratio and raise it to the 5th power: \\(\\text{OR} = 1.036^{5} = 1.19\\) So a 5-unit increase in glucose levels equates to \\(19\\%\\) greater odds of a positive test Similarly, as someone ages 10 years, their odds of a positive test increases by a factor of \\({OR} = 1.032^{10} = 1.37\\) so the odds are \\(1.37\\) times greater for someone who is 10 years older than average! Now what about the BMI categories. Clearly, there are some differences in log-odds between higher BMI and normal, but what if we just wanted a test of whether BMI matters? We use the likelihood ratio approach. We can do this in 2 ways: drop1 drop1(mod1, test = &quot;Chi&quot;) ## Single term deletions ## ## Model: ## test ~ glucose_fix + dbp_fix + bmi_fac + age ## Df Deviance AIC LRT Pr(&gt;Chi) ## &lt;none&gt; 692.40 706.40 ## glucose_fix 1 817.65 829.65 125.248 &lt; 2.2e-16 *** ## dbp_fix 1 692.40 704.40 0.001 0.9721066 ## bmi_fac 3 734.94 742.94 42.538 3.085e-09 *** ## age 1 707.10 719.10 14.699 0.0001261 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Fit a reduced model and use anova mod2 &lt;- glm(test ~ glucose_fix + dbp_fix + age, family = binomial, data = pima) anova(mod2, mod1) ## Analysis of Deviance Table ## ## Model 1: test ~ glucose_fix + dbp_fix + age ## Model 2: test ~ glucose_fix + dbp_fix + bmi_fac + age ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 724 734.94 ## 2 721 692.40 3 42.538 3.085e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 So you can see, that drop1 is just a short-cut to fitting a restricted model and testing with a likelihood-ratio test using anova. As we said, we’ll skip the diagnostics, but here’s what they might look like. plot(mod1) Finally, let’s try to understand model fit via ROC and Nagelkerke’s pseudo-\\(R^{2}\\). We can get an even better look at how well our model actual predicts the test results by making calibration plots, but we’ll come back to those later in the course. 3.2 Model Discrimination and Fit If we were simply interested in whether the test could replace another test, then we only need cross-classification of the two tests for sensitivity and specificity. However, we use the two here to judge whether the use of our model equation can potentially provide helpful information to discriminate between positive and negative cases. The ROC and AUROC are only part of the story, but they’re helpful. We’ll begin first by picking an arbitrary probability threshold from our model. That is, the model equation can be transformed from log-odds to probability with the logistic function: If \\(\\eta\\) is the linear predictor (our model equation), then \\[ p_{predict} = \\frac{\\exp^{\\eta}}{1+ \\exp^{\\eta}} \\] For example: Person 41 has the following values of the predictors: pima[41, c(&quot;glucose_fix&quot;,&quot;dbp_fix&quot;,&quot;bmi_fac&quot;,&quot;age&quot;)] ## glucose_fix dbp_fix bmi_fac age ## 41 180 25 obese 26 pima[41, &quot;test&quot;] ## [1] 0 We also see that this person’s test result is negative. Let’s use the equation to predict the probability that this person tests positive, pretending that we don’t know their true result: coef(mod1) ## (Intercept) glucose_fix dbp_fix bmi_facunderweight bmi_facoverweight ## -7.9008278062 0.0349670205 0.0002151114 0.7440400790 1.2315583898 ## bmi_facobese age ## 2.2004433703 0.0310290344 \\[ \\begin{align} \\log(odds) &amp; = -7.901 + (0.035\\times 180) + (0.0002 \\times 25) + (1 \\times 2.200) + (0.031\\times 26)&amp;\\\\ &amp;= -7.901 + 6.3 + 0.005 + 2.20 + 0.806\\\\ &amp;= 1.41 \\end{align} \\] So this person’s prediction is 1.41 logits. Obviously, that’s not helpful, but this is their value of \\(\\eta\\) so we plug into the equation for probability: \\[ \\begin{align} \\hat{p} &amp; = \\frac{\\exp^{1.41}}{1 + \\exp^{1.41}} &amp;\\\\ &amp; = 0.804 \\end{align} \\] So on average \\(0.804\\) proportion of the population with those covariate values should have a positive test. Clearly, we might want to set a high threshold for prediction if someone with a predicted probability of \\(0.804\\) is not a positive case. Here, we’ll set the threshold at the arbitrary value of \\(0.51\\) Also, due to missing data in our dataset, we’ll make a new dataframe using the model pima_pred &lt;- mod1$model ## sensitivity and specificity # set a threshold thresh &lt;- .51 # add predicted probabilities to dataset pima_pred$pred.prob &lt;- predict(mod1, type = &quot;response&quot;) # create binary prediction pima_pred$pred.response &lt;- ifelse(pima_pred$pred.prob &gt; thresh, &quot;yes&quot;,&quot;no&quot;) # confusion matrix (thresh51 &lt;- xtabs(~ test + pred.response, data = pima_pred)) ## pred.response ## test no yes ## 0 426 52 ## 1 119 131 thresh51[2,2] / (thresh51[2,2] + thresh51[2,1]) # sensitivity ## [1] 0.524 thresh51[1,1] / (thresh51[1,1] + thresh51[1,2]) # specificity ## [1] 0.8912134 Now, remember, this is only for that given threshold. The ROC can help us choose an optimal threshold and give us some idea of our overall ability to determine positive from negative cases given values of the covariates. What we’re plotting is sensitivity and specificity for every choice of threshold between \\(0\\) and \\(1\\). So we’ll get a wiggly line because in this dataset, there are \\(725\\) different thresholds! Note, the pROC package, which we’ll use, produces a plot with specificity on the x-axis. You’re probably more familiar with a plot that has \\(1-\\text{specificity}\\) on the x-axis (the false positive rate). This curve is the same, it just starts at a different place. 3.2.1 ROC and AUROC m1_roc &lt;- roc(test ~ pred.prob, data = pima_pred) ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases plot(m1_roc) auc(m1_roc) ## Area under the curve: 0.8273 ci.auc(m1_roc) ## 95% CI: 0.7973-0.8573 (DeLong) Finally, we can chose one of a number of goodness of fit measures. You may have heard of the Hosmer-Lemeshow statistic, which is essentially a \\(\\chi^{2}\\) goodness of fit test between the mean response of some set of the population \\(y_{i}\\) and the predicted probability from the model, in a “bin” of data with \\(m_{j}\\) observations. Because it depends on a choice of bin size \\(m_i\\), we’ll leave it until we cover calibration in Week 5. Instead, we’ll compute the Nagelkerke pseudo-\\(R^{2}\\) which is a little easier, and doesn’t depend on a special R package. mod.dev &lt;- mod1$deviance null.dev &lt;- mod1$null.deviance n &lt;- nrow(pima_pred) (1-exp((mod.dev - null.dev)/n))/(1-exp(-null.dev/n)) ## [1] 0.3937377 "],["regression-with-counts-as-outcomes.html", "4 Regression with Counts as Outcomes 4.1 Example data: PHMC Fruits question 4.2 Coefficients in Poisson Models 4.3 Overdispersion and other count regression models 4.4 Zero-inflated models", " 4 Regression with Counts as Outcomes As a reminder from the text, unlike the log-odds used as the link in logistic regression, the standard “log-linear” model uses the natural logarithm (\\(\\log (x)\\)) as the link function so: \\[ \\log{[\\hat{\\mu}(\\textbf{x})]} = \\beta_{0}+\\beta_{1}x_{1} + \\ldots \\] We use the notation \\(\\hat{\\mu}(\\textbf{x})\\) as the expected value of \\(y\\) given \\(\\textbf{x}\\) Interpretation of coefficients: Log scale: an increase of 1 unit of \\(x_i\\) leads to \\(\\beta_{i}\\) increase or decrease in \\(\\log[\\hat{\\mu}]\\) with other variables in the model, this is an adjusted change Exponentiated: an increase of 1 unit of \\(x_i\\) leads to \\(e^{\\beta_{i}}\\) times the number or rate of \\(Y\\) again, this will be an adjusted change in multiple regression 4.1 Example data: PHMC Fruits question In 2018, the Public Health Management Corporation conducted a home health survey sampling residents of the southeastern PA region (Bucks, Montgomery, Chester, Delaware, and Philadelphia Counties). One question they asked was: How many servings of fruits and vegetables do you eat on a typical day? Responses were recorded as integers: \\(y=\\{0, \\dots, 15\\}\\) Here’s a histogram of the responses d &lt;- foreign::read.spss(&quot;https://rickhass.github.io/PHMC_count_tutorial_2.sav?raw=true&quot;, to.data.frame = T) hist(d$FRUITS, breaks = 12, main = &quot;&quot;, xlab = &quot;Number of Fruits&quot;, ylab = &quot;Freq&quot;) Since we do have a numeric, possibly unbounded count, but not a lot of zeros, we’ll try an ordinary linear model with lm() We’ll use the following predictors: Whether or not the person has insurance Their biological sex Their BMI lm.fruit &lt;- lm(FRUITS ~ INSUREDA2 + SEX01 + BMI, data=d) summary(lm.fruit) ## ## Call: ## lm(formula = FRUITS ~ INSUREDA2 + SEX01 + BMI, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9551 -1.1369 -0.3328 0.6685 8.7147 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.623202 0.167370 15.673 &lt; 2e-16 *** ## INSUREDA2No -0.222155 0.146952 -1.512 0.1307 ## SEX01Female 0.473712 0.071179 6.655 3.61e-11 *** ## BMI -0.009467 0.005611 -1.687 0.0917 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.598 on 2081 degrees of freedom ## (173 observations deleted due to missingness) ## Multiple R-squared: 0.02356, Adjusted R-squared: 0.02215 ## F-statistic: 16.74 on 3 and 2081 DF, p-value: 9.586e-11 qqnorm(residuals(lm.fruit)) plot(fitted.values(lm.fruit), residuals(lm.fruit), xlab = &quot;Predicted value&quot;, ylab = &quot;Residual&quot;) As we can see, the residuals are not normally distributed, and their variance is not constant. Perhaps we can do better with a Poisson model. 4.2 Coefficients in Poisson Models glm.fruit &lt;- glm(FRUITS ~ INSUREDA2 + SEX01 + BMI, family = &quot;poisson&quot;, data=d) summary(glm.fruit) ## ## Call: ## glm(formula = FRUITS ~ INSUREDA2 + SEX01 + BMI, family = &quot;poisson&quot;, ## data = d) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.957420 0.065044 14.720 &lt; 2e-16 *** ## INSUREDA2No -0.088984 0.059421 -1.498 0.1343 ## SEX01Female 0.184059 0.028081 6.555 5.58e-11 *** ## BMI -0.003588 0.002175 -1.649 0.0991 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 1979.1 on 2084 degrees of freedom ## Residual deviance: 1929.6 on 2081 degrees of freedom ## (173 observations deleted due to missingness) ## AIC: 7525.7 ## ## Number of Fisher Scoring iterations: 5 halfnorm(residuals(glm.fruit)) It looks like we may have some outliers, but we’ll proceed with interpreting coefficients before looking into the model fit. 4.2.1 Exponentiated Coefficients Interpretation A good source for interpretation of Poisson coefficients is here: https://stats.idre.ucla.edu/r/dae/poisson-regression/ When we exponentiate, we get incidence rates, which are essentially expected counts. Let’s look at the indicator for Female: the raw coefficient is \\(\\hat{\\beta} = 0.184\\) meaning that, on average, females eat 0.184 more log fruits compared with males. Let’s compare with the exponentiated coefficient: the IRR exp(coef(glm.fruit)) ## (Intercept) INSUREDA2No SEX01Female BMI ## 2.6049669 0.9148600 1.2020871 0.9964187 So \\(e^{\\beta} = 1.202\\) meaning that females eat about \\(20\\%\\) more fruit on average. Or that the number of fruits consumed by the average female is \\(1.20\\) times that eaten by males. As with logistic regression, we can exponentiate the confidence limits to get CI’s for the incidence rate ratios: round(cbind(exp(coef(glm.fruit)), exp(confint(glm.fruit))), 3) ## Waiting for profiling to be done... ## 2.5 % 97.5 % ## (Intercept) 2.605 2.294 2.960 ## INSUREDA2No 0.915 0.813 1.026 ## SEX01Female 1.202 1.138 1.270 ## BMI 0.996 0.992 1.001 4.3 Overdispersion and other count regression models As we see above, the dispersion parameter is taken to be equal to 1. We can relax that assumption and estimate it using the quasipoisson family. The Poisson model assumes that the dispersion parameter, \\(\\phi\\) is equal to 1 in the below equation \\[ Var(y \\mid \\textbf{x}) = \\phi \\times V[\\mu(\\textbf{x})] \\] qp.fruit &lt;- glm(FRUITS ~ INSUREDA2 + SEX01 + BMI, family = quasipoisson, data=d) summary(qp.fruit) ## ## Call: ## glm(formula = FRUITS ~ INSUREDA2 + SEX01 + BMI, family = quasipoisson, ## data = d) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.957420 0.064138 14.928 &lt; 2e-16 *** ## INSUREDA2No -0.088984 0.058593 -1.519 0.1290 ## SEX01Female 0.184059 0.027689 6.647 3.8e-11 *** ## BMI -0.003588 0.002145 -1.673 0.0946 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasipoisson family taken to be 0.9723222) ## ## Null deviance: 1979.1 on 2084 degrees of freedom ## Residual deviance: 1929.6 on 2081 degrees of freedom ## (173 observations deleted due to missingness) ## AIC: NA ## ## Number of Fisher Scoring iterations: 5 Here, we see that \\(\\hat{\\phi} = 0.972\\), so the original fit is likely to be ok. Indeed, we can test it’s fit directly by getting a p-value for the residual deviance of the original model: with(glm.fruit, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 1929.629 2081 0.9916986 4.3.1 Overdispersion and Zero-inflation For an example of overdispersed and zero-inflated data, let’s have a look at a snippet of data collected by Jefferson Health on a number of questions on patients’ health related social needs. To protect PHI, the individual questions are not here, only the number of needs each patient reported (from zero to 8). load(url(&quot;https://rickhass.github.io/HRSN.RData?raw=true&quot;)) summary(HRSN.example) ## Sex Age race4 SVI4 SumScore ## Female:5910 19-44 :3476 White :6666 1 - Low :3378 Min. :0.0000 ## Male :4090 45-64 :3274 BlackAA :1872 2 - Low Medium :2678 1st Qu.:0.0000 ## 65-84 :2963 Asian : 600 3 - Medium High:1800 Median :0.0000 ## 85 And Over: 287 Other/Unknown: 862 4 - High :1371 Mean :0.2177 ## NA&#39;s : 773 3rd Qu.:0.0000 ## Max. :8.0000 ## race3 ## Length:10000 ## Class :character ## Mode :character ## ## ## xtabs(~SumScore, data = HRSN.example) ## SumScore ## 0 1 2 3 4 5 6 7 8 ## 8786 723 250 109 70 38 13 9 2 mean(HRSN.example$SumScore) ## [1] 0.2177 var(HRSN.example$SumScore) ## [1] 0.5337601 hist(HRSN.example$SumScore, breaks = 10, xlab = &quot;HRSN&quot;) So we can see that \\(\\text{Var}(Y) &gt; E(Y)\\) in this case. First, let’s look at a negative binomial regression model, this ignores the fact that about \\(88\\%\\) of patients have no needs… Remember: NB regression will often have very similar coefficients to Poisson Standard errors will be larger for NB regression, if \\(\\phi &gt; 1\\) If overdispersion is the “truth” the SEs for NB regression will be less biased Interpretation of \\(e^{\\beta}\\) is the same in NB and Poisson regression We use the glm.nb function from the MASS package. The syntax is the same as before, and we don’t have to specify a family because the function just fits NB models. library(MASS) hrsn.nb &lt;- glm.nb(SumScore ~ Sex + Age + SVI4 + race3, data = HRSN.example) summary(hrsn.nb) ## ## Call: ## glm.nb(formula = SumScore ~ Sex + Age + SVI4 + race3, data = HRSN.example, ## init.theta = 0.1689023943, link = log) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.22624 0.11726 -10.458 &lt; 2e-16 *** ## SexMale -0.18436 0.07389 -2.495 0.012590 * ## Age45-64 -0.22775 0.08254 -2.759 0.005794 ** ## Age65-84 -0.80505 0.09405 -8.560 &lt; 2e-16 *** ## Age85 And Over -0.90897 0.25519 -3.562 0.000368 *** ## SVI42 - Low Medium 0.40764 0.09397 4.338 1.44e-05 *** ## SVI43 - Medium High 0.57892 0.10308 5.616 1.95e-08 *** ## SVI44 - High 0.92585 0.11327 8.174 2.98e-16 *** ## race3Other -0.49160 0.11768 -4.177 2.95e-05 *** ## race3White -0.57691 0.09381 -6.150 7.76e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Negative Binomial(0.1689) family taken to be 1) ## ## Null deviance: 3639.7 on 9226 degrees of freedom ## Residual deviance: 3322.3 on 9217 degrees of freedom ## (773 observations deleted due to missingness) ## AIC: 9155.1 ## ## Number of Fisher Scoring iterations: 1 ## ## ## Theta: 0.16890 ## Std. Err.: 0.00953 ## ## 2 x log-likelihood: -9133.06500 This suggests there is actually **under*-dispersion. This is not exactly true. The issue is that there are very many more zeros than there ought to be given the model. 4.4 Zero-inflated models Remember, Zero-inflated models are Mixture Models Mixture distribution is built out of combinations of other distributions In Zero-inflated Models we model separate distributions for “zero v. not zero” and then the counts \\(1\\) to \\(\\inf\\) \\[ P(Y = 0) \\sim Logistic \\] \\[ P(Y = y_{i}) \\sim Count \\] Where “Count” is either Poisson or Negative Binomial Technically, each has a “mixture” proportion, but we’ll ignore that Fitting a Zero-Inflated Negative Binomial (ZINB) model requires the pscl package library(pscl) ## Classes and Methods for R originally developed in the ## Political Science Computational Laboratory ## Department of Political Science ## Stanford University (2002-2015), ## by and under the direction of Simon Jackman. ## hurdle and zeroinfl functions by Achim Zeileis. ZINB.1 &lt;- zeroinfl(SumScore ~ Sex + race3 + SVI4 | SVI4 + Sex, data = HRSN.example, dist = &quot;negbin&quot;) summary(ZINB.1) ## ## Call: ## zeroinfl(formula = SumScore ~ Sex + race3 + SVI4 | SVI4 + Sex, data = HRSN.example, dist = &quot;negbin&quot;) ## ## Pearson residuals: ## Min 1Q Median 3Q Max ## -0.4224 -0.3173 -0.2721 -0.2198 17.5424 ## ## Count model coefficients (negbin with log link): ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.39269 0.24793 -1.584 0.113230 ## SexMale 0.12044 0.10722 1.123 0.261302 ## race3Other -0.41252 0.11255 -3.665 0.000247 *** ## race3White -0.58888 0.08957 -6.575 4.88e-11 *** ## SVI42 - Low Medium -0.01276 0.14831 -0.086 0.931425 ## SVI43 - Medium High 0.27838 0.15436 1.803 0.071315 . ## SVI44 - High 0.31952 0.15006 2.129 0.033225 * ## Log(theta) -0.64406 0.36460 -1.767 0.077312 . ## ## Zero-inflation model coefficients (binomial with logit link): ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.7370 0.3650 2.019 0.04349 * ## SVI42 - Low Medium -0.6833 0.2101 -3.253 0.00114 ** ## SVI43 - Medium High -0.5381 0.1954 -2.754 0.00588 ** ## SVI44 - High -1.1535 0.2572 -4.485 7.29e-06 *** ## SexMale 0.4981 0.1602 3.110 0.00187 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Theta = 0.5252 ## Number of iterations in BFGS optimization: 45 ## Log-likelihood: -4587 on 13 Df exp(cbind(coef(ZINB.1), confint(ZINB.1))) ## 2.5 % 97.5 % ## count_(Intercept) 0.6752389 0.4153512 1.0977399 ## count_SexMale 1.1279935 0.9142019 1.3917816 ## count_race3Other 0.6619785 0.5309322 0.8253701 ## count_race3White 0.5549508 0.4656012 0.6614467 ## count_SVI42 - Low Medium 0.9873187 0.7382721 1.3203780 ## count_SVI43 - Medium High 1.3209873 0.9761330 1.7876738 ## count_SVI44 - High 1.3764721 1.0257433 1.8471244 ## zero_(Intercept) 2.0896773 1.0217890 4.2736331 ## zero_SVI42 - Low Medium 0.5049381 0.3345206 0.7621729 ## zero_SVI43 - Medium High 0.5838432 0.3980924 0.8562656 ## zero_SVI44 - High 0.3155179 0.1905896 0.5223345 ## zero_SexMale 1.6456525 1.2023081 2.2524778 The strange part is that the Zero-inflation model is a logistic model for a zero count. So we see that compared to low SVI, those in high SVI neighborhoods had smaller odds of NOT having an needs. The count part of the model can be interpreted the same way as ordinary Poisson or NB regression: log count raw coefficient IRR for the exponentiated coefficient "],["model-fit-and-assumptions-for-glms.html", "5 Model Fit and Assumptions for GLMs 5.1 Model Checking and Diagnostics in Ordinary Least Squares 5.2 Model Checking and Diagnostics in Logistic Regression 5.3 Summary", " 5 Model Fit and Assumptions for GLMs Two general kinds of approaches, both are important! Detecting single cases or a small group of cases that are affecting the overall fit or do not seem to go with the rest of the data Outlier detection, influence, leverage Checking model assumptions Structural form of the model: do we have the right set of predictors, do they need to be transformed? Stochastic or random form: eg., do residuals conform to model assumptions We’ll step through this for Ordinary Linear Regression and Logistic Regression, as those are the two approaches that we’ll continue to deal with in the course Remember: It is virtually impossible to verify that a given model is exactly correct. The purpose of the diagnostics is more to check whether the model is not grossly wrong. Indeed, a successful data analyst should pay more attention to avoiding big mistakes than optimizing the fit. (Faraway, p. 14) 5.1 Model Checking and Diagnostics in Ordinary Least Squares As we have seen, for ordinary linear models, the plot function returns very helpful output. Let’s take a look at it again for the teengamb data that is in the faraway package. As a reminder: Data has 47 rows and 5 columns. It was a from a survey studying teenage gambling in the UK Variables: sex: 0 = male, 1 = female status: Socioeconomic status score based on parents’ occupation income: in pounds per week verbal: verbal score in words out of 12 correctly defined gamble: expenditure on gambling in pounds per year Here, we’ll change sex to a factor and have a look at the results again teengamb$sex_fac &lt;- factor(teengamb$sex, levels = c(0, 1), labels = c(&quot;Male&quot;,&quot;Female&quot;)) ## model with numeric variable gamb.mod.fac &lt;- lm(gamble ~ sex_fac + status + income + verbal, data = teengamb) summary(gamb.mod.fac) ## ## Call: ## lm(formula = gamble ~ sex_fac + status + income + verbal, data = teengamb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.082 -11.320 -1.451 9.452 94.252 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.55565 17.19680 1.312 0.1968 ## sex_facFemale -22.11833 8.21111 -2.694 0.0101 * ## status 0.05223 0.28111 0.186 0.8535 ## income 4.96198 1.02539 4.839 1.79e-05 *** ## verbal -2.95949 2.17215 -1.362 0.1803 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.69 on 42 degrees of freedom ## Multiple R-squared: 0.5267, Adjusted R-squared: 0.4816 ## F-statistic: 11.69 on 4 and 42 DF, p-value: 1.815e-06 We can also see that drop1 will utilize the residual \\(SS\\) from each model, which relates to model deviance drop1(gamb.mod.fac, test = &quot;F&quot;) ## Single term deletions ## ## Model: ## gamble ~ sex_fac + status + income + verbal ## Df Sum of Sq RSS AIC F value Pr(&gt;F) ## &lt;none&gt; 21624 298.18 ## sex_fac 1 3735.8 25360 303.67 7.2561 0.01011 * ## status 1 17.8 21642 296.21 0.0345 0.85349 ## income 1 12056.2 33680 317.00 23.4169 1.792e-05 *** ## verbal 1 955.7 22580 298.21 1.8563 0.18031 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 But let’s see the residual plots again. This time we’ll go in order 5.1.1 Residuals v. Fitted Values First, we have the residuals v. the fitted values. For OLS, the residuals are the raw residuals That is: \\[ \\text{resid: } y_{i} - \\hat{y}_{i}\\\\ \\text{fitted: } \\hat{y}_{i} = 22.56 - 22.12(Female_{i}) + 0.05(Status_{i}) + 4.96(Income_{i}) - 2.96(Verbal_{i}) \\] plot(gamb.mod.fac, which = 1) We see some evidence that the variance of the residuals changes as predicted values increase. This violates the homoskedasticity assumption, and affects standard errors 5.1.2 Normalty of residuals This assumption is only relevant for GLMs with the Gaussian random component. We don’t expect normally distributed residuals for Poisson, Logistic, etc. Also, with larger datasets, if the normality is less crucial as inference can still be robust. Like with other plots, it takes experience to interpret these and know what to do about them. plot(gamb.mod.fac, which = 2) We can see that for most responses, things look good, but cases 24, 36, and 39 appear again! 5.1.3 Leverage Let’s take a closer look at leverage. We do so using the so-called “hat matrix” (because it puts a “hat” on \\(y\\)): First, define fitted values using matrix notation: \\[ \\hat{y} = \\textbf{X}\\hat{\\beta} \\\\ = \\textbf{X}(\\textbf{X}^{T}\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y} \\\\ = \\textbf{H}\\textbf{y} \\] The first part is \\(\\textbf{H}\\) and the diagonal values \\(h_{i} = \\textbf{H}_{ii}\\) are the leverages We define the variance of the residuals: \\(\\text{var}(\\hat{\\epsilon}_{i}) = \\sigma^{2}(1-h_{i})\\) So large values of \\(h_{i}\\) exert leverage since they tend to make the variance small and subsequently to “force” the fit of the regression line close to that particular \\(y_{i}\\) 5.1.4 Influence It’s hard to look at the leverages so Cook defined a statistic using standardized residuals, \\(r_i = \\epsilon / \\text{SE}(\\epsilon)\\) that we’ll call Cook’s Distance: \\[ D_{i}= \\frac{(\\hat{y}-\\hat{y}_{(i)})^{T}(\\hat{y}-\\hat{y}_{(i)})}{p\\sigma^{2}} = \\frac{1}{p}r^{2}_{i}\\frac{h_{i}}{1-h_{i}} \\] It basically represents a scaled change of fit when a particular case \\(y_{(i)}\\) is dropped from the dataset. Below we have the leverages and standardized residuals. Cook’s distances are shown as contour lines. plot(gamb.mod.fac, which = 5) There’s that case 24 again! Let’s check it out more closely along with a couple of others. teengamb[cooks.distance(gamb.mod.fac) &gt; .1, ] ## sex status income verbal gamble sex_fac ## 24 0 27 10 4 156 Male ## 39 0 51 10 6 6 Male predict(gamb.mod.fac, newdata = teengamb[c(24,39), ]) ## 24 39 ## 61.74778 57.08241 So we see that with case 24, we’re actually under predicting, and with case 39 we’re way over. These are both males with the same income level and similar verbal scores, but of different statuses. What we do with these cases varies in different situations. This is a real dataset and these are plausible values of the covariates, so we would probably leave it alone. However, this is also a small dataset, so we might like to see how things shake out in a follow-up study. 5.2 Model Checking and Diagnostics in Logistic Regression When we move to the logistic regression environment, we now have more complicated residuals, but the process is very similar, with a few twists. Let’s look at the birthweight data that you analyzed for HW 3 ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... We’ll go ahead and model presence of low birthweight using the mother’s race, smoking status, mother’s weight at last menstrual period (lwt) and the number of physician visits during the first trimester (ftv) # full model mod3 &lt;- glm(low ~ race_fac + smoke_fac + lwt + ftv, data = birthwt, family = binomial) summary(mod3) ## ## Call: ## glm(formula = low ~ race_fac + smoke_fac + lwt + ftv, family = binomial, ## data = birthwt) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.103559 0.886013 -0.117 0.90695 ## race_facblack 1.284937 0.511773 2.511 0.01205 * ## race_facother 0.963552 0.415185 2.321 0.02030 * ## smoke_facsmoker 1.055738 0.379667 2.781 0.00542 ** ## lwt -0.013106 0.006392 -2.051 0.04031 * ## ftv -0.025504 0.161963 -0.157 0.87488 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 234.67 on 188 degrees of freedom ## Residual deviance: 214.99 on 183 degrees of freedom ## AIC: 226.99 ## ## Number of Fisher Scoring iterations: 4 ## odds ratios and 95% CI&#39;s (OR_CI &lt;- cbind(&quot;OR&quot; = exp(coef(mod3)), exp(confint(mod3)))) ## Waiting for profiling to be done... ## OR 2.5 % 97.5 % ## (Intercept) 0.9016227 0.1660422 5.4902084 ## race_facblack 3.6144402 1.3289453 10.0493156 ## race_facother 2.6209902 1.1754754 6.0409987 ## smoke_facsmoker 2.8740954 1.3837707 6.1837182 ## lwt 0.9869793 0.9739259 0.9988046 ## ftv 0.9748189 0.7003830 1.3293647 drop1(mod3, test = &quot;Chi&quot;) ## Single term deletions ## ## Model: ## low ~ race_fac + smoke_fac + lwt + ftv ## Df Deviance AIC LRT Pr(&gt;Chi) ## &lt;none&gt; 214.99 226.99 ## race_fac 2 224.09 232.09 9.1004 0.010565 * ## smoke_fac 1 223.08 233.08 8.0891 0.004453 ** ## lwt 1 219.68 229.68 4.6926 0.030293 * ## ftv 1 215.01 225.01 0.0249 0.874558 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This is a large enough dataset that we might be able to use the residual deviance in Pearson’s \\(X^{2}\\) but that’s not usually done in logistic regression. Instead, we’ll compute two fit statistics before looking at the diagnostic plots. Note, we already produced an ROC plot as well as computing the area under the curve, which also help with testing model fit, so we’ll skip those here. 5.2.1 Hosmer-Lemeshow Test Hosmer and Lemeshow (e.g., 2013) devised a method for checking the fit of a logistic regression model by a Chi-square like procedure of examining how close predicted probabilities are to the observations in the dataset: \\[ X^{2}_{HL} = \\sum_{j=1}^{J}\\frac{(y_{j}-m_{j}\\hat{p}_{j})}{m_{j}\\hat{p}_{j}(1-\\hat{p})} \\] It has an approximate \\(\\chi^2\\) distribution with \\(J - 1\\) degrees of freedom. One issue is choosing the bin size. Many programs default to \\(J = 10\\). We’ll use the hoslem function from the y &lt;- mod3$y # the y-values y_hat &lt;- mod3$fitted.values # the predicted probabilities (HL_test &lt;- ResourceSelection::hoslem.test(x = y, y = y_hat)) ## ## Hosmer and Lemeshow goodness of fit (GOF) test ## ## data: y, y_hat ## X-squared = 7.8931, df = 8, p-value = 0.444 We might also choose to make a calibration plot, which is a little beyond the scope of the course, but the test suggest that we’d find our predictions in line with the observed proportion of “ones” at different levels of predicted values. 5.2.2 Nagelkerke’s pseudo R-squared Another measure that approaches fit, but from a different perspective is the Nagelkerke \\(R^{2}\\) We have the equation in our older notes, so we’ll just point out that it is a function of the likelihoods of our model and a null model, and can be computed using the model deviances. It will never be as high as in ordinary linear regression due to the nature of binary data, but it is helpful for comparing different logistic models. (1-exp((mod3$deviance - mod3$null.deviance)/189)) / (1-exp(-mod3$null.deviance/189)) ## [1] 0.1390815 5.2.3 Residuals and leverages Raw residuals are not as helpful in logistic regression, since they can only take one of two values for any fixed set of predictor values. plot(mod3, which = 1) Deviance residuals can be plotted, but they require a binned plot, which is not ready made, and requires some coding. See p. 36-37 in Faraway for more. Those plots need not have mean of zero for residuals, but we would like to see constant variance. We can, however, produce a kind of QQ plot for the leverage values. We’ll use the halfnorm function from faraway to plot the leverages and pick out any extreme values: halfnorm(hatvalues(mod3)) We see that case 68 has quite a lot of leverage, and for comparison, we’ll also look at case 167 birthwt[c(&quot;68&quot;,&quot;167&quot;), c(&quot;low&quot;, &quot;race_fac&quot;,&quot;smoke_fac&quot;,&quot;lwt&quot;,&quot;ftv&quot;)] ## low race_fac smoke_fac lwt ftv ## 68 1 white smoker 120 3 ## 167 0 white smoker 135 0 predict(mod3, newdata = birthwt[c(&quot;68&quot;,&quot;167&quot;), c(&quot;low&quot;, &quot;race_fac&quot;,&quot;smoke_fac&quot;,&quot;lwt&quot;,&quot;ftv&quot;)], &quot;response&quot;) ## 68 167 ## 0.3324594 0.3063656 summary(birthwt$ftv) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.0000 0.0000 0.7937 1.0000 6.0000 We see that the median number of first trimester visits is 0 but that case 68 had 3. The other values aren’t so extreme. The two cases have similar predicted probabilities, however, so it’s not clear what’s going on. Either way, the calibration may be a bit off for folks with higher numbers of ftv 5.3 Summary Regression diagonistics are part of “model criticism” where we try to figure out if our model is too wrong or bad to be of any use. We hope to find that it will be good enough and-or that perhaps there are ways to improve it. This process is very straightforward with ordinary linear regression, but in generalized linear modeling, specialized procedures exist for the discrete outcomes models We’ll return to these diagonstic procedures when we start to fit random-effects and fixed-effects models "],["introducing-mixed-models-and-the-lme4-package.html", "6 Introducing mixed-models and the lme4 package 6.1 Options in R 6.2 A possible workflow 6.3 Model 1: one-way random-effects ANOVA using REML 6.4 Quasi-ANOVA estimator 6.5 Bootstrapped confidence intervals 6.6 Linear mixed-effects", " 6 Introducing mixed-models and the lme4 package This tutorial covers very basic lme4 syntax as an introduction to random effects. There are some great resources on the web about the syntax as well as the how to distinguish crossed and nested effects using lme4. You can find them here: Ben Bolker’s FAQ site Cross Validated answer on crossed v. nested 6.1 Options in R There are several options for including random effects in linear models using R. This is only a partial list: nlme: earliest package made for mixed-effects models. Includes the Highschool and Beyond dataset that we will use starting next week lme4: the successor to nlme written by many of the same people. It allows for more complex modeling as well as improved speed. this is the package we will use glmmTMB: more options for generalized linear mixed models brms: Bayesian approach with a back-end to rstan 6.1.1 Why lme4? For several years lme4 has been the most popular option, probably due to its ease of use, good performance with a variety of data sizes and complexity of modeling. It also has good default settings. We will learn that there are many things to be aware of lurking behind the defaults, and that, if you read Ch. 10 in Faraway, inferences using mixed-effects models are not straightforward. This will be a central topic for subsequent weeks. For now, we are interested just in getting used to using this package and what typical code will look like. 6.2 A possible workflow This tutorial will focus on 3 things: Demonstration of lme4::lmer contrasted with aov() and lm() Walk through of the output from simple random and mixed-effects models Tour of the methods that operate on the model object (e.g., ranef,predict,residuals, etc.) 6.2.1 High School and Beyond Starting next week, we’ll be using a classic data set, made “famous” by Raudenbush and Bryk in their book. Information about the entire set of studies can be found here and here. The data set we will use is a subset of data from the early 1980’s. The outcome is a student’s math achievement score measured using standardized testing, and scored on a logit scale common in testing and item-response theory. This data set forms the core of the examples in the Raudenbush and Bryk book that we’ll use over the next 4 weeks. We’ll have much more to say about it next week and the week after. This week, we are only interested in a student’s math score and the fact that students are naturally clustered in \\(N = 160\\) schools. We’ll later learn that some of these schools are public schools and the rest are private, Catholic schools. As an illustration of the distinction between ordinary linear modeling and linear mixed modeling, we’ll also use a student’s socioeconomic status as a predictor of math achievement. This data set is available via the nlme package as two separate data sets, one at the student level (MathAchieve) and the other at the school level (MathAchSchool). In subsequent weeks, I’ll provide an RData file that will load this directly. Here’s how to construct the data yourself. Note, you will need to install nlme and dplyr. ## load the libraries library(&quot;nlme&quot;) library(&quot;dplyr&quot;) ## ## Attaching package: &#39;dplyr&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## collapse ## The following object is masked from &#39;package:MASS&#39;: ## ## select ## The following object is masked from &#39;package:car&#39;: ## ## recode ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union ## MathAchieve and MathAchSchool are datasets in the nlme package # ?MathAchieve # ?MathAchSchool # Make the school-level mean(SES) variable for later use MathAchieve %&gt;% group_by(School) %&gt;% summarize(mean.ses = mean(SES)) -&gt; Temp Temp &lt;- merge(MathAchSchool, Temp, by=&quot;School&quot;) # brief(Temp) # Merge the data to get the single file HSB &lt;- merge(Temp[, c(&quot;School&quot;, &quot;Sector&quot;, &quot;mean.ses&quot;,&quot;Size&quot;,&quot;HIMINTY&quot;)], MathAchieve[, c(&quot;School&quot;,&quot;Sex&quot;,&quot;SES&quot;,&quot;MathAch&quot;,&quot;Minority&quot;)], by=&quot;School&quot;) names(HSB) &lt;- tolower(names(HSB)) # make a level 1 variables that is group-mean (school) centered for SES of the student HSB$cses &lt;- with(HSB, ses - mean.ses) # Define levels of Sector HSB$sector &lt;- factor(HSB$sector, levels=c(&quot;Public&quot;, &quot;Catholic&quot;)) Here’s a quick look at the overall structure of the data. ## &#39;data.frame&#39;: 7185 obs. of 10 variables: ## $ school : Factor w/ 160 levels &quot;1224&quot;,&quot;1288&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ sector : Factor w/ 2 levels &quot;Public&quot;,&quot;Catholic&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ mean.ses: num -0.434 -0.434 -0.434 -0.434 -0.434 ... ## $ size : num 842 842 842 842 842 842 842 842 842 842 ... ## $ himinty : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 2 2 1 1 1 1 2 1 2 1 ... ## $ ses : num -1.528 -0.588 -0.528 -0.668 -0.158 ... ## $ mathach : num 5.88 19.71 20.35 8.78 17.9 ... ## $ minority: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ cses : num -1.0936 -0.1536 -0.0936 -0.2336 0.2764 ... The grouping factor is school and the outcome is mathach so a random-effects ANOVA would be specified (using this week’s notation) as: \\[ Y_{ij} = \\mu + \\alpha_{j} + \\epsilon_{ij} \\] where \\(Y_{ij}\\) is the \\(i^{th}\\) student’s math achievement score in school \\(j\\) and \\(\\mu\\) is the grand mean math achievement across students and schools. The \\(\\alpha_{j}\\)’s are the school random effects and the \\(\\epsilon_{ij}\\)’s are the student-level random errors This is a classic nested design as a student exists in one and only one school Let’s look at the ANOVA estimators, the REML estimates, and the ML estimates for two models: A one-way anova as specified above A mixed-effects model with student SES (centered within the school as cses) as a single predictor 6.3 Model 1: one-way random-effects ANOVA using REML To run this code, you will first need to install lme4 using either install.packages or using the Packages tab. Each time you use lme4 you will need to load it library(lme4) # load the package ## Loading required package: Matrix ## ## Attaching package: &#39;lme4&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## lmList mod1_re &lt;- lmer(mathach ~ (1|school), data = HSB) # fit the model The syntax is very simple, and we’ll go through more complex versions in the coming weeks. In lme4 random effects are specified in parentheses using the mid-bar | So (1|school) means fit a random effect (intercept) of school (allow the mean outcome to vary across schools). Note, if we had a crossed design, with teacher as a second factor, we’d have: (1|school) + (1|teacher) for schools crossed with teachers Additional levels of nesting use \\: (1|school/teacher) or explicitly the : as in(1|school) + (1|school:teacher) for teachers nested in schools The full output of this model is somewhat boring, but includes important information: Estimates of \\(\\hat{\\sigma}^{2}_{\\alpha}\\) and \\(\\hat{\\sigma}^{2}_{\\epsilon}\\) Estimates of the grand mean (only works for a model with no predictors) Note, the default for lmer is to use REML. This is what we want currently as it will give us the best estimate of the variance of the random effects. summary(mod1_re) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ (1 | school) ## Data: HSB ## ## REML criterion at convergence: 47116.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0631 -0.7539 0.0267 0.7606 2.7426 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 8.614 2.935 ## Residual 39.148 6.257 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6370 0.2444 51.71 Note also, that the estimate of the intercept is not the average mathach across the students, as that ignores the grouping: mean(HSB$mathach) ## [1] 12.74785 Instead, we’ll learn next week, that with unequal group sizes \\(n_j\\), the intercept will be a precision-weighted average of the group means. Essentially, groups with smaller variance (greater precision) contribute more to the overall estimate of the intercept. This is in contrast with other weighting techniques that just utilize sample-size. 6.4 Quasi-ANOVA estimator If we use aov() to estimate the variance, we won’t get what we: the ANOVA estimator does not work with unequal group size. amod &lt;- aov(mathach ~ Error(school), data = HSB) summary(amod) ## ## Error: school ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 159 64907 408.2 ## ## Error: Within ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 7025 274970 39.14 6.4.1 (unrestricted) Maximum Likelihood We’ll learn in later weeks that comparing models with different fixed effects must be done with REML = TRUE (ie., using ML or “unrestricted” maximum likelihood estimation). For large data sets, the differences are very slight. For example: mod1_ml &lt;- lmer(mathach ~ (1|school), data = HSB, REML = FALSE) summary(mod1_ml) ## Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] ## Formula: mathach ~ (1 | school) ## Data: HSB ## ## AIC BIC logLik -2*log(L) df.resid ## 47121.8 47142.4 -23557.9 47115.8 7182 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.06262 -0.75365 0.02676 0.76070 2.74184 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 8.553 2.925 ## Residual 39.148 6.257 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6371 0.2436 51.87 Note, the school-level variance is estimated to be smaller (\\(8.55\\) v. \\(8.64\\)) but the residual is the same. Also note that we now have AIC, BIC, a log likelihood, deviance, and residual df. This is because we have a full ML model. We do not get that information from REML. 6.4.2 Intraclass correlation One of the main outcomes of the one-way random effects ANOVA, or unconditional model is the ability to compute the intraclass correlation. Recall that we can compute it using the estimates from unconditional model (we should use the REML estimates): \\[ ICC = \\frac{\\hat{\\sigma}^{2}_{\\alpha}}{\\hat{\\sigma}^{2}_{\\alpha} + \\hat{\\sigma}^{2}_{\\epsilon}} \\] From our output, we see that \\(\\hat{\\sigma}^{2}_{\\alpha} = 8.614\\) and \\(\\hat{\\sigma}^{2}_{\\epsilon} = 39.148\\). So the unconditional intraclass correlation is: \\[ \\begin{aligned} ICC &amp; = \\frac{\\hat{\\sigma}^{2}_{\\alpha}}{\\hat{\\sigma}^{2}_{\\alpha} + \\hat{\\sigma}^{2}_{\\epsilon}} \\\\ &amp; = \\frac{8.614}{8.614 +39.148}\\\\ &amp; = 0.18 \\end{aligned} \\] Remember, this is an estimate of the correlation between two randomly selected students’ math scores from within the same school. 6.5 Bootstrapped confidence intervals We’ll talk more about the complexity of inference procedures starting next week. The short version is that bootstrapped confidence intervals are probably the best, though other methods also work well. Either way, bootstrapped CI’s are great for simple models. They may take a very long time to compute for complex models, however. confint(mod1_re, method = &quot;boot&quot;) ## Computing bootstrap confidence intervals ... ## 2.5 % 97.5 % ## .sig01 2.594500 3.354701 ## .sigma 6.152638 6.361720 ## (Intercept) 12.158422 13.085090 In the above, .sig01 is the standard deviation of the random effects of school (\\(\\sigma_{\\alpha}\\)). If you want variances, you must square the end points. However, standard deviation is more interpretable. Also, .sigma is the CI for the residual standard deviation. The random effects CI’s will always be on top of the confint output. Fixed effects will be listed next. Here, we only have one fixed effect, the overall grand mean \\(\\mu\\) which we will learn can also be parameterized as a regression intercept \\(\\gamma_{00}\\). We’ll also discuss the assumption of normality of the random effects next week. The intercept and standard deviation of the random effects together give us information about the unconditional distribution of mean math scores: \\(\\hat{\\mu}_{..} = 12.64\\), \\(95\\% \\text{ CI } (12.16, 13.14)\\) \\(\\text{SD} = 2.94\\), \\(95\\% \\text{ CI } (2.55, 3.26)\\) We can see in the plot below, that theoretically, most (\\(\\sim 68 \\%\\)) of the schools have mean math achievement between \\(\\sim 9.70\\) and \\(\\sim 15.50\\) 6.6 Linear mixed-effects For illustration, we’ll fit a model where a student’s math achievement is a function of their group-centered SES (cses). We’ll learn some different terminology for this in the next two weeks, but here, we’re going to contrast the fixed-effect estimate from lmer with that from lm. Here’s how we include a predictor in lmer: mod2_re &lt;- lmer(mathach ~ cses + (1|school), data = HSB) summary(mod2_re) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ cses + (1 | school) ## Data: HSB ## ## REML criterion at convergence: 46724 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0969 -0.7322 0.0194 0.7572 2.9147 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 8.672 2.945 ## Residual 37.010 6.084 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6361 0.2445 51.68 ## cses 2.1912 0.1087 20.17 ## ## Correlation of Fixed Effects: ## (Intr) ## cses 0.000 Now, with lm() we ignore the fact that students are grouped mod2_lm &lt;- lm(mathach ~ cses, data = HSB) summary(mod2_lm) ## ## Call: ## lm(formula = mathach ~ cses, data = HSB) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.8660 -5.1165 0.2966 5.3880 14.8705 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.74785 0.07933 160.69 &lt;2e-16 *** ## cses 2.19117 0.12010 18.24 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.725 on 7183 degrees of freedom ## Multiple R-squared: 0.04429, Adjusted R-squared: 0.04415 ## F-statistic: 332.8 on 1 and 7183 DF, p-value: &lt; 2.2e-16 Note that the cses effects are similar, but with different standard errors, and that the intercept estimate is essentially the sample average math achievement in lm, ignoring the grouping by school. We also do not get any information about variability in the school means. 6.6.1 Random effects estimates Let’s go back to the first model and see some of the random effects estimates: ran &lt;- ranef(mod1_re) ran$school$`(Intercept)`[1:10] ## [1] -2.6639348 0.7394098 -4.5684656 2.9485171 0.4939461 -1.2425116 -2.5023497 6.2682432 4.9621083 ## [10] 3.6965749 These are simply the amount by which school \\(J\\) deviates from the estimated mean of \\(12.64\\). We can also get the estimated school means. Note, these are NOT the actual means of the scores within each school. In later weeks, we’ll discuss that these are Empirical Bayes estimates, which are shrinkage estimates. When a school’s mean is not precisely captured in the sample, the estimate shrinks toward the grand mean (\\(12.64\\)). When a school’s estimate is precise, the estimated mean is less influenced by the grand mean. In this way, estimates of smaller or less precisely estimated schools take information from the rest of the distribution. cof &lt;- coef(mod1_re) cof$school$`(Intercept)`[1:10] ## [1] 9.973039 13.376384 8.068508 15.585491 13.130920 11.394462 10.134624 18.905217 17.599082 ## [10] 16.333549 As we see, the estimated mean math achievement in school 1308 is \\(15.59\\) while the actual sample average is: mean(HSB$mathach[HSB$school == &quot;1308&quot;]) ## [1] 16.2555 Summary: We have now started to use lmer the main function for fitting mixed-effects models with REML (and with ML) We’ve seen some simple output and computed the intraclass correlation We’ve discussed a bit about the distribution of random effects and their estimates Next week, we’ll pull this together in the context of an actual research question. "],["mixed-models-as-hierarchical-linear-models.html", "7 Mixed models as Hierarchical Linear Models 7.1 High School and Beyond Data 7.2 Model 1: unconditional model 7.3 Means as outcomes: Binary Predictor 7.4 Multiple hierarchical linear regression 7.5 Plotting predictor effects", " 7 Mixed models as Hierarchical Linear Models This week, we review the code introduced last week in the context of hierarchical models. We will extend last week’s examples to include predictors at the school level. Note: we will not talk about inferences this week (p-values, confidence intervals, likelihood-ratio tests). We’ll defer our discussion to next week. You can, however, test hypotheses about fixed effects parameters using confint(model, method = \"boot\") Computing p-values and doing inference in general with mixed models is difficult, and we’ll discuss it next week, but a good place for information on the issues is the GLMM FAQ 7.1 High School and Beyond Data As we discussed last week, we’ll be using the High School and Beyond Dataset that appears in the Raudenbush and Bryk book. Our objective will be to reproduce the results they include in Chapter 4. This week, we’ll be interested in a few predictors: Mean SES - this is the average of the socioeconomic status scores for students within a school, it is a school-level variable School Sector - this is a binary variable indicating if a school is a Catholic School (comparison group is Public) Group-mean centered student SES - this is the deviation of a student’s socioeconomic status score from the mean for the school (Mean SES). This is a student-level variable More can be added, and I encourage you to try some out for yourselves. First, let’s load the data set. I have already produced it using the code from last week, and saved it as a .rda file on github. HSB &lt;- readRDS(file = url(&quot;https://rickhass.github.io/HSB_data.rds&quot;)) 7.2 Model 1: unconditional model We covered this last week, but just to illustrate with the new symbols The grouping factor is school and the outcome is mathach so a random-effects ANOVA would be specified (using this week’s notation) as: \\[ Y_{ij} = \\mu + \\alpha_{j} + \\epsilon_{ij} \\rightarrow Y_{ij} = \\gamma_{00} + u_{0j} + r_{ij} \\] where, now, \\(Y_{ij}\\) is the \\(i^{th}\\) student’s math achievement score in school \\(j\\) and \\(\\gamma_{00}\\) is the grand mean math achievement across students and schools. The \\(u_{j}\\)’s are the school random effects and the \\(r_{ij}\\)’s are the student-level random errors. We obtain \\(\\gamma_{00}\\) from the hierarchical version: Student level: \\(Y_{ij} = \\beta_{0j} + r_{ij}\\) School level: \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\) library(lme4) # load the package u_mod &lt;- lmer(mathach ~ (1|school), data = HSB) # fit the model Remember, with a nested, two-level design, typing (1|school) means fit a random effect (intercept) of school (allow the mean outcome to vary across schools). In our output, we get estimates of three things: The variance (\\(\\tau_{00}\\)) and standard deviation (\\(\\sqrt{\\tau_{00}}\\)) of the random effects of schools. This is in the top of the Random effects table labeled school, (Intercept) The residual variance, also known as level-1 variance, \\(\\sigma^{2}\\) The estimated grand mean, or model (Intercept), \\(\\gamma_{00}\\) We also see a summary of deviance residuals at level 1 (more on these in subsequent weeks). summary(u_mod) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ (1 | school) ## Data: HSB ## ## REML criterion at convergence: 47116.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0631 -0.7539 0.0267 0.7606 2.7426 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 8.614 2.935 ## Residual 39.148 6.257 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6370 0.2444 51.71 7.2.1 Unconditional ICC As mentioned last week, the unconditional model is somewhat boring, but does allow us to examine the variability of the random effects and compute the intraclass correlation. Again, our symbols change slightly: \\[ ICC = \\frac{\\hat{\\sigma}^{2}_{\\alpha}}{\\hat{\\sigma}^{2}_{\\alpha} + \\hat{\\sigma}^{2}_{\\epsilon}} \\rightarrow \\frac{\\tau_{00}}{\\tau_{00} + \\hat{\\sigma}^{2}} \\] We just read these values from the Variance column in the output and compute: 8.614 / (8.614 + 39.148) ## [1] 0.1803526 So the intraclass correlation is \\(ICC = 0.18\\) for these data. About \\(18\\%\\) of the variation in math achievement is between the schools. That is, there is a decent amount of variability in mean math achievement across the schools. This is a nice alternative interpretation of the ICC in nested designs. We can only conclude this from the unconditional model. We’ll see next week what we can do with explained variation as we add predictors. 7.3 Means as outcomes: Binary Predictor The second model we covered this week was the so-called Means as Outcomes Model. We’re trying to predict the group-level mean from group-level predictors. We’ll start with a binary predictor: Sector = Catholic Level-1: Student Level: \\(y_{ij} = \\beta_{0j} + r_{ij}\\) same as before Level-2: School level: \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}\\mathrm{Catholic}+ u_{0j}\\) \\[ \\mathrm{Math}_{ij} = \\gamma_{00} + \\gamma_{01}\\mathrm{Catholic}+ u_{0j}+ r_{ij} \\] \\(\\gamma_{00}\\): The mean math achievement of in catholic schools \\(\\gamma_{01}\\): The difference between mean math achievement scores for Catholic v. Public schools \\(\\tau_{00}\\): the variance of the \\(u_{0j}\\)’s, which is now a conditional random effect - what remains to be explained about a school’s mean math achievement beyond what sector tells us \\(\\sigma^{2}\\): the variance of the person-level residuals \\(r_{ij}\\) MAO_mod &lt;- lmer(mathach ~ sector + (1|school), data = HSB) summary(MAO_mod) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ sector + (1 | school) ## Data: HSB ## ## REML criterion at convergence: 47080.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0130 -0.7523 0.0253 0.7602 2.7472 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 6.677 2.584 ## Residual 39.151 6.257 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 11.3930 0.2928 38.907 ## sectorCatholic 2.8049 0.4391 6.388 ## ## Correlation of Fixed Effects: ## (Intr) ## sectorCthlc -0.667 Note, we now see a smaller number for \\(\\tau_{00}\\) as we’ve “explained” some of the variation between the schools: mean math achievement is estimated to be \\(2.80\\) points higher for a catholic schools compared with public schools. This shrinks the variance of the conditional random effects \\(u_{0j}\\) and we can quantify this by a quasi “variance explained” metric: \\[ \\begin{aligned} \\text{Var explained}_{\\text{L2}}: &amp; \\frac{\\tau_{unc} - \\tau_{const}}{\\tau_{unc}}\\\\ = &amp;\\frac{8.614- 6.677}{8.614}\\\\ = &amp; \\frac{1.937}{8.614}\\\\ = &amp; 0.22 \\end{aligned} \\] So knowing the sector of a school, we have a reduction in random effects variance of \\(22 \\%\\) 7.3.1 Means as outcomes: continuous predictor The extension to continous predictors is very straightforward. Let’s trade the Sector variable for mean.ses Level-1: Student Level: \\(y_{ij} = \\beta_{0j} + r_{ij}\\) same as before Level-2: School level: \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}\\mathrm{mSES}+ u_{0j}\\) \\[ \\mathrm{Math}_{ij} = \\gamma_{00} + \\gamma_{01}\\mathrm{mSES}+ u_{0j}+ r_{ij} \\] MAO_mod2 &lt;- lmer(mathach ~ mean.ses + (1|school), data = HSB) summary(MAO_mod2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ mean.ses + (1 | school) ## Data: HSB ## ## REML criterion at convergence: 46961.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.13493 -0.75254 0.02413 0.76766 2.78515 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 2.639 1.624 ## Residual 39.157 6.258 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6846 0.1493 84.97 ## mean.ses 5.8635 0.3615 16.22 ## ## Correlation of Fixed Effects: ## (Intr) ## mean.ses 0.010 We have the same information here, but now \\(\\gamma_{01}\\) is a slope (it was before, but now it REALLY is…). So we estimate that a unit increase in a school’s mean.ses equates to a \\(5.86\\) increase in the mean math achievement. That seems like a big effect, and indeed, it’s t-value is large, but remember, SES is measured on a relatively small scale: hist(nlme::MathAchSchool$MEANSES, main = &quot;Histogram of School mean SES&quot;, xlab = &quot;Mean SES&quot;) So this result really tells that there’s about a 10-point difference in math achievement between the lowest and highest mean SES schools going from \\(-1.0 \\text{ to} +1.0\\) on SES we go up 2 units on SES, so \\(\\gamma_{01}\\times 2 = 11.73\\) There is an appreciable reduction in variance of the \\(u_{0j}\\) here too: \\[ \\frac{8.614 - 2.639}{8.614}= 0.69 \\] So we can reduce the variability of the school mean math achievement \\(69\\%\\) if we know the mean SES of the students in the school. 7.4 Multiple hierarchical linear regression As mentioned at the end of lecture, we’ll often have many predictors for our models. Let’s see what the output looks like when we fit a linear mixed model using both Sector and mean.ses. Now we have two predictors at level 2, so our model is: Level-1: Student Level: \\(y_{ij} = \\beta_{0j} + r_{ij}\\) same as before Level-2: School level: \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}\\mathrm{Catholic}+ \\gamma_{02}\\mathrm{MeanSES}+u_{0j}\\) \\[ \\mathrm{Math}_{ij} = \\gamma_{00} + \\gamma_{01}\\mathrm{Catholic}+\\gamma_{02}\\mathrm{MeanSES}+ u_{0j}+ r_{ij} \\] Everything retains the same meaning as before, and now we have a new regression coefficient \\(\\gamma_{02}\\) which gives us the sector-adjusted linear relationship between mean math achievement and mean SES for the \\(J = 160\\) schools. MAO_mod3 &lt;- lmer(mathach ~ sector + mean.ses + (1|school), data = HSB) summary(MAO_mod3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ sector + mean.ses + (1 | school) ## Data: HSB ## ## REML criterion at convergence: 46946.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.08429 -0.75039 0.02046 0.76635 2.78875 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school (Intercept) 2.314 1.521 ## Residual 39.161 6.258 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.1282 0.1992 60.887 ## sectorCatholic 1.2254 0.3058 4.008 ## mean.ses 5.3328 0.3686 14.467 ## ## Correlation of Fixed Effects: ## (Intr) sctrCt ## sectorCthlc -0.700 ## mean.ses 0.256 -0.356 In our output, we see that the inclusion of mean.ses has now reduced the effect of sector. So controlling for mean.ses we have a \\(\\gamma_{01} = 1.23\\) difference between catholic and public schools. Specifically, we might say that if we take a randomly selected catholic school and a randomly selected public school, both of which are at the same level of SES (say the overall average), we’d estimate that their mean level of math achievement scores would be about \\(1.23\\) points apart. Controlling for sector did not seem to change much about the mean.ses effect. If we assume no interaction between sector and SES, this suggests that schools with higher mean SES have higher mean math scores. 7.5 Plotting predictor effects The effects package has some nice methods for building plots of predictor effects. Essentially, this involves plotting model predictions for a levels of a predictor, holding the others constant. It requires new data, and the effects package creates these data for you. Important to note: the plots are partial or conditional effects plots (when there is more than one predictor in the model). So they’re model based, and not purely sample correlations or mean differences. You can try it yourself by installing it and running the following code: plot(effects::predictorEffect(&quot;sector&quot;, MAO_mod3)) plot(effects::predictorEffect(&quot;mean.ses&quot;, MAO_mod3)) "],["more-on-hierarchical-linear-models.html", "8 More on Hierarchical Linear Models 8.1 Overview 8.2 Random Coefficients model 8.3 Intercepts and Slopes as Outcomes 8.4 Model comparison with Likelihood Ratios: Fixed and Random 8.5 Diagnostics", " 8 More on Hierarchical Linear Models 8.1 Overview In part 1, we covered the One-way ANOVA with random effects and Means as Outcomes models from Raudenbush and Bryk. This week, we cover the remaining models with an aim to reconstruct the results from pages 75-86 in their book. This vignette makes use of some great code by Rens van de Schoot 8.1.1 Load the data We’ll continue using the HSB data set, loaded from the github repository HSB &lt;- readRDS(file = url(&quot;https://rickhass.github.io/HSB_data.rds&quot;)) 8.2 Random Coefficients model To remind you, this model is a two-level model, with a predictor at level 1 (group-centered-SES or cses in our data set), and the outcome also at level 1 (mathach). The purpose of this model is truly multilevel: you want to know about an overall average effect of a level-1 predictor across groups, but also about how variable that effect is across the groups. Here, we’re asking what is the average effect of cses on math achievement across schools, and by how much does it vary from school to school. Later, we’ll ask whether variables at the school level relate to the slope variation. Level 1: \\[ Y_{ij} = \\beta_{0j} + \\beta_{1j}(cses) + r_{ij} \\] Level 2: \\[ \\begin{aligned} \\beta_{0j} = \\gamma_{00} + u_{0j} \\\\ \\beta_{1j} = \\gamma_{11} + u_{1j} \\end{aligned} \\] 8.2.1 Visualizing the within-school slopes To get a sense of what we’re doing, let’s first visualize the mathach ~ cses relationship without respect to school. Below is an overall plot of all \\(n = 7185\\) students’ cses and math achievement scores. It looks pretty incoherent. Given the known hierarchical structure of the data, this is not surprising, so we should try to understand what’s happening within each school and between schools. However, we still see that, ignoring the clustering, there’s some degree of linear relationship between a student’s SES and his or her math achievement score. Now, let’s zoom in on a few schools and see if there are some differences in the cses relationship across them. To make it easier to see, we’ll sample \\(J = 40\\) schools and plot a regression line for each: schools &lt;- sample(HSB$school, 40) Sampledata &lt;- HSB[is.element(HSB$school,schools), ] ggplot(data = Sampledata, aes(x = cses, y = mathach, col = school, group = school)) + geom_point(size = 1, alpha = .7, position = &quot;jitter&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) + geom_smooth(method = lm, se = FALSE, linewidth = .4, alpha = .7) + # to add regression line labs(title = &quot;SES and Math Achievement in a sample of 40 schools&quot;, subtitle = &quot;The within-school regression lines&quot;) We can see that most of the lines have positive slope, but there are a few that do not! The random coefficients model focuses on two things: An overall average estimate across these regression equations \\(\\gamma_{00} =\\) weighted average of \\(\\beta_{0j}\\) the school-level regression intercepts \\(\\gamma_{10} =\\) the weighted average of \\(\\beta_{1j}\\) the school-level slopes for the cses ~ mathach relationship The estimated variability across schools in \\(\\beta_{0j}\\) and \\(\\beta_{1j}\\) Since our equations for the gammas include a random effect of each school, we can obtain variability estimates by working with these random effects \\(u_{0j}\\) and \\(u_{1j}\\) Note: we’re not attempting to “explain” why schools have different intercepts and slopes, so \\(u_{0j}\\) and \\(u_{1j}\\) for each school are simply the amount by which that school differs from the mean intercept (\\(\\gamma_{00}\\)) and mean slope (\\(\\gamma_{01}\\)), respectively. They’re essentially level-2 error terms. 8.2.2 Fitting the Random Coefficients 2-level model Substituting the leve-2 equations above into the level 1 equation with cses as the level-1 predictor, mathach as outcome, and both random intercepts (\\(\\beta_{0j}\\)) and slopes (\\(\\beta_{1j}\\)) we get: \\[ Y_{ij} = \\gamma_{00} + \\gamma_{10}(cses) + u_{0j} + u_{1j}(cses) + r_{ij} \\] So that means, our mixed-effects output should contain estimates of 2 fixed effects: \\(\\gamma_{00}\\), the weighted average intercept across schools (scaled to be the grand mean) \\(\\gamma_{10}\\), the weighted average cses-mathach slope across schools Note that we do not estimate \\(\\beta_{0j}\\) or \\(\\beta_{1j}\\) directly, but they can be computed. Generally, that’s not our goal, but we could use these estimates for data in other analyses We get estimates of the variances of 3 random effects \\(\\text{Var}(u_{0j}) = \\tau_{00}\\) \\(\\text{Var}(u_{1j}) = \\tau_{11}\\) \\(\\text{Var}(r_{ij}) = \\sigma^{2}\\) AND we have a new term, a covariance between \\(u_{0j}\\) and \\(u_{1j}\\) \\(\\text{Cov}(u_{0j},u_{1j}) = \\tau_{10}\\) Let’s now estimate our mixed-effects parameters model3 &lt;- lmer(mathach ~ cses + (cses|school), data = HSB) summary(model3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ cses + (cses | school) ## Data: HSB ## ## REML criterion at convergence: 46714.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.09680 -0.73193 0.01855 0.75386 2.89924 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## school (Intercept) 8.681 2.9464 ## cses 0.694 0.8331 0.02 ## Residual 36.700 6.0581 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6362 0.2445 51.68 ## cses 2.1932 0.1283 17.10 ## ## Correlation of Fixed Effects: ## (Intr) ## cses 0.009 For inference, we’ll use bootstrapped confidence intervals: confint(model3, method = &quot;boot&quot;) ## 2.5 % 97.5 % ## .sig01 2.5968018 3.2927604 ## .sig02 -0.3022129 0.4414194 ## .sig03 0.4346349 1.1285269 ## .sigma 5.9544060 6.1672046 ## (Intercept) 12.1208481 13.1124875 ## cses 1.9523704 2.4369979 Here’s a graph showing the difference between a hierarchical model and an OLS regression line. 8.2.3 Adding additional level-1 predictors to the random coefficients model We can add as many level-1 predictors as we like. If we want to also model the level-1 slopes for these predictors as random, we need to change how our random-effects syntax looks. It is very similar to the combined equation though: mod3a &lt;- lmer(mathach ~ cses + minority + (cses + minority | school), data =HSB) ## boundary (singular) fit: see help(&#39;isSingular&#39;) We may have a singular fit issue, but we’ll ignore it. This happens when variance components are close to zero, the boundary of the parameter space. The combined equation from the above model is: Model equation: \\[ Y_{ij} = \\gamma_{00} + \\gamma_{10}(cses) + \\gamma_{20}(minority = \\text{Yes}) + u_{0j} + u_{1j}(cses) + u_{2j}(sex) + r_{ij} \\] Here’s our results. Note the new rows in the Random Effects part of the output and how small the cses variance is. The correlation between csesslopes and the school (Intercept) is also estimated to be \\(-1.0\\) which is likely another cause of the warning. ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ cses + minority + (cses + minority | school) ## Data: HSB ## ## REML criterion at convergence: 46503.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.13665 -0.71773 0.03569 0.75813 2.98894 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## school (Intercept) 5.8580 2.4203 ## cses 0.0114 0.1068 -1.00 ## minorityYes 1.9527 1.3974 0.30 -0.30 ## Residual 35.9143 5.9929 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 13.5218 0.2134 63.35 ## cses 1.9047 0.1092 17.44 ## minorityYes -3.1596 0.2515 -12.56 ## ## Correlation of Fixed Effects: ## (Intr) cses ## cses -0.111 ## minorityYes -0.108 0.123 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) Not only do we have a new variance (\\(\\text{Var}(u_{2j}) = \\tau_{22}\\)), we have two new covariances, in fact, we have a 3 by 3 variance-covariance matrix \\(\\textbf{T}\\): \\[ \\begin{bmatrix} \\tau_{00} &amp;. &amp;. \\\\ \\tau_{10} &amp;\\tau_{11} &amp;. \\\\ \\tau_{20} &amp;\\tau_{21} &amp;\\tau_{22} \\end{bmatrix} \\] The lower triangle (including the diagonal terms) are the only unique terms here. The diagonal lists the 3 random effect variances (of the random intercept, cses slope, and sex slopes in that order). The other entries are the covariances between those 3 terms. For example, \\(\\tau_{10}\\) is the covariance between the random effect \\(u_{0j}\\) and \\(u_{1j}\\) In the output from r, we only get this lower triangle including \\(\\tau_{10}\\), \\(\\tau_{20}\\), and \\(\\tau_{21}\\). The variances are given in the variance column, along with \\(\\sigma^{2}\\) which is the variance of the level-1 residuals (\\(r_{ij}\\)) Finally, we can ask how much variance at level-1 we’ve reduced by adding minority as a level 1 predictor. We can use the CSES model as the comparison. (36.700 - 35.91) / 36.700 ## [1] 0.02152589 So despite the average slope for minority being significantly different from zero, we haven’t explained much more variance by adding it. 8.3 Intercepts and Slopes as Outcomes We now illustrate the Intercepts-and-slopes-as-outcomes model. We will fit exactly what appears in Raudenbush &amp; Bryk, Chapter 4, but note, we can include more predictors at each level if we wish. Let’s look at the hierarchical model: Level 1 \\(Y_{ij} = \\beta_{0j} + \\beta_{1j}(cses_{ij}) + r_{ij}\\) Level 2 \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}(mean.ses_{j}) + \\gamma_{02}(Sector_{j}) + u_{0j}\\) \\(\\beta_{1j} = \\gamma_{10} + \\gamma_{11}(mean.ses_{j}) + \\gamma_{12}(Sector_{j}) + u_{1j}\\) So we know we have 3 predictor variables: cses at level 1 mean.ses at level 2 Sector, which is an indicator for Catholic at level 2 8.3.1 Interactions and the ISO model The combined model for the above includes interactions. This is due to the fact that when we substitute the level 2 equation for \\(\\beta_{1j}\\) into the level 1 equation, the entire level 2 equation is multiplied by \\(cses_{ij}\\) so we have: \\[ Y_{ij} = [\\gamma_{00} + \\gamma_{01}(mean.ses_{j}) + \\gamma_{02}(Sector_{j}) + u_{0j}] + [cses \\times (\\gamma_{10} + \\gamma_{11}(mean.ses_{j}) + \\gamma_{12}(Sector_{j}) + u_{1j})] + r_{ij} \\] In the first bracket above, we have the substitution of \\(\\beta_{0j}\\) with the level-2 equation for it. Since \\(\\beta_{0j}\\) is the intercept, and not multiplied by anything, these terms just add right in. However, in the second set of brackets, we see that the equation for \\(\\beta_{1j}\\) gets multiplied by the level-1 predictor \\(cses_{ij}\\) because that’s how it’s written at level 1. Multiplying through we have \\[ Y_{ij} = [\\gamma_{00} + \\gamma_{01}(mean.ses_{j}) + \\gamma_{02}(Sector_{j}) + u_{0j}] + [(cses \\times\\gamma_{10}) + (cses \\times \\gamma_{11}(mean.ses_{j})) + (cses \\times \\gamma_{12}(Sector_{j}))+ (cses \\times u_{1j})] + r_{ij} \\] Rearranging our terms we see that the first 4 fixed effects (including the intercept) are not interactions, the next 2 are, and then we have the random part. Note that in the random part there is an interaction between \\(cses\\) and \\(u_{ij}\\) but lmer specifies this for us. \\[ Y_{ij} = \\gamma_{00} + \\gamma_{01}(mean.ses_{j}) + \\gamma_{02}(Sector_{j}) + \\gamma_{10}(cses) + \\gamma_{11}(mean.ses_{j} \\times cses) + \\gamma_{12}(Sector_{j} \\times cses)+ u_{0j} + u_{1j}(cses) + r_{ij} \\] So we insert the fixed effects into the lmer formula, and then specify random cses slopes as with the random coefficients model (cses|school) and lmer takes care of the rest. Note: You can use * or : for interaction terms, but the * is better here as it will build the necessary terms for you without duplication or omission. Using : you would need to specify each term in the equation. See below (mod4alt): # using the * operator for interactions mod4 &lt;- lmer(mathach ~ cses*mean.ses + cses*sector + (cses | school), data = HSB) # alternate specification forming interaction terms &quot;by hand&quot; with &quot;:&quot; mod4alt &lt;- lmer(mathach ~ cses + mean.ses + sector + cses:mean.ses + cses:sector + (cses|school), data = HSB) In the output, we can see that, indeed, we have the correct interaction variables in the model. Now, what do they mean? summary(mod4) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: mathach ~ cses * mean.ses + cses * sector + (cses | school) ## Data: HSB ## ## REML criterion at convergence: 46503.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.15926 -0.72319 0.01704 0.75444 2.95822 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## school (Intercept) 2.380 1.5426 ## cses 0.101 0.3179 0.39 ## Residual 36.721 6.0598 ## Number of obs: 7185, groups: school, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.1279 0.1993 60.856 ## cses 2.9450 0.1556 18.928 ## mean.ses 5.3329 0.3692 14.446 ## sectorCatholic 1.2266 0.3063 4.005 ## cses:mean.ses 1.0393 0.2989 3.477 ## cses:sectorCatholic -1.6427 0.2398 -6.851 ## ## Correlation of Fixed Effects: ## (Intr) cses men.ss sctrCt css:m. ## cses 0.075 ## mean.ses 0.256 0.019 ## sectorCthlc -0.699 -0.053 -0.356 ## cses:men.ss 0.019 0.293 0.074 -0.026 ## css:sctrCth -0.052 -0.696 -0.027 0.077 -0.351 8.3.2 Mean SES and Student SES The cses:mean.ses term in the model is positive, and has a t-value that is likely significant (3.477). This means that the student ses relation to math achievement gets more positive as the school’s average SES increases. So schools with a higher mean SES tend to have stronger student-level ses effects on math achievement. This is true because the marginal cses slope is positive, so the positive interaction term adds to the already positive slope. 8.3.3 Sector and Student SES In contrast, the cses:sectorCatholic term in the model is negative, but with a large t-value, which is also likely significant. It tells us that on average, Catholic schools have slopes that are -1.6427 less than Public schools. So the effect of student-level ses on math achievement is weaker in Public Schools, but still net positive on average. 8.3.4 Visualizing the mean SES effect To understand the interaction between mean.ses and cses, it’s helpful to split Mean SES into categories and plot the different schools. We do this using the cut command. In cut we specify breaks = 3 to just let R pick 3 equally spaced categories that we name low, average, and high ses. There are better ways to do it, but this is a nice quick and dirty method HSB$mean.ses.cat &lt;- cut(HSB$mean.ses, breaks = 3, labels = c(&#39;lowSES&#39;,&#39;averageSES&#39;,&#39;highSES&#39;)) As before, we will use the ggplot2 package to make the graphs. Consult Hadley Wickham’s e-Book Chapter 3 for an introduction to the syntax. Note, I am colorblind so I’m using this (rather ugly) colorblind palette, which is just a collection of hex codes for colors that have good contrast. cbbPalette &lt;- c(&quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;) ggplot(data = HSB, aes(x = cses, y = mathach, col = mean.ses.cat, group = school)) + #geom_point(size = 1, alpha = .7, position = &quot;jitter&quot;) + theme_bw() + scale_color_manual(values = cbbPalette[1:3]) + geom_smooth(method = lm, se = FALSE, linewidth = .4, alpha = .7) + # to add regression line labs(title = &quot;SES and Math Achievement&quot;, subtitle = &quot;The within-school regression lines colored by MeanSES&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; As can be seen, there is a clear difference in the slopes across the 3 categories of Mean SES. Note that in this way, we’re really seeing the multilevel part in action. We have 2 sample levels, one of the 7185 students, and now we can see that the 160 schools make up a second (random) sample. This random sample has systematic components, one of them being Mean SES. But instead of just looking at the relation between this level-2 systematic component and a measurement, we looking at the relationship between the level-2 systematic component and the strength of a level-1 relationship. 8.4 Model comparison with Likelihood Ratios: Fixed and Random As noted in lecture, there are some issues with p-values from likelihood ratio tests (LRTs) when we have dependent data: The LRTs for fixed effects (using REML = FALSE) can be too small and inflate Type I error The LRT for random effects (using REML = TRUE) can be too big inflating Type II error These are really only issues for model building: deciding on the fixed or random components of your final model. In the final model, you can use the bootstrapped confidence intervals 8.4.1 Example 1: LRT for fixed effects Let’s say we want a p-value for the minority effect in model 3a. We could fit a model without minority and use anova to compute the LRT \\(p\\)-value, but we’ll run into two problems Model 3a has a random slope for minority, and so there is no way to fit a model without sex as a predictor, but allowing for random slopes We may find the \\(p\\) value is too small since the \\(\\chi^{2}\\) approximation is not exact Let’s see what happens in a simpler situation: a random intercept model mod3_int &lt;- lmer(mathach ~ cses + minority + (1 | school), data =HSB) mod3_int_null &lt;- lmer(mathach ~ cses + (1 | school), data =HSB) anova(mod3_int_null, mod3_int) ## refitting model(s) with ML (instead of REML) ## Data: HSB ## Models: ## mod3_int_null: mathach ~ cses + (1 | school) ## mod3_int: mathach ~ cses + minority + (1 | school) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## mod3_int_null 4 46728 46756 -23360 46720 ## mod3_int 5 46523 46557 -23256 46513 207.34 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is a significant reduction in the deviance for the model with minority but it may not be exact. Below is the code to run a parametric bootstrapped likelihood ratio test. Note, it can take quite a while to run (and actually prints out how long in the output): pbkrtest::PBmodcomp(mod3_int, mod3_int_null) ## Bootstrap test; time: 42.41 sec; samples: 1000; extremes: 0; ## large : mathach ~ cses + minority + (1 | school) ## stat df p.value ## LRT 207.34 1 &lt; 2.2e-16 *** ## PBtest 207.34 0.000999 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 So this tells us that under a null model, there only \\(0.09 \\%\\) of samples returned LRT statistics greater than \\(207.34\\). That means that our \\(LR = 207.34\\) is NOT compatible with the null, so we should reject it: minority IS significant. 8.4.2 Example 2: LRT for random effects Similarly, we might want to test if the variance of the cses slopes is greater than 0. model3 is the full model, and we fit a reduced model and test it: mod3_null &lt;- lmer(mathach ~ cses + (1| school), data = HSB) anova(model3, mod3_null, refit = FALSE) ## Data: HSB ## Models: ## mod3_null: mathach ~ cses + (1 | school) ## model3: mathach ~ cses + (cses | school) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## mod3_null 4 46732 46760 -23362 46724 ## model3 6 46726 46768 -23357 46714 9.7617 2 0.007591 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Again, we see evidence of a significant reduction in deviance when we allow for random slopes. Again, this can be too conservative. We omit the pbkrtest results since they take quite a while and have some convergence issues due to the small scale of the variance in the \\(\\beta\\)’s for cses across schools. What you might do in this situation is reason that the risk in testing random effects is that the p-value is conservative, and since it’s still well below \\(\\alpha = 0.05\\) you might accept this result. 8.5 Diagnostics In our final section, we will quickly illustrate how to produce some residual plots to examine whether assumptions have been violated. Our aim is to simply examine the residuals to see if they indeed follow a normal distribution. We do this at both levels: Level 1: \\(r_{ij} \\sim \\mathcal{N}(0,\\sigma^{2})\\) Level 2: \\(u_{qj} \\sim \\mathcal{N}(0,\\tau_{qq})\\) We’ll look at model 3 with random intercepts and slopes for cses At level 1: ## QQ plot of the level-1 residuals qqnorm(residuals(model3)) ## Scatter plot of level-1 residuals against predictions plot(fitted(model3), residuals(model3)) At level 2, we will simply see if the distribution is Normal. We do this for both the random intercepts and random slopes ranef3 &lt;- ranef(model3) ## QQ plot of the Intercept random effects qqnorm(ranef3$school$`(Intercept)`) ## QQ plot of the Slope random effects qqnorm(ranef3$school$cses) We see in each case, we have nicely behaved results "],["using-lme4-to-fit-mlm-to-longitudinal-data.html", "9 Using lme4 to fit MLM to longitudinal data 9.1 Data description: average reaction time per day for subjects in a sleep deprivation study (Belenky et al. 2003) 9.2 Fitting the level-1 model 9.3 Model building 9.4 Model comparison and testing 9.5 Quadratic model with lmer 9.6 Summary of the sleepstudy analysis 9.7 Preview of the Blackmore data used for Assignment 7b", " 9 Using lme4 to fit MLM to longitudinal data Longitudinal data come in all shapes and sizes, but we need the data in a particular form to be able to fit models using lme4 Person period refers to a dataset where each row corresponds to an observation of a person in a particular period of time. This is also called “long” (as opposed to wide) and within the tidyverse it is referred to as tidy data. For example, we see below a printout of the first 6 rows of the sleepstudy dataset that comes with the lme4 package. As you can see, the first 6 rows all are from Subject 308. ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 9.1 Data description: average reaction time per day for subjects in a sleep deprivation study (Belenky et al. 2003) The response variable, Reaction, represents average reaction times in milliseconds (ms) on a series of tests given each Day to each Subject (Figure 1) On day \\(0\\) the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night Note how this will affect the model interpretation There are no level 2 explanatory variables in this data set, so we’re simply going to model growth as random and take a look at some examples of how to evaluate it 9.1.1 Visualization of the data There are only 18 participants in this study, which is typical of a repeated measures / longitudinal lab study in cognitive psychology and cognitive neuroscience. Let’s see whether linear trajectories seem to fit by graphing the data for each participant. The code below uses xyplot a great function for producing multiple scatterplots. What do you see in this plot? What seems to be the common theme across subjects in terms of the relationship between day in the study (number of days with sleep deprivation) and Reaction time? xyplot(Reaction ~ Days | Subject, data = sleepstudy, panel=function(x, y){ panel.points(x, y) }) 9.2 Fitting the level-1 model Theory and experience suggest that as people become more cumulatively sleep deprived, cognitive functioning should suffer. The questions that we can answer with MLM are as follows: Does a model with only linear growth (change) fit better than a model with both linear and quadratic growth? Is there variance in the intercepts? Is there variance in the slopes? We should answer question 1 first, since there will be more than one “slope” if we fit a model with quadratic growth. 9.2.1 Model Equations We’ll start with a random intercept model first, so that we can test whether linear slopes should be random using a comparison test. Level 1: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}(a_{ti}-L) + e_{ij} \\] Level 2: \\[ \\pi_{0i} = \\beta_{00} + r_{0i} \\] \\[ \\pi_{1i} = \\beta_{10} \\] Combined model: \\[ Y_{ti} = \\beta_{00} + \\beta_{10}(a_{ti}-L) + r_{0i} +e_{ij} \\] In the equation \\(L\\) stands for “lag” and will be 0 to start. That means that we can just use the raw \\(a\\) variable which is just Days in our example as the time is measured in days since full sleep, starting with zero. Remember, this coding for time has an effect on the intercept variability. In the models we run today, the intercept variance will be the variance across individuals in their reaction time on the first day of the study (with full sleep). Below, and for HW we’ll see how changing this “zero point” or “center” of the data changes the intercept variance estimate when we allow different slopes. 9.3 Model building We use the lmer function exactly as before to fit the intercepts and slopes as outcomes models with cross-sectional data. However, we’ll proceed in two steps this time: Fit the linear growth model as described above – without a random slope and examine: The variance of the intercepts as \\(\\text{Var}(r_{0i}) = \\tau_{00}\\) The coefficient of the linear time (Days) variable Fit a random slopes model and compare to the first randIntMod &lt;- lmer(Reaction ~ Days + (1|Subject), data = sleepstudy) summary(randIntMod) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (1 | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1786.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2257 -0.5529 0.0109 0.5188 4.2506 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Subject (Intercept) 1378.2 37.12 ## Residual 960.5 30.99 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.4051 9.7467 25.79 ## Days 10.4673 0.8042 13.02 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.371 What we see above is that \\(\\tau_{00}\\) which is the only variance component at level 2 (the variance of the \\(r_{0i}\\)’s) is 1378.2. That’s a large number because we’re measuring reaction time in milliseconds. The Std.Dev. column shows us that on average, the participants’ reaction time differs from the common intercept \\(\\beta_{00} = 251.41\\) by about 37.12 milliseconds. 9.4 Model comparison and testing Remember, significance testing with multilevel models can be tricky. This data set is actually balanced, so we could use an ANOVA based test, but let’s explore the options we’ve reviewed 9.4.1 Option 1: using confidence intervals Since we might suspect that we need the linear growth term, testing it’s “significance” might be most easily accomplished with the bootstrapping method: confint(randIntMod, method = &quot;boot&quot;) ## 2.5 % 97.5 % ## .sig01 24.242737 48.89273 ## .sigma 27.722382 34.27304 ## (Intercept) 233.755861 268.33898 ## Days 8.876771 11.96578 So we see that a parametric bootstrap \\(95\\%\\) CI for the linear days effect is \\((8.80, 12.03)\\) We could also use any number of the “fixes” in the lmerTest or pbkrtest packages to get a p-value 9.4.1.1 Random slopes More importantly, we need to determine whether to allow slopes to randomly vary. Again, it might be that we do so by design, but if we were building the model from the ground up, we could test whether \\(\\tau_{10} = 0\\) with a model comparison test. First, we fit the random slopes model to compare with the previous one. Changing the model to allow slopes to vary changes the equation for \\(\\pi_{1i}\\) to \\[ \\pi_{1i} = \\beta_{10} + r_{1i} \\] The combined model thus is: \\[ Y_{ti} = \\beta_{00} + \\beta_{10}(a_{ti}-L) + r_{0i} +r_{1i}(a_{ti}-L) +e_{ij} \\] This means that we’re adding 2 new variance components the \\(\\text{Var}(r_{1i}) = \\tau_{10}\\) and the \\(\\text{Cov}(r_{0i},r_{1i}) = \\tau_{01}\\) 9.4.2 Tests As an exercise, let’s see how things differ between the ordinary likelihood ratio test and a bootstrap version randSlope &lt;- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) # ordinary LRT anova(randSlope, randIntMod, refit = FALSE) ## Data: sleepstudy ## Models: ## randIntMod: Reaction ~ Days + (1 | Subject) ## randSlope: Reaction ~ Days + (Days | Subject) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## randIntMod 4 1794.5 1807.2 -893.23 1786.5 ## randSlope 6 1755.6 1774.8 -871.81 1743.6 42.837 2 4.99e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 With the ordinary LRT we see that the random slopes model has a lower AIC, BIC and deviance. The change in deviance is significant with a \\(\\chi^{2}(2) = 42.14, p &lt; .001\\). These results favor the model with both random intercepts and random slopes. Now let’s see if this holds up with a bootstrap test pbkrtest::PBmodcomp(randSlope, randIntMod) ## Bootstrap test; time: 13.96 sec; samples: 1000; extremes: 0; ## large : Reaction ~ Days + (Days | Subject) ## stat df p.value ## LRT 42.139 2 7.072e-10 *** ## PBtest 42.139 0.000999 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Now let’s see the estimates for \\(\\tau_{10}\\) and \\(\\tau_{01}\\) summary(randSlope) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4634 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 612.10 24.741 ## Days 35.07 5.922 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.825 36.838 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 The results show us that \\(\\tau_{10} = 35.07\\) and that the correlation is small. We will keep this random intercepts and slopes model and add a quadratic predictor for Days. 9.5 Quadratic model with lmer Note, in this model, we are only going to model the linear slope as random. We’ll keep the quadratic term fixed for now. The combined equation therefore just adds a fixed effect and looks like this: \\[ Y_{ti} = \\beta_{00} + \\beta_{10}(a_{ti}-L) + \\beta_{20}(a_{ti}-L)^{2}+ r_{0i} +r_{1i}(a_{ti}-L) +e_{ij} \\] Let’s fit the model and compare it to the random slopes model with only a linear predictor sleepstudy$Daysquared &lt;- sleepstudy$Days^2 # quadmod2 &lt;- lmerTest::lmer(Reaction ~ Days + Daysquared + (Days| Subject), data = sleepstudy) quadmod &lt;-lmer(Reaction ~ Days + I(Days^2) + (Days| Subject), data = sleepstudy) anova(randSlope, quadmod) ## Data: sleepstudy ## Models: ## randSlope: Reaction ~ Days + (Days | Subject) ## quadmod: Reaction ~ Days + I(Days^2) + (Days | Subject) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## randSlope 6 1763.9 1783.1 -875.97 1751.9 ## quadmod 7 1764.3 1786.6 -875.14 1750.3 1.6577 1 0.1979 pbkrtest::PBmodcomp(quadmod, randSlope) ## Bootstrap test; time: 15.86 sec; samples: 1000; extremes: 215; ## large : Reaction ~ Days + I(Days^2) + (Days | Subject) ## stat df p.value ## LRT 1.6577 1 0.1979 ## PBtest 1.6577 0.2158 We can also use the bootstrap confidence interval approach: confint(quadmod, method = &quot;boot&quot;) ## 2.5 % 97.5 % ## .sig01 10.7899579 35.4070753 ## .sig02 -0.5021857 0.9031948 ## .sig03 3.4497884 8.2301896 ## .sigma 22.8124498 28.5945090 ## (Intercept) 240.5315090 271.2280011 ## Days 1.8960615 12.3040694 ## I(Days^2) -0.1573193 0.8086611 So as we can see, adding the quadratic term does not yield a better fitting model. We can also see this within the model: summary(quadmod) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + I(Days^2) + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1742.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.0093 -0.4489 0.0422 0.5036 5.2702 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 613.12 24.761 ## Days 35.11 5.925 0.06 ## Residual 651.97 25.534 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 255.4494 7.5135 33.999 ## Days 7.4341 2.8189 2.637 ## I(Days^2) 0.3370 0.2619 1.287 ## ## Correlation of Fixed Effects: ## (Intr) Days ## Days -0.418 ## I(Days^2) 0.418 -0.836 So the tests converge, and we don’t seem to have evidence for a quadratic term. 9.5.1 A note on quadratic terms Technically, there will be a high degree of collinearity between the linear and quadratic terms like those above. To avoid this, we can make orthogonal polynomials – linear and squared variables that are not correlated – using the poly() function. What is cumbersome about orthogonal polynomial variables like this s is that they’re on weird scales as you can see above. So now the intercept will be meaningless, but we can still test if a quadratic predictor reduces deviance. We’ll add these to the dataframe to show you how this works sleepstudy2 &lt;- cbind(sleepstudy, poly(sleepstudy$Days, 2)) colnames(sleepstudy2)[4:5] &lt;- c(&quot;linear&quot;,&quot;quad&quot;) head(sleepstudy2) ## Reaction Days Subject linear quad 2 ## 1 249.5600 0 308 0 -0.11677484 0.12309149 ## 2 258.7047 1 308 1 -0.09082488 0.04103050 ## 3 250.8006 2 308 4 -0.06487491 -0.02051525 ## 4 321.4398 3 308 9 -0.03892495 -0.06154575 ## 5 356.8519 4 308 16 -0.01297498 -0.08206099 ## 6 414.6901 5 308 25 0.01297498 -0.08206099 Now let’s see what the effect is on the model ## refit random slopes randSlope2 &lt;- lmerTest::lmer(Reaction ~ Days + (Days|Subject), sleepstudy2) quadmod2 &lt;- lmerTest::lmer(Reaction ~ linear + quad + (linear| Subject), data = sleepstudy2) anova(randSlope2, quadmod2) ## Data: sleepstudy2 ## Models: ## randSlope2: Reaction ~ Days + (Days | Subject) ## quadmod2: Reaction ~ linear + quad + (linear | Subject) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## randSlope2 6 1763.9 1783.1 -875.97 1751.9 ## quadmod2 7 1768.9 1791.3 -877.45 1754.9 0 1 1 The deviance test generally agrees with the one for the “non-orthogonal” predictors, but the numbers are different. Within the summary, we’ll see that the new variables yield strange intercepts and variance components (why?) summary(quadmod2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: Reaction ~ linear + quad + (linear | Subject) ## Data: sleepstudy2 ## ## REML criterion at convergence: 1740.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.7016 -0.4715 -0.0002 0.5066 5.3026 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 763.3403 27.6286 ## linear 0.3764 0.6135 0.35 ## Residual 671.2606 25.9087 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 288.9028 10.1738 63.3704 28.397 &lt; 2e-16 *** ## linear 0.3370 0.3026 119.7398 1.114 0.26755 ## quad 286.4777 95.7439 143.0131 2.992 0.00326 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) linear ## linear -0.547 ## quad 0.717 -0.846 ## optimizer (nloptwrap) convergence code: 0 (OK) ## Model failed to converge with max|grad| = 0.0055591 (tol = 0.002, component 1) So if you’re interested in making substantive statements about the intercept and the variance components, use of orthogonal polynomials is somewhat awkward. 9.6 Summary of the sleepstudy analysis What we have just done is as follows: We fit models with a linear effect of Days on Reaction Time and asked whether there is significant random variation in both intercepts and slopes. This was done by assessing the reduction in deviance in a model with random linear slopes and intercepts compared to the random intercept-only linear growth model. The Deviance test was significant indicating that the model with random intercepts and slopes, and a covariance term between them is to be preferred. We added a quadratic term to our model and again used a deviance test to see if the fit was further improved. We did not find justification for keeping the quadratic growth term (since the test was not significant, and the other fit indices favored the linear model). Below we have the same data as Figure 1 above, but now we’ve added the within-subject regression lines (approximated). As we can see, the linear growth model is a pretty good model for these data. The fact that the dark grey “loess” lines aren’t much different with the graphed lines illustrates why the quadratic term doesn’t add much. xyplot(Reaction ~ Days | Subject, data = sleepstudy, panel=function(x, y){ panel.points(x, y) panel.lmline(x, y, lty=2, lwd=2) panel.loess(x, y, span=1, lwd=2, col = &quot;darkgray&quot;) }) There are no person-level predictors in the sleepstudy dataset, but if there were, we could now ask whether those person-level predictors affect the intercept and/or the slope in the linear growth model. We will cover that next week. 9.7 Preview of the Blackmore data used for Assignment 7b From Fox and Weisberg: Davis, Blackmore, Katzman, and Fox (2005) study on the exercise histories of a patient group of 138 teenage girls hospitalized for eating disorders and of 93 comparable control subjects. At the time of data collection, the girls and their parents were interviewed, and based on the interviews, an estimate of the average number of hours per week of exercise was constructed at each subject’s current age, which varied from girl to girl, and in most cases at 2-year intervals in the past, starting at age 8. Thus, the response variable, exercise, was measured at several different ages for each girl, with most subjects measured four or five times and a few measured two or three times. We are interested in modeling change in exercise with age and particularly in examining the potential difference in typical exercise trajectories between patients and control subjects. The data for the study are in the data frame Blackmore (named after the researcher who collected the data) in the carData package: ## 945 x 4 data.frame (937 rows omitted) ## subject age exercise group ## [f] [n] [n] [f] ## 1 100 8.00 2.71 patient ## 2 100 10.00 1.94 patient ## 3 100 12.00 2.36 patient ## 4 100 14.00 1.54 patient ## 5 100 15.92 8.63 patient ## . . . ## 770 286 12.00 0.35 control ## 771 286 14.00 0.40 control ## 772 286 17.00 0.29 control ## agegroup ## group [8,10] (10,12] (12,14] (14,17.9] ## control 185 60 58 56 ## patient 275 118 83 110 Let’s visualize these data too. Since there are so many participants. We’ll use the sample() function. I’m also using set.seed set.seed(12345) sampBlackmore &lt;- sample(unique(Blackmore$subject), 20) sampd &lt;- Blackmore[is.element(Blackmore$subject, sampBlackmore), ] xyplot(exercise ~ age | subject, data = sampd, panel=function(x, y){ panel.points(x, y) panel.lmline(x, y, lty=2, lwd=2) }) These data are much more typical of longitudinal studies, even though they’re technically event histories. There are differing numbers of observations across participants, and the observations are not equally spaced. As we’ll see next week, the control group also has differing numbers across the ages. All of this is no good for old-school repeated measures analysis but it is A-OK for MLM. 9.7.1 A note on the age variable in Blackmore For this week’s assignment, you will need to create 2 new age variables, both centered at different points. This chunk illustrates how to do that: # intercept is the end of the study (current time) Blackmore$endcentered &lt;- Blackmore$age - max(Blackmore$age) # intercept is the average age for the group Blackmore$midcentered &lt;- Blackmore$age - mean(Blackmore$age) head(Blackmore) ## subject age exercise group agegroup endcentered midcentered ## 1 100 8.00 2.71 patient [8,10] -9.92 -3.4416614 ## 2 100 10.00 1.94 patient [8,10] -7.92 -1.4416614 ## 3 100 12.00 2.36 patient (10,12] -5.92 0.5583386 ## 4 100 14.00 1.54 patient (12,14] -3.92 2.5583386 ## 5 100 15.92 8.63 patient (14,17.9] -2.00 4.4783386 ## 6 101 8.00 0.14 patient [8,10] -9.92 -3.4416614 As you can see above, the endcentered variable has values close to zero when the child is older, and the midcentered variable will have values close to zero when the child is at the mean age of approximately 11.5 years. Use both of these variables in your assignment. "],["longitudinal-models-with-upper-level-predictors.html", "10 Longitudinal models with upper-level predictors 10.1 Overview 10.2 Part 1: Intercepts and Slopes as Outcomes 10.3 Adding level 2 predictors 10.4 Summary 10.5 Adding Level-2 Explanatory variables 10.6 Time dependent covariates", " 10 Longitudinal models with upper-level predictors 10.1 Overview This week’s tutorial covers three topics: The intercepts-and-slopes as outcomes model in a longitudinal analysis Some more information on using ggplot2 Quick look at time-dependent covariates Packages required car lme4 ggplot2 10.2 Part 1: Intercepts and Slopes as Outcomes Davis, Blackmore, Katzman, and Fox (2005) study on the exercise histories of a patient group of 138 teenage girls hospitalized for eating disorders and of 93 comparable control subjects. At the time of data collection, the girls and their parents were interviewed, and based on the interviews, an estimate of the average number of hours per week of exercise was constructed at each subject’s current age, which varied from girl to girl, and in most cases at 2-year intervals in the past, starting at age 8. Thus, the response variable, exercise, was measured at several different ages for each girl, with most subjects measured four or five times and a few measured two or three times. We are interested in modeling change in exercise with age and particularly in examining the potential difference in typical exercise trajectories between patients and control subjects. The data for the study are in the data frame Blackmore (named after the researcher who collected the data) in the carData package: Blackmore$agegroup &lt;- with(Blackmore, cut(age, quantile(age, c(0, 0.25, 0.5, 0.75, 1)), include.lowest=TRUE)) # intercept is the end of the study (current time) Blackmore$endcentered &lt;- Blackmore$age - max(Blackmore$age) # intercept is the average age for the group Blackmore$midcentered &lt;- Blackmore$age - mean(Blackmore$age) xtabs(~ group + agegroup, data=Blackmore) ## agegroup ## group [8,10] (10,12] (12,14] (14,17.9] ## control 185 60 58 56 ## patient 275 118 83 110 10.2.1 A short tutorial on ggplot2 Let’s try a different visualization to preview our level-2 results. This visualization is much like the one that we used for (cross-sectional) Model 4. This uses the ggplot2 package This package has become a standard with R users because it is very well documented and very flexible. However, it takes a bit of getting used to. This is a link to the package author (Hadley Wickham’s) book chapter on how it works. A ggplot is built in steps. These can be executed one at a time or in steps. To illustrate, let’s build a plot in several steps. The key is that we can save the plot that we build first and then manipulate it. The way these plots are constructed is based on the grammar of graphics, and that’s what makes it a bit cumbersome, but after a while it becomes second nature (though of course, I look things up constantly in the help pages!). The first thing we’re going to do is to create the basic plot area and tell ggplot where the data are. Then, we’re going to we’re going to add a layer of points and map those points to our data. We can’t do anything, of course, if we don’t attach the ggplot2 package… (note: the package is called ggplot2 but the main function is ggplot()). library(ggplot2) ggplot(Blackmore) + # tell ggplot where the data are geom_point(mapping = aes(x = age, y = exercise)) The + sign is part of the package and separates layers and other options. It’s not uncommon to have several + as you add more options. In RStudio, type the + and then press return (or Enter) and the cursor will move the next line and indent. This helps organize the code so that each line contains one layer or option. Next, let’s add some color. There are two ways we might use color. One is mundane, and that is to color all the points the same. Let’s do that first, and then let’s do something more interesting, let’s color points according to whether the girl was part of the control group or a “patient” in the Blackmore study. Also, this time, I’m not going to save the plot. You’ll note that when you run the code it will appear. The reason I’m not adding to the already saved plot is we’re modifying the options within one layer (the geom_point layer). ggplot(Blackmore) + geom_point(mapping = aes(x = age, y = exercise), color = &quot;blue&quot;) # color all the points blue ggplot(Blackmore) + geom_point(mapping = aes(x = age, y = exercise, color = group)) # color according to group OK, this is more helpful for data exploration. We can sort of see a trend, though the relationship is not exactly linear. It looks like the girls in the patient group were exercising more at the end of the study. It’s hard to see because the age variable only takes on certain values (is nearly discrete). To help us see all the points, we’ll add what is called jitter. This option adds a small bit of noise (a very small normally distributed number) to each point and sort of, well, jitters it. ggplot(Blackmore) + geom_point(mapping = aes(x = age, y = exercise, color = group), position = &quot;jitter&quot;) # add jitter So we see a bit better now, but there’s something a bit funny about our dataset besides the discrete age values. We can see this a bit better if we use ggplot to make a histogram for age and then add color to see whether there’s a difference between the two groups. By default, the geom_bar function in ggplot2 plots count data, so it makes a histogram, which isn’t always what we want, but here it is. As you’ll see below, exercise is positively skewed. This is why your level 1 models might have fit weirdly. We’ll deal with that a little later. ggplot(Blackmore) + geom_histogram(mapping = aes(x = exercise, fill = group), bins = 15) Back to our scatterplots, let’s do a bit of formatting before we move on to our analysis. There are many other plot layers we can add, for example using geom_smooth() we can add linear and nonparametric regression lines as in earlier vignettes. But since our data likely need some transformation, we’ll skip that. Most of the time, our variable label in our dataframe isn’t what we want on either axis. To change the axis labels, we use labs() as below. We’ll also change the colors of the dots with scale_color_manual(). Finally, we’ll add a pre-packaged theme for the plot theme_minimal(). This is just a small sample of all the things one can do with ggplot. ggplot(Blackmore) + geom_point(mapping = aes(x = age, y = exercise, color = group), position = &quot;jitter&quot;) + scale_color_manual(values = c(&quot;grey&quot;,&quot;black&quot;)) + labs(x = &quot;Age&quot;, y = &quot;Estimated Exercise&quot;) + theme_minimal() + facet_wrap(~ group, 2) 10.3 Adding level 2 predictors Let’s start with the model using age centered with \\(0\\) at the end of the study: mod1 &lt;- lmer(exercise ~ endcentered + (endcentered |subject), data = Blackmore) sumary(mod1) ## Fixed Effects: ## coef.est coef.se ## (Intercept) 5.48 0.41 ## endcentered 0.45 0.04 ## ## Random Effects: ## Groups Name Std.Dev. Corr ## subject (Intercept) 5.48 ## endcentered 0.51 1.00 ## Residual 1.98 ## --- ## number of obs: 945, groups: subject, 231 ## AIC = 4452.5, DIC = 4426.2 ## deviance = 4433.3 10.3.1 Transforming the Exercise Variable Before we proceed, we need to do something about the exercise variable. It’s clearly numeric and not a count variable, so it can’t be handled in a generlized model format (not part of the course). A quick fix with positively skewed data is a square-root transformation. This often shrinks the range, though our data will likely not be symmetrical. Blackmore$rootEx &lt;- sqrt(Blackmore$exercise) ggplot(Blackmore) + geom_histogram(mapping = aes(x = rootEx, fill = group), bins = 15) The result is probably good enough for us, but see Fox &amp; Weisberg for the Box-Cox transform of this data. Importantly, let’s see how our model is affected. Here I’m going to run steps 1-3 just using endcentered age. Note, the convergence problems are “solved” using a different optimzation routine. The reason that convergence is failing is because many of the slopes in the control group are close to zero. 10.3.2 Steps 1 and 2: mod1.2t &lt;- lmer(rootEx ~ endcentered + (endcentered|subject), data = Blackmore, control = lmerControl(optimizer =&quot;Nelder_Mead&quot;)) sumary(mod1.2t) ## Fixed Effects: ## coef.est coef.se ## (Intercept) 2.06 0.09 ## endcentered 0.12 0.01 ## ## Random Effects: ## Groups Name Std.Dev. Corr ## subject (Intercept) 1.21 ## endcentered 0.11 0.91 ## Residual 0.52 ## --- ## number of obs: 945, groups: subject, 231 ## AIC = 2050.6, DIC = 2014.7 ## deviance = 2026.6 10.3.3 Step 3: Here, instead of using the sumary command from the faraway package, I’ll use the full summary. Also, we’ll use the ordinary likelihood-ratio test from anova() knowing that it might be too liberal. mod1.3t &lt;- lmer(rootEx ~ endcentered + I(endcentered^2) + (endcentered|subject), data = Blackmore, control = lmerControl(optimizer =&quot;Nelder_Mead&quot;)) anova(mod1.2t, mod1.3t) ## Data: Blackmore ## Models: ## mod1.2t: rootEx ~ endcentered + (endcentered | subject) ## mod1.3t: rootEx ~ endcentered + I(endcentered^2) + (endcentered | subject) ## npar AIC BIC logLik -2*log(L) Chisq Df Pr(&gt;Chisq) ## mod1.2t 6 2038.6 2067.8 -1013.3 2026.6 ## mod1.3t 7 2023.9 2057.9 -1005.0 2009.9 16.711 1 4.353e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(mod1.3t) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: rootEx ~ endcentered + I(endcentered^2) + (endcentered | subject) ## Data: Blackmore ## Control: lmerControl(optimizer = &quot;Nelder_Mead&quot;) ## ## REML criterion at convergence: 2032.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.8748 -0.5449 -0.0113 0.4837 4.1950 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## subject (Intercept) 1.51468 1.2307 ## endcentered 0.01197 0.1094 0.91 ## Residual 0.26089 0.5108 ## Number of obs: 945, groups: subject, 231 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 2.385443 0.122250 19.513 ## endcentered 0.246183 0.032218 7.641 ## I(endcentered^2) 0.010211 0.002473 4.129 ## ## Correlation of Fixed Effects: ## (Intr) endcnt ## endcentered 0.818 ## I(ndcntr^2) 0.637 0.953 10.4 Summary Using the square-root transformation we arrive at the same conclusions as with un-transformed exercise, though deviance is lower, and the estimates of the intercept are a bit uninterpretable, more on that later. So we have that: The best fitting level 1 model is one with random intercepts and age slopes, and a fixed quadratic age term Slope variance is not very large, but still significantly different from zero (as per our deviance test) There are still some issues with a few level-1 residuals, namely that there are a few outlier observations. Despite some of the issues with outliers, we’ll attempt to explain the intercept and slope variance using the group factor, which is the explanatory variable of interest. 10.5 Adding Level-2 Explanatory variables We can have as many explanatory variables as we like (so far as our model is still identified) but with most datasets, you won’t have that many level-2 variables. Unlike cross-sectional MLMs, it isn’t necessary to create a level-2 aggregate predictor (e.g., like mean.ses) since it makes no sense to compute the average age for each girl. Thus, we can focus just on the group variable, which categorizes each girl as a patient or part of the control group. Fitting this model is exactly the same as with cross-sectional, only now, we’re going to include a level-1 predictor that doesn’t vary: the quadratic age term. So, we want to make sure that our cross-level interaction only involves the linear age variable and group. Then we add in the quadratic effect before the random component. Also, since we were having convergence problems we’ll also continue to use the Nedler_Mead optimizer. We’re also going to check assumptions of normal errors at both levels. Level 1: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}(a_{ti}-L) + \\pi_{2i}(a_{ti}-L)^{2} e_{ij} \\] Level 2: \\[ \\pi_{0i} = \\beta_{00} + \\beta_{01}Group_{i} + r_{0i} \\] \\[ \\pi_{1i} = \\beta_{10} + \\beta_{11}Group_{i} + r_{1i} \\] \\[ \\pi_{2i} = \\beta_{20} \\] Combined model: \\[ Y_{ti} = \\beta_{00} + \\beta_{01}Group_{i} + \\beta_{10}(a_{ti}-L) + \\beta_{11}(Group\\times(a_{ti}-L)) + \\beta_{20}(a_{ti}-L)^{2} + r_{0i} + r_{1i}(a_{ti}-L) + e_{ij} \\] mod2.1a &lt;- lmer(rootEx ~ endcentered + group + endcentered:group + I(endcentered^2) + (endcentered|subject), data = Blackmore, control = lmerControl(optimizer =&quot;Nelder_Mead&quot;)) # Level 1 residuals qqnorm(residuals(mod2.1a)) # level 2 residuals qqnorm(ranef(mod2.1a)$subject$endcentered) So as we see, the level-1 residuals are still not the best, but at level 2, we have what we need. With these caveats in mind, let’s now check out the results: summary(mod2.1a) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: rootEx ~ endcentered + group + endcentered:group + I(endcentered^2) + ## (endcentered | subject) ## Data: Blackmore ## Control: lmerControl(optimizer = &quot;Nelder_Mead&quot;) ## ## REML criterion at convergence: 1997.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.9292 -0.5018 -0.0021 0.4899 4.1928 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## subject (Intercept) 1.230033 1.10907 ## endcentered 0.008466 0.09201 0.89 ## Residual 0.259621 0.50953 ## Number of obs: 945, groups: subject, 231 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 1.623296 0.163399 9.935 ## endcentered 0.149659 0.034294 4.364 ## grouppatient 1.148317 0.179620 6.393 ## I(endcentered^2) 0.008898 0.002449 3.634 ## endcentered:grouppatient 0.127303 0.018451 6.900 ## ## Correlation of Fixed Effects: ## (Intr) endcnt grpptn I(n^2) ## endcentered 0.782 ## grouppatint -0.706 -0.345 ## I(ndcntr^2) 0.502 0.905 -0.052 ## endcntrd:gr -0.641 -0.396 0.885 -0.065 Because we’ve taken the square-root (raised Y to the 1/2-power), but left the X’s untransformed, interpretation using the “change in Y for a unit change in X” is difficult. This Cross-Validated answer gives the gist of how cumbersome actual interpretation can be, but it goes something like this: The average within-subject slope is 0.15. This means that a unit change in age (1 year) yields \\(2 \\times 0.15 = 0.3\\) times the square of the current level of exercise (in hours per week). If we needed a more interpretable effect description, we could try another transformation, specifically, one that makes sense in the field or with respect to what we measured. 10.5.1 Visualizing the transformed data Let’s make a new ggplot and see if the square root transform helps with data visualization. We’ll also add lines for each person to see if we can approximate the linear trend. Also, the values argument of scale_color_manual can take many different arguments including the names of colors as we have done above, and also Hex Color Codes as I have included below (c(\"#FEC601\",\"#4F9CED\")). ggplot(data = Blackmore, aes(x = age, y = rootEx, col = group, group = subject)) + geom_point(size = 1, alpha = .7, position = &quot;jitter&quot;) + theme_classic() + scale_color_manual(values = c(&quot;red&quot;,&quot;#4F9CED&quot;)) + geom_smooth(method = lm, se = F, linewidth = .4, alpha = .1) + # to add regression line labs(x = &quot;Age&quot;, y = &quot;Square-root Exercise&quot;, title = &quot;Exercise (square root) and age by group and participant&quot;, subtitle = &quot;The within-person regression lines colored by group&quot;) 10.6 Time dependent covariates As a final analysis, let’s examine a hypothetical effect of involvement in sports. These are simulated data added onto the exercise dataset. We’ll add two variables: one hypothetical level-1 variable indicating if a girl played sports at that time and a level-2 variable indicating whether a girl ever played sports I’ve done this at random, but we can see that we have most of our level 1 sports time points in the patient group. xtabs(~sports1 + group, data = Blackmore) ## group ## sports1 control patient ## no sports 267 459 ## sports 92 127 As an illustration, I’ll fit two models: Using the level-1 sports variable: an indicator of whether the girl played a sport at the time of measurement (estimation) of exercise Using the level-2 sports variable: an indicator of whether the girl ever played sports during her lifetime 10.6.1 Level-1: Time-dependent sports predictor time_dep &lt;- lmer(rootEx ~ sports1 + age + (age|subject), data = Blackmore) sumary(time_dep) ## Fixed Effects: ## coef.est coef.se ## (Intercept) -0.07 0.10 ## sports1sports -0.02 0.05 ## age 0.12 0.01 ## ## Random Effects: ## Groups Name Std.Dev. Corr ## subject (Intercept) 0.95 ## age 0.11 -0.85 ## Residual 0.52 ## --- ## number of obs: 945, groups: subject, 231 ## AIC = 2056.5, DIC = 2010.5 ## deviance = 2026.5 10.6.2 Level-2: Participant-level indicator of sports participation Sports2 &lt;- lmer(rootEx ~ sports2 + age + (age|subject), data = Blackmore) sumary(Sports2) ## Fixed Effects: ## coef.est coef.se ## (Intercept) -0.01 0.11 ## sports2Sports -0.13 0.08 ## age 0.12 0.01 ## ## Random Effects: ## Groups Name Std.Dev. Corr ## subject (Intercept) 0.94 ## age 0.11 -0.85 ## Residual 0.52 ## --- ## number of obs: 945, groups: subject, 231 ## AIC = 2053.4, DIC = 2009 ## deviance = 2024.2 We can see that the coefficients are not the same. In the level-1 model, we have a (likely non-significant) difference in exercise at each time point that is small and favors those who didn’t play sports. The level-2 sports variable, in contrast, gives us a test of the difference in intercepts (here the beginning of the study) between those who did and did not ever play sports. Note here, the difference is larger, but still likely not significant. "],["multilevel-logistic-regression.html", "11 Multilevel logistic regression 11.1 Unconditional model 11.2 Conditional model 11.3 Interpreting odds ratios", " 11 Multilevel logistic regression Overview Explore how to deal with binary outcomes in multilevel framework Simple random-effects models for binary outcomes Dataset For illustration, we’ll use the 2018 PHMC Survey Dataset Note: this is a different data set than you’ll use in your project PHMC18 &lt;- readRDS(file = url(&quot;https://rickhass.github.io/PHMC18_Data.rds&quot;)) Though a more fine-grained analysis can be had by exploring effects by Zip Code, the dataset also has a ZIPREGION variable has 31 levels (see p. ) Based on City Planning Commission Planning Analysis Sections. For Bucks, Chester, Delaware, and Montgomery counties the ZIPREGION categories were developed to provide geographic areas with sufficient sample size for most statistical calculations. Twelve of them are in Philadelphia County, and the rest are North, Central, Central-South, etc. for Bucks, Chester, Delaware, and Montgomery counties Let’s look at incidence of emergency department visits in the last year reported by respondents across these 31 regions: # table of Hospitalization by ZIPREGION hosp.by.z &lt;- table(PHMC18$HOSPERA2, by = PHMC18$ZIPREGION) # Chi-squared test (chi2 &lt;- chisq.test(hosp.by.z)) ## ## Pearson&#39;s Chi-squared test ## ## data: hosp.by.z ## X-squared = 130.49, df = 30, p-value = 1.699e-14 # Average Incidence of hosp sum(hosp.by.z[2,])/sum(hosp.by.z) ## [1] 0.2719334 The \\(\\chi^{2}\\) test is extremely high powered, so not surprising that we find evidence that \\(\\hat{p}\\) varies by ZIPREGION. props &lt;- hosp.by.z[2,]/(hosp.by.z[2,] + hosp.by.z[1,]) lattice::densityplot(props, xlab = &quot;Proportion of Hospitalized Respondents per zipcode region&quot;) We can, in fact, see that there is variability in the proportion of respondents reporting an ED visit in the last year across the regions. The density is relatively symmetrical. Note, this variable is actually a dichotomized version of a variable asking for how many times a person visited the ED, but not surprisingly, it’s relatively rare to visit the ED more than once in a year 11.1 Unconditional model First, let’s get a model-based estimate of the between-cluster variability in proportions. Again, we do this by converting to the logit model Level 1: \\[ \\text{logit}(P(Y_{ij} = 1)) = \\beta_{0j} \\] Level 2: \\[ \\beta_{0j} = \\gamma_{00} + u_{0j} \\] Again, note that the usual \\(r_{ij}\\) is not explicitly in level 1. It is dealt with in the estimation process. In words: the log-odds of an ED visit is simply a function of the overall log-odds plus some effect of living in zip region \\(j\\) 11.1.1 Fitting the model We will use the glmer function in the lme4 package, which is an extension of the glm function in the same way lmer is an extension of the lm function. The syntax is the same, and we add the family = binomial argument to obtain the correct model and link function (logit) Important points: There is no REML = FALSE or REML = TRUE, estimation is done using full maximum likelihood via either Laplace Approximation or Gaussian Quadrature (more on this next week) We will only get variance estimation for the random effects at levels 2 and up We are given \\(p\\)-values based on Wald Tests, but they are not always accruate (more on this next week too) unc_mod &lt;- glmer(HOSPERA2 ~ (1|ZIPREGION), family = binomial, data = PHMC18) summary(unc_mod) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: HOSPERA2 ~ (1 | ZIPREGION) ## Data: PHMC18 ## ## AIC BIC logLik -2*log(L) df.resid ## 8528.1 8541.9 -4262.1 8524.1 7327 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.8063 -0.6325 -0.5671 1.3607 2.0375 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ZIPREGION (Intercept) 0.07431 0.2726 ## Number of obs: 7329, groups: ZIPREGION, 31 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.02211 0.05684 -17.98 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Main results: \\(\\gamma_{00} = -1.02\\) so the model-estimated mean logit of ED visits is \\(-1.02\\) To make this a probability we use the inverse link function: \\[ \\begin{aligned} h(\\eta) &amp; = \\frac{e^{(\\eta)}}{1 + e^{(\\eta)}}\\\\ &amp; = \\frac{e^{-1.02}}{1 + e^{-1.02}}\\\\ &amp; = \\frac{0.361}{1 + 0.361}\\\\ &amp; = 0.265 \\end{aligned} \\] Contrast that with the population estimate \\(\\hat{p} = 0.272\\) above. Here, the model-based estimate is cluster specific. So in the “typical” cluster, or one with a random effect of zero, we expect an ED visit with \\(p = 0.265\\) \\(\\text{Var}(\\beta_{0j}) = \\tau_{00} = 0.07\\) or \\(SD = \\sqrt{\\tau} = 0.273\\) The model-based distribution is shown below, with a rug-plot showing the observed log-odds across the 31 zipcode regions The code is based on Snijders and Bosker, and can be obtained at their website # Estimated average log-odds is b0 &lt;- fixef(unc_mod) # which transformed to a probability is p0 &lt;- exp(b0)/(1+exp(b0)) # The estimated level-2 variance is tau00 &lt;- (VarCorr(unc_mod)$ZIPREGION[1,1]) # with corresponding standard deviation tau0 &lt;- sqrt(tau00) # Approximation formula (17.13) yields var0 &lt;- tau00*((p0*(1-p0))^2) ## observed log odds logodds &lt;- log(props/(1-props)) # The normal density in Figure 17.5 can be obtained by x &lt;- tau0*c(-100:100)/25+b0 y &lt;- dnorm(x,mean=b0,sd=tau0) plot(x,y, type = &quot;l&quot;, xlab=&quot;log-odds of ED visit&quot;,ylab = &quot;density&quot;, main = &quot;Observed and model-based distribution of\\nlog-odds of ED visits across zip regions&quot;) rug(logodds) 11.2 Conditional model Now let’s add some predictors at level 1. You’ll find that things will get complex very quickly in terms of running time of the fitting process. There are mathematical reasons for this involving the approximation of the likelihood function, which must be marginalized over the random-effects. If it sounds daunting, it is! There are obviously numerous explanatory factors for an ED visit, and our model won’t be complete, but will suffice to illustrate how to add level-1 predictors. Predictors: SEX01 (Male / Female) RESPAGE_4CAT - 4 category age variable BMI RESPRACE_4CAT - White, Black, Asian, Other NPOV100 - indicator for poverty Stay tuned for quite a bit of output! cond_mod &lt;- glmer(HOSPERA2 ~ SEX01 + RESPAGE_4CAT + scale(BMI) + RESPRACE_4CAT + NPOV100 + (1|ZIPREGION), family = binomial, data = PHMC18) summary(cond_mod) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: HOSPERA2 ~ SEX01 + RESPAGE_4CAT + scale(BMI) + RESPRACE_4CAT + NPOV100 + (1 | ZIPREGION) ## Data: PHMC18 ## ## AIC BIC logLik -2*log(L) df.resid ## 7917.5 7992.8 -3947.8 7895.5 6916 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.1945 -0.6003 -0.5322 1.1341 2.4108 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ZIPREGION (Intercept) 0.01818 0.1348 ## Number of obs: 6927, groups: ZIPREGION, 31 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.645074 0.126977 -5.080 3.77e-07 *** ## SEX01Female 0.109431 0.056905 1.923 0.054474 . ## RESPAGE_4CAT35-49 -0.094279 0.117951 -0.799 0.424113 ## RESPAGE_4CAT50-64 -0.117714 0.105760 -1.113 0.265698 ## RESPAGE_4CAT65+ -0.009925 0.103941 -0.095 0.923927 ## scale(BMI) 0.122698 0.027196 4.512 6.43e-06 *** ## RESPRACE_4CATBlack 0.385136 0.076132 5.059 4.22e-07 *** ## RESPRACE_4CATAsian -0.303373 0.261972 -1.158 0.246849 ## RESPRACE_4CATOther 0.370979 0.109083 3.401 0.000672 *** ## NPOV100Not in poverty -0.562270 0.078256 -7.185 6.72e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) SEX01F RESPAGE_4CAT3 RESPAGE_4CAT5 RESPAGE_4CAT6 s(BMI) RESPRACE_4CATB ## SEX01Female -0.259 ## RESPAGE_4CAT3 -0.579 -0.033 ## RESPAGE_4CAT5 -0.665 -0.032 0.711 ## RESPAGE_4CAT6 -0.685 -0.044 0.724 0.816 ## scale(BMI) 0.028 0.018 -0.061 -0.087 -0.045 ## RESPRACE_4CATB -0.201 -0.083 0.015 0.030 0.047 -0.098 ## RESPRACE_4CATA -0.126 0.030 0.048 0.081 0.098 0.018 0.074 ## RESPRACE_4CATO -0.228 -0.020 0.077 0.117 0.150 -0.029 0.238 ## NPOV100Ntip -0.557 0.054 -0.021 -0.006 0.002 0.040 0.104 ## RESPRACE_4CATA RESPRACE_4CATO ## SEX01Female ## RESPAGE_4CAT3 ## RESPAGE_4CAT5 ## RESPAGE_4CAT6 ## scale(BMI) ## RESPRACE_4CATB ## RESPRACE_4CATA ## RESPRACE_4CATO 0.063 ## NPOV100Ntip 0.034 0.087 Some things of note: BMI is a numeric variable, which should be cluster-centered. Here, I quickly used grand-mean centering via the scale() function, which turns BMI into mean-deviation form Even though we have not included any ZIPREGION level variables, the residual variance of the random effects has dropped to \\(\\tau_{00} = 0.018\\) There seems to be no evidence for age-related differences in log-odds between the youngest respondents and the 3 oldest The other effects are as we might expect Also, the Laplace approximation can be improved upon, and we’ll demonstrate now with Gaussian Quadrature. Note my call to system.time system.time(cond_modq &lt;- glmer(HOSPERA2 ~ SEX01 + RESPAGE_4CAT + scale(BMI) + RESPRACE_4CAT + NPOV100 + (1|ZIPREGION), family = binomial, data = PHMC18, nAGQ = 10)) ## user system elapsed ## 2.727 0.037 2.764 Below we see that the fixed effects are identical and the random effect variances differ only at the thousandths place: data.frame(&quot;Laplace&quot;= round(fixef(cond_mod), 3), &quot;AQ&quot; = round(fixef(cond_modq), 3)) ## Laplace AQ ## (Intercept) -0.645 -0.645 ## SEX01Female 0.109 0.109 ## RESPAGE_4CAT35-49 -0.094 -0.094 ## RESPAGE_4CAT50-64 -0.118 -0.118 ## RESPAGE_4CAT65+ -0.010 -0.010 ## scale(BMI) 0.123 0.123 ## RESPRACE_4CATBlack 0.385 0.385 ## RESPRACE_4CATAsian -0.303 -0.303 ## RESPRACE_4CATOther 0.371 0.371 ## NPOV100Not in poverty -0.562 -0.562 # SD from Laplace VarCorr(cond_mod) ## Groups Name Std.Dev. ## ZIPREGION (Intercept) 0.13484 # SD from Quadrature VarCorr(cond_modq) ## Groups Name Std.Dev. ## ZIPREGION (Intercept) 0.13502 11.3 Interpreting odds ratios When interpreting results from generalized linear mixed effects models, nothing changes when we don’t use the inverse transformation. That is, the results below can be interpreted as normal:   HOSPERA 2 Predictors Log-Odds std. Error p (Intercept) -0.65 0.13 &lt;0.001 SEX01 [Female] 0.11 0.06 0.054 RESPAGE_4CAT35-49 -0.09 0.12 0.424 RESPAGE_4CAT50-64 -0.12 0.11 0.266 RESPAGE 4CAT [65+] -0.01 0.10 0.924 BMI 0.12 0.03 &lt;0.001 RESPRACE 4CAT [Black] 0.39 0.08 &lt;0.001 RESPRACE 4CAT [Asian] -0.30 0.26 0.247 RESPRACE 4CAT [Other] 0.37 0.11 0.001 NPOV100 [Not in poverty] -0.56 0.08 &lt;0.001 N ZIPREGION 31 Observations 6927 So for example, holding age, BMI, race and poverty status constant, the log-odds of an ED visit is increase by \\(0.11\\) for females compared to males. However, for the odds ratios, we have to exponentiate. This is a non-linear transformation and brings the model back to it’s non-linear form. As discussed, we can obtain odds ratios and confidence intervals, but bootstrap or even profile-likelihood-based intervals can take a while to return. For now, we’ll use the Confint function from car which is based simply on the normal approximation to the log-odds betas round(exp(car::Confint(cond_mod)),3) ## Estimate 2.5 % 97.5 % ## (Intercept) 0.525 0.409 0.673 ## SEX01Female 1.116 0.998 1.247 ## RESPAGE_4CAT35-49 0.910 0.722 1.147 ## RESPAGE_4CAT50-64 0.889 0.723 1.094 ## RESPAGE_4CAT65+ 0.990 0.808 1.214 ## scale(BMI) 1.131 1.072 1.192 ## RESPRACE_4CATBlack 1.470 1.266 1.706 ## RESPRACE_4CATAsian 0.738 0.442 1.234 ## RESPRACE_4CATOther 1.449 1.170 1.795 ## NPOV100Not in poverty 0.570 0.489 0.664 Above, we must now interpret the association between sex and odds of ED visit as follows: Holding all other variables constant, and the cluster / random effect constant, females have \\(12\\%\\) greater odds of an ED visit compared to males This is why the mixed-effects logistic regression is referred to as “cluster-specific” (compared to say, GEE which is a “population average model”) Greater insight to this issue can be found here and we’ll briefly look at an example. Here’s a histogram of the predicted probabilities of ED visit holding the random effect constant at \\(-0.0581\\) which is the 25th percentile of the random effects: ## [1] 0.2302176 And now here’s a histogram of the predictions at the 75th percentile, a random effect of \\(0.062\\) ## [1] 0.2521749 The distributions are slightly different, but the median predicted probability is about the same. So in this case, there isn’t a ton of variability due to the cluster, after conditioning on the within-cluster variables. So the fixed effects do carry some weight. If, however, the distribution shifted quite a bit, we might conclude that although within a particular zipcode region, it would be good to focus on individual variables to potentially intervene to reduce ED visits, at it may be better to focus on equity efforts between low and high risk regions We will discuss this more next week when we compare our results to the “population average model.” "],["mlm-v.-gee-for-binary-outcomes.html", "12 MLM v. GEE for Binary Outcomes 12.1 Overview 12.2 HLM Model 12.3 Population Average Model with GEE 12.4 HLM with level-2 predictors 12.5 Compare to GEE", " 12 MLM v. GEE for Binary Outcomes 12.1 Overview Contrast the GEE approach with a simple random effects model with a binary outcome Illustrate more complex mulilevel glm issues with binary outcomes New package alert! for generalized estimating equations we’ll use the geepack package You’ll need to install it before using it 12.1.1 Dataset For illustration, we’ll continue to use the 2018 PHMC Survey Dataset PHMC18 &lt;- readRDS(file = url(&quot;https://rickhass.github.io/PHMC18_Data.rds&quot;)) 12.2 HLM Model Recall last week we modeled ED visit (yes/no) with the following predictors: Predictors: SEX01 (Male / Female) RESPAGE_4CAT - 4 category age variable BMI RESPRACE_4CAT - White, Black, Asian, Other NPOV100 - indicator for poverty Here are the results on the log-odds scale   HOSPERA 2 Predictors Log-Odds std. Error p (Intercept) -1.16 0.11 &lt;0.001 SEX01 [Female] 0.13 0.06 0.021 RESPAGE_4CAT35-49 -0.11 0.12 0.343 RESPAGE_4CAT50-64 -0.12 0.11 0.246 RESPAGE 4CAT [65+] -0.01 0.10 0.937 BMI 0.13 0.03 &lt;0.001 RESPRACE 4CAT [Black] 0.44 0.08 &lt;0.001 RESPRACE 4CAT [Asian] -0.25 0.26 0.342 RESPRACE 4CAT [Other] 0.44 0.11 &lt;0.001 N ZIPREGION 31 Observations 6927 12.2.1 Interpreting odds ratios Remember, the odds ratios here are “cluster specific.” Indeed, the entire model is focused on the individual level, not the cluster level. round(exp(car::Confint(cond_mod)),3) ## Estimate 2.5 % 97.5 % ## (Intercept) 0.314 0.255 0.387 ## SEX01Female 1.139 1.020 1.273 ## RESPAGE_4CAT35-49 0.894 0.710 1.126 ## RESPAGE_4CAT50-64 0.885 0.720 1.088 ## RESPAGE_4CAT65+ 0.992 0.810 1.215 ## scale(BMI) 1.140 1.081 1.202 ## RESPRACE_4CATBlack 1.549 1.330 1.805 ## RESPRACE_4CATAsian 0.781 0.469 1.301 ## RESPRACE_4CATOther 1.545 1.249 1.912 Above, we must now interpret the association between sex and odds of ED visit as follows: Holding all other variables constant, and the cluster / random effect constant, females have \\(12\\%\\) greater odds of an ED visit compared to males This is why the mixed-effects logistic regression is referred to as “cluster-specific” (compared to say, GEE which is a “population average model”) 12.3 Population Average Model with GEE As we discussed, generalized estimating equations marginalize over the individuals and model the “population average” effect. This is great for our use of odds ratios, but not as good if we want to include more complex random effects One annoying part here is that we need to supply complete data to the function geeglm, it will not automatically reduce the dataframe for us. We must also put the observations in order by cluster (ZIPREGION) and change to a 0/1 numeric variable PHMC18$PHILA &lt;- ifelse(PHMC18$COUNTY == &quot;Philadelphia&quot;, 1, 0) PHMC18$PHILA &lt;- factor(PHMC18$PHILA, levels = c(0,1), labels = c(&quot;Not Phila&quot;,&quot;Phila&quot;)) PHMC18$ed_visit &lt;- ifelse(PHMC18$HOSPERA2 == &quot;0 visits&quot;, 0,1) PHMC18_order &lt;- PHMC18[order(PHMC18$ZIPREGION), ] PHMC18_gee &lt;- na.omit(PHMC18_order[,c(&quot;ed_visit&quot;,&quot;SEX01&quot;,&quot;RESPAGE_4CAT&quot;,&quot;BMI&quot;,&quot;RESPRACE_4CAT&quot;,&quot;ZIPREGION&quot;,&quot;PHILA&quot;)]) pop_avg &lt;- geeglm(ed_visit ~ SEX01 + RESPAGE_4CAT + scale(BMI) + RESPRACE_4CAT, id = ZIPREGION, corstr = &quot;exchangeable&quot;, scale.fix = TRUE, data = PHMC18_gee, family=binomial) summary(pop_avg) ## ## Call: ## geeglm(formula = ed_visit ~ SEX01 + RESPAGE_4CAT + scale(BMI) + ## RESPRACE_4CAT, family = binomial, data = PHMC18_gee, id = ZIPREGION, ## corstr = &quot;exchangeable&quot;, scale.fix = TRUE) ## ## Coefficients: ## Estimate Std.err Wald Pr(&gt;|W|) ## (Intercept) -1.149729 0.102404 126.054 &lt; 2e-16 *** ## SEX01Female 0.130091 0.041740 9.714 0.00183 ** ## RESPAGE_4CAT35-49 -0.111381 0.100455 1.229 0.26753 ## RESPAGE_4CAT50-64 -0.122429 0.099943 1.501 0.22058 ## RESPAGE_4CAT65+ -0.008848 0.092650 0.009 0.92392 ## scale(BMI) 0.130595 0.025419 26.396 2.78e-07 *** ## RESPRACE_4CATBlack 0.437663 0.066523 43.285 4.73e-11 *** ## RESPRACE_4CATAsian -0.246682 0.258178 0.913 0.33934 ## RESPRACE_4CATOther 0.435724 0.093036 21.934 2.82e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation structure = exchangeable ## Scale is fixed. ## ## Link = identity ## ## Estimated Correlation Parameters: ## Estimate Std.err ## alpha 0.004531 0.002029 ## Number of clusters: 31 Maximum cluster size: 410 Comparing with above, we can see that the results are nearly identical. One reason for that can be seen by inspecting the \\(\\alpha\\) parameter, estimated to be almost zero. This means there’s very little within-group correlation, so we might as well model this as independent data. The good news is that the cluster-specific and population average models converge, so we could consider the confidence intervals from the MLM to be accurate. Here’s the GEE confidence intervals for the odds-ratios broom::tidy(pop_avg, conf.int = T, exponentiate = T) ## # A tibble: 9 × 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.317 0.102 126. 0 0.259 0.387 ## 2 SEX01Female 1.14 0.0417 9.71 1.83e- 3 1.05 1.24 ## 3 RESPAGE_4CAT35-49 0.895 0.100 1.23 2.68e- 1 0.735 1.09 ## 4 RESPAGE_4CAT50-64 0.885 0.0999 1.50 2.21e- 1 0.727 1.08 ## 5 RESPAGE_4CAT65+ 0.991 0.0926 0.00912 9.24e- 1 0.827 1.19 ## 6 scale(BMI) 1.14 0.0254 26.4 2.78e- 7 1.08 1.20 ## 7 RESPRACE_4CATBlack 1.55 0.0665 43.3 4.73e-11 1.36 1.76 ## 8 RESPRACE_4CATAsian 0.781 0.258 0.913 3.39e- 1 0.471 1.30 ## 9 RESPRACE_4CATOther 1.55 0.0930 21.9 2.82e- 6 1.29 1.86 12.4 HLM with level-2 predictors Despite the nice properties of the population average approach, it is arguably less suited to situations in which we have random slopes as well as other predictors at level 2 From a philosophical perspective, we would use HLM if our questions were best answered by them We’ll have a look at two additional models, mirroring our approach in ordinary HLM 12.4.1 Random slopes You’ll find that things can get quite messy when you try to let all the slopes be random. We’ll stick with one that might make sense: Examine the model fit and \\(\\tau_{11}\\) for BMI - it is conceivable that the relationship between BMI and odds of an ED visit might vary across ZIPREGION To do this properly, we’ll group-center BMI bmi &lt;- PHMC18 |&gt; group_by(ZIPREGION) |&gt; summarise(MeanBMI = mean(BMI, na.rm = T)) for (i in 1:nrow(PHMC18)){ if (is.na(PHMC18$BMI[i])){ next } else { s = PHMC18$ZIPREGION[i] if (is.na(s)){ next } else { PHMC18$cBMI[i] = PHMC18$BMI[i] - bmi$MeanBMI[s] } } } rand_sl &lt;- glmer(HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + (cBMI|ZIPREGION), family = binomial, data = PHMC18) summary(rand_sl) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + (cBMI | ZIPREGION) ## Data: PHMC18 ## ## AIC BIC logLik -2*log(L) df.resid ## 8307 8389 -4141 8283 7196 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.969 -0.612 -0.544 1.241 2.392 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ZIPREGION (Intercept) 3.11e-02 0.17649 ## cBMI 5.15e-06 0.00227 -1.00 ## Number of obs: 7208, groups: ZIPREGION, 31 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.17684 0.10590 -11.11 &lt; 2e-16 *** ## SEX01Female 0.11885 0.05564 2.14 0.033 * ## RESPAGE_4CAT35-49 -0.07859 0.11528 -0.68 0.495 ## RESPAGE_4CAT50-64 -0.09463 0.10390 -0.91 0.362 ## RESPAGE_4CAT65+ 0.02196 0.10215 0.22 0.830 ## cBMI 0.01947 0.00459 4.24 2.2e-05 *** ## RESPRACE_4CATBlack 0.45496 0.07790 5.84 5.2e-09 *** ## RESPRACE_4CATAsian -0.29957 0.25309 -1.18 0.237 ## RESPRACE_4CATOther 0.44251 0.10693 4.14 3.5e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) SEX01F RESPAGE_4CAT3 RESPAGE_4CAT5 RESPAGE_4CAT6 cBMI RESPRACE_4CATB ## SEX01Female -0.269 ## RESPAGE_4CAT3 -0.698 -0.037 ## RESPAGE_4CAT5 -0.786 -0.040 0.716 ## RESPAGE_4CAT6 -0.806 -0.047 0.729 0.818 ## cBMI 0.032 0.026 -0.056 -0.088 -0.051 ## RESPRACE_4CATB -0.171 -0.080 0.009 0.026 0.044 -0.113 ## RESPRACE_4CATA -0.134 0.031 0.055 0.086 0.104 0.011 0.079 ## RESPRACE_4CATO -0.219 -0.023 0.079 0.120 0.152 -0.037 0.258 ## RESPRACE_4CATA ## SEX01Female ## RESPAGE_4CAT3 ## RESPAGE_4CAT5 ## RESPAGE_4CAT6 ## cBMI ## RESPRACE_4CATB ## RESPRACE_4CATA ## RESPRACE_4CATO 0.065 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) The fit is possibly singular as we can see the small variance of the BMI slopes, plus the perfect correlation of slopes and intercepts. The solution to the problem is often not clear. The most practical thing to do would be to revert back to the random-intercept model. 12.4.2 Level 2 predictors In our reading, it was argued that GEE was better for these macro-micro situations, which is not necessarily true. Especially because in HLM, a level-2 variable can be entered wherever we like, and usually, it’s a predictor of the intercept. In that way, the effect is not on individuals, but on the mean. The odds ratio would then be that effect in a group with \\(u_{0j} = 0\\) and again, we can investigate the variations in the effects as well as predictions Let’s take a look at a county-based variable: is the ZIPREGION in Philadelphia County or not? # collapse county into an indicator for Philadelphia County PHMC18$PHILA &lt;- ifelse(PHMC18$COUNTY == &quot;Philadelphia&quot;, 1, 0) PHMC18$PHILA &lt;- factor(PHMC18$PHILA, levels = c(0,1), labels = c(&quot;Not Phila&quot;,&quot;Phila&quot;)) lvl2 &lt;- glmer(HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + PHILA + (1|ZIPREGION), family = binomial, data = PHMC18) summary(lvl2) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + PHILA + (1 | ZIPREGION) ## Data: PHMC18 ## ## AIC BIC logLik -2*log(L) df.resid ## 8304 8380 -4141 8282 7197 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.991 -0.610 -0.543 1.238 2.379 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ZIPREGION (Intercept) 0.0292 0.171 ## Number of obs: 7208, groups: ZIPREGION, 31 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.20372 0.10968 -10.98 &lt; 2e-16 *** ## SEX01Female 0.11744 0.05566 2.11 0.035 * ## RESPAGE_4CAT35-49 -0.07713 0.11528 -0.67 0.503 ## RESPAGE_4CAT50-64 -0.09035 0.10394 -0.87 0.385 ## RESPAGE_4CAT65+ 0.02482 0.10212 0.24 0.808 ## cBMI 0.01906 0.00442 4.31 1.6e-05 *** ## RESPRACE_4CATBlack 0.43717 0.08059 5.42 5.8e-08 *** ## RESPRACE_4CATAsian -0.30598 0.25326 -1.21 0.227 ## RESPRACE_4CATOther 0.43157 0.10763 4.01 6.1e-05 *** ## PHILAPhila 0.07661 0.08863 0.86 0.387 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) SEX01F RESPAGE_4CAT3 RESPAGE_4CAT5 RESPAGE_4CAT6 cBMI RESPRACE_4CATB ## SEX01Female -0.253 ## RESPAGE_4CAT3 -0.678 -0.037 ## RESPAGE_4CAT5 -0.768 -0.041 0.716 ## RESPAGE_4CAT6 -0.784 -0.047 0.729 0.818 ## cBMI 0.049 0.024 -0.058 -0.086 -0.047 ## RESPRACE_4CATB -0.071 -0.069 0.006 0.013 0.034 -0.092 ## RESPRACE_4CATA -0.119 0.032 0.055 0.085 0.103 0.015 0.084 ## RESPRACE_4CATO -0.169 -0.019 0.077 0.114 0.148 -0.031 0.277 ## PHILAPhila -0.272 -0.026 0.016 0.037 0.021 0.021 -0.314 ## RESPRACE_4CATA RESPRACE_4CATO ## SEX01Female ## RESPAGE_4CAT3 ## RESPAGE_4CAT5 ## RESPAGE_4CAT6 ## cBMI ## RESPRACE_4CATB ## RESPRACE_4CATA ## RESPRACE_4CATO 0.068 ## PHILAPhila -0.038 -0.144 Interestingly, the log-odds of an ED visit does not seem to differ between residents in and outside of Philadelphia County 12.5 Compare to GEE pop_avg2 &lt;- geeglm(ed_visit ~ SEX01 + RESPAGE_4CAT + scale(BMI) + RESPRACE_4CAT + PHILA, id = ZIPREGION, corstr = &quot;exchangeable&quot;, scale.fix = TRUE, data = PHMC18_gee, family=binomial) summary(pop_avg2) ## ## Call: ## geeglm(formula = ed_visit ~ SEX01 + RESPAGE_4CAT + scale(BMI) + ## RESPRACE_4CAT + PHILA, family = binomial, data = PHMC18_gee, ## id = ZIPREGION, corstr = &quot;exchangeable&quot;, scale.fix = TRUE) ## ## Coefficients: ## Estimate Std.err Wald Pr(&gt;|W|) ## (Intercept) -1.17527 0.09761 144.98 &lt; 2e-16 *** ## SEX01Female 0.12871 0.04169 9.53 0.002 ** ## RESPAGE_4CAT35-49 -0.11005 0.10032 1.20 0.273 ## RESPAGE_4CAT50-64 -0.11870 0.09932 1.43 0.232 ## RESPAGE_4CAT65+ -0.00691 0.09211 0.01 0.940 ## scale(BMI) 0.13082 0.02543 26.47 2.7e-07 *** ## RESPRACE_4CATBlack 0.41433 0.06824 36.86 1.3e-09 *** ## RESPRACE_4CATAsian -0.25493 0.26134 0.95 0.329 ## RESPRACE_4CATOther 0.42189 0.09023 21.86 2.9e-06 *** ## PHILAPhila 0.07641 0.07914 0.93 0.334 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation structure = exchangeable ## Scale is fixed. ## ## Link = identity ## ## Estimated Correlation Parameters: ## Estimate Std.err ## alpha 0.00424 0.00222 ## Number of clusters: 31 Maximum cluster size: 410 lvl2.a &lt;- glmer(HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + PHILA + PHILA:SEX01 + (1|ZIPREGION), family = binomial, data = PHMC18) summary(lvl2.a) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: HOSPERA2 ~ SEX01 + RESPAGE_4CAT + cBMI + RESPRACE_4CAT + PHILA + ## PHILA:SEX01 + (1 | ZIPREGION) ## Data: PHMC18 ## ## AIC BIC logLik -2*log(L) df.resid ## 8306 8388 -4141 8282 7196 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.987 -0.612 -0.543 1.242 2.394 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ZIPREGION (Intercept) 0.0292 0.171 ## Number of obs: 7208, groups: ZIPREGION, 31 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.21741 0.11290 -10.78 &lt; 2e-16 *** ## SEX01Female 0.14091 0.07174 1.96 0.05 * ## RESPAGE_4CAT35-49 -0.07768 0.11529 -0.67 0.50 ## RESPAGE_4CAT50-64 -0.09138 0.10396 -0.88 0.38 ## RESPAGE_4CAT65+ 0.02503 0.10213 0.25 0.81 ## cBMI 0.01913 0.00442 4.33 1.5e-05 *** ## RESPRACE_4CATBlack 0.43943 0.08070 5.45 5.2e-08 *** ## RESPRACE_4CATAsian -0.30420 0.25330 -1.20 0.23 ## RESPRACE_4CATOther 0.43321 0.10768 4.02 5.7e-05 *** ## PHILAPhila 0.11263 0.11256 1.00 0.32 ## SEX01Female:PHILAPhila -0.05882 0.11331 -0.52 0.60 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) SEX01Fm RESPAGE_4CAT3 RESPAGE_4CAT5 RESPAGE_4CAT6 cBMI RESPRACE_4CATB ## SEX01Female -0.340 ## RESPAGE_4CAT3 -0.657 -0.035 ## RESPAGE_4CAT5 -0.742 -0.043 0.716 ## RESPAGE_4CAT6 -0.762 -0.034 0.729 0.818 ## cBMI 0.039 0.039 -0.058 -0.087 -0.047 ## RESPRACE_4CATB -0.081 -0.020 0.005 0.012 0.034 -0.089 ## RESPRACE_4CATA -0.119 0.034 0.055 0.085 0.103 0.015 0.085 ## RESPRACE_4CATO -0.171 0.004 0.077 0.114 0.148 -0.029 0.278 ## PHILAPhila -0.354 0.376 0.007 0.018 0.019 0.037 -0.213 ## SEX01F:PHIL 0.235 -0.631 0.009 0.018 -0.005 -0.033 -0.054 ## RESPRACE_4CATA RESPRACE_4CATO PHILAP ## SEX01Female ## RESPAGE_4CAT3 ## RESPAGE_4CAT5 ## RESPAGE_4CAT6 ## cBMI ## RESPRACE_4CATB ## RESPRACE_4CATA ## RESPRACE_4CATO 0.069 ## PHILAPhila -0.021 -0.095 ## SEX01F:PHIL -0.014 -0.029 -0.616 12.5.1 Visualizing REs Finally, there are nice plot methods for visualizing the random effects themselves. This is easier with a smaller number of clusters, but it’s often nice. Let’s first look at the unconditional variance of the intercepts: unc_mod &lt;- glmer(HOSPERA2 ~ (1|ZIPREGION), family = binomial, data = PHMC18) require(lattice) dotplot(ranef(unc_mod)) ## $ZIPREGION We can also look at conditional variance, and here, we’ll plot the slopes even though the model was singular. We do it in two separate plots because the estimated slope random effects are very small compared to the intercept random effects rand_slps &lt;- ranef(rand_sl) dotplot(rand_slps, scales = list(relation = &quot;free&quot;)) ## $ZIPREGION "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
