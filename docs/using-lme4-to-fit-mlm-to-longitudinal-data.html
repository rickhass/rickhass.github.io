<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Using lme4 to fit MLM to longitudinal data | Generalized Linear Mixed Models with R: A tutorial</title>
  <meta name="description" content="9 Using lme4 to fit MLM to longitudinal data | Generalized Linear Mixed Models with R: A tutorial" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Using lme4 to fit MLM to longitudinal data | Generalized Linear Mixed Models with R: A tutorial" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Using lme4 to fit MLM to longitudinal data | Generalized Linear Mixed Models with R: A tutorial" />
  
  
  

<meta name="author" content="Rick Hass" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="more-on-hierarchical-linear-models.html"/>
<link rel="next" href="longitudinal-models-with-upper-level-predictors.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="1" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>1</b> R Basics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-basics.html"><a href="r-basics.html#what-is-coding"><i class="fa fa-check"></i><b>1.1</b> What is “coding”</a></li>
<li class="chapter" data-level="1.2" data-path="r-basics.html"><a href="r-basics.html#r-console-versus-the-rstudio-script"><i class="fa fa-check"></i><b>1.2</b> R Console versus the RStudio Script</a></li>
<li class="chapter" data-level="1.3" data-path="r-basics.html"><a href="r-basics.html#working-with-data"><i class="fa fa-check"></i><b>1.3</b> Working with data</a></li>
<li class="chapter" data-level="1.4" data-path="r-basics.html"><a href="r-basics.html#using-a-script-to-generate-data-and-computing-the-mean-and-standard-deviation"><i class="fa fa-check"></i><b>1.4</b> Using a script to generate data, and computing the mean and standard deviation</a></li>
<li class="chapter" data-level="1.5" data-path="r-basics.html"><a href="r-basics.html#importing-data"><i class="fa fa-check"></i><b>1.5</b> Importing Data</a></li>
<li class="chapter" data-level="1.6" data-path="r-basics.html"><a href="r-basics.html#reading-in-an-spss-file"><i class="fa fa-check"></i><b>1.6</b> Reading in an SPSS file</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="r-basics.html"><a href="r-basics.html#a-quick-note-on-indexing"><i class="fa fa-check"></i><b>1.6.1</b> A quick note on indexing</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="r-basics.html"><a href="r-basics.html#frequencies-and-contingency-tables"><i class="fa fa-check"></i><b>1.7</b> Frequencies and Contingency Tables</a></li>
<li class="chapter" data-level="1.8" data-path="r-basics.html"><a href="r-basics.html#descriptive-statistics"><i class="fa fa-check"></i><b>1.8</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="r-basics.html"><a href="r-basics.html#the-describe-function"><i class="fa fa-check"></i><b>1.8.1</b> The describe function</a></li>
<li class="chapter" data-level="1.8.2" data-path="r-basics.html"><a href="r-basics.html#the-describeby-function"><i class="fa fa-check"></i><b>1.8.2</b> The describeBy function</a></li>
<li class="chapter" data-level="1.8.3" data-path="r-basics.html"><a href="r-basics.html#computing-a-new-variable-and-adding-it-to-the-dataframe"><i class="fa fa-check"></i><b>1.8.3</b> Computing a new variable and adding it to the dataframe</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="r-basics.html"><a href="r-basics.html#visualizing-data"><i class="fa fa-check"></i><b>1.9</b> Visualizing Data</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="r-basics.html"><a href="r-basics.html#histograms-and-density-plots"><i class="fa fa-check"></i><b>1.9.1</b> Histograms and density plots</a></li>
<li class="chapter" data-level="1.9.2" data-path="r-basics.html"><a href="r-basics.html#boxplots"><i class="fa fa-check"></i><b>1.9.2</b> Boxplots</a></li>
<li class="chapter" data-level="1.9.3" data-path="r-basics.html"><a href="r-basics.html#scatterplots"><i class="fa fa-check"></i><b>1.9.3</b> Scatterplots</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="r-basics.html"><a href="r-basics.html#review"><i class="fa fa-check"></i><b>1.10</b> Review</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Ordinary Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#our-data"><i class="fa fa-check"></i><b>2.1</b> Our data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#converting-from-numeric-to-factor"><i class="fa fa-check"></i><b>2.1.1</b> Converting from numeric to factor</a></li>
<li class="chapter" data-level="2.1.2" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#confidence-intervals-v.-p-values"><i class="fa fa-check"></i><b>2.1.2</b> Confidence Intervals v. p-values</a></li>
<li class="chapter" data-level="2.1.3" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#adding-interaction-terms"><i class="fa fa-check"></i><b>2.1.3</b> Adding interaction terms</a></li>
<li class="chapter" data-level="2.1.4" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#interaction-model-for-gambling"><i class="fa fa-check"></i><b>2.1.4</b> Interaction model for Gambling</a></li>
<li class="chapter" data-level="2.1.5" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#interaction-output"><i class="fa fa-check"></i><b>2.1.5</b> Interaction Output</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#anova-and-drop1-commands"><i class="fa fa-check"></i><b>2.2</b> ANOVA and drop1 commands</a></li>
<li class="chapter" data-level="2.3" data-path="ordinary-linear-regression.html"><a href="ordinary-linear-regression.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>3</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#an-example-diabetes-risk-factors"><i class="fa fa-check"></i><b>3.1</b> An Example: Diabetes risk factors</a></li>
<li class="chapter" data-level="3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#model-discrimination-and-fit"><i class="fa fa-check"></i><b>3.2</b> Model Discrimination and Fit</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-and-auroc"><i class="fa fa-check"></i><b>3.2.1</b> ROC and AUROC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html"><i class="fa fa-check"></i><b>4</b> Regression with Counts as Outcomes</a>
<ul>
<li class="chapter" data-level="4.1" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#example-data-phmc-fruits-question"><i class="fa fa-check"></i><b>4.1</b> Example data: PHMC Fruits question</a></li>
<li class="chapter" data-level="4.2" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#coefficients-in-poisson-models"><i class="fa fa-check"></i><b>4.2</b> Coefficients in Poisson Models</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#exponentiated-coefficients-interpretation"><i class="fa fa-check"></i><b>4.2.1</b> Exponentiated Coefficients Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#overdispersion-and-other-count-regression-models"><i class="fa fa-check"></i><b>4.3</b> Overdispersion and other count regression models</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#overdispersion-and-zero-inflation"><i class="fa fa-check"></i><b>4.3.1</b> Overdispersion and Zero-inflation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="regression-with-counts-as-outcomes.html"><a href="regression-with-counts-as-outcomes.html#zero-inflated-models"><i class="fa fa-check"></i><b>4.4</b> Zero-inflated models</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html"><i class="fa fa-check"></i><b>5</b> Model Fit and Assumptions for GLMs</a>
<ul>
<li class="chapter" data-level="5.1" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#model-checking-and-diagnostics-in-ordinary-least-squares"><i class="fa fa-check"></i><b>5.1</b> Model Checking and Diagnostics in Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#residuals-v.-fitted-values"><i class="fa fa-check"></i><b>5.1.1</b> Residuals v. Fitted Values</a></li>
<li class="chapter" data-level="5.1.2" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#normalty-of-residuals"><i class="fa fa-check"></i><b>5.1.2</b> Normalty of residuals</a></li>
<li class="chapter" data-level="5.1.3" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#leverage"><i class="fa fa-check"></i><b>5.1.3</b> Leverage</a></li>
<li class="chapter" data-level="5.1.4" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#influence"><i class="fa fa-check"></i><b>5.1.4</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#model-checking-and-diagnostics-in-logistic-regression"><i class="fa fa-check"></i><b>5.2</b> Model Checking and Diagnostics in Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#hosmer-lemeshow-test"><i class="fa fa-check"></i><b>5.2.1</b> Hosmer-Lemeshow Test</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#nagelkerkes-pseudo-r-squared"><i class="fa fa-check"></i><b>5.2.2</b> Nagelkerke’s pseudo R-squared</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#residuals-and-leverages"><i class="fa fa-check"></i><b>5.2.3</b> Residuals and leverages</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-fit-and-assumptions-for-glms.html"><a href="model-fit-and-assumptions-for-glms.html#summary"><i class="fa fa-check"></i><b>5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html"><i class="fa fa-check"></i><b>6</b> Introducing mixed-models and the lme4 package</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#options-in-r"><i class="fa fa-check"></i><b>6.1</b> Options in R</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#why-lme4"><i class="fa fa-check"></i><b>6.1.1</b> Why lme4?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#a-possible-workflow"><i class="fa fa-check"></i><b>6.2</b> A possible workflow</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#high-school-and-beyond"><i class="fa fa-check"></i><b>6.2.1</b> High School and Beyond</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#model-1-one-way-random-effects-anova-using-reml"><i class="fa fa-check"></i><b>6.3</b> Model 1: one-way random-effects ANOVA using REML</a></li>
<li class="chapter" data-level="6.4" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#quasi-anova-estimator"><i class="fa fa-check"></i><b>6.4</b> Quasi-ANOVA estimator</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#unrestricted-maximum-likelihood"><i class="fa fa-check"></i><b>6.4.1</b> (unrestricted) Maximum Likelihood</a></li>
<li class="chapter" data-level="6.4.2" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#intraclass-correlation"><i class="fa fa-check"></i><b>6.4.2</b> Intraclass correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#bootstrapped-confidence-intervals"><i class="fa fa-check"></i><b>6.5</b> Bootstrapped confidence intervals</a></li>
<li class="chapter" data-level="6.6" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#linear-mixed-effects"><i class="fa fa-check"></i><b>6.6</b> Linear mixed-effects</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="introducing-mixed-models-and-the-lme4-package.html"><a href="introducing-mixed-models-and-the-lme4-package.html#random-effects-estimates"><i class="fa fa-check"></i><b>6.6.1</b> Random effects estimates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html"><i class="fa fa-check"></i><b>7</b> Mixed models as Hierarchical Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#high-school-and-beyond-data"><i class="fa fa-check"></i><b>7.1</b> High School and Beyond Data</a></li>
<li class="chapter" data-level="7.2" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#model-1-unconditional-model"><i class="fa fa-check"></i><b>7.2</b> Model 1: unconditional model</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#unconditional-icc"><i class="fa fa-check"></i><b>7.2.1</b> Unconditional ICC</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#means-as-outcomes-binary-predictor"><i class="fa fa-check"></i><b>7.3</b> Means as outcomes: Binary Predictor</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#means-as-outcomes-continuous-predictor"><i class="fa fa-check"></i><b>7.3.1</b> Means as outcomes: continuous predictor</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#multiple-hierarchical-linear-regression"><i class="fa fa-check"></i><b>7.4</b> Multiple hierarchical linear regression</a></li>
<li class="chapter" data-level="7.5" data-path="mixed-models-as-hierarchical-linear-models.html"><a href="mixed-models-as-hierarchical-linear-models.html#plotting-predictor-effects"><i class="fa fa-check"></i><b>7.5</b> Plotting predictor effects</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html"><i class="fa fa-check"></i><b>8</b> More on Hierarchical Linear Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#overview-1"><i class="fa fa-check"></i><b>8.1</b> Overview</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#load-the-data"><i class="fa fa-check"></i><b>8.1.1</b> Load the data</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#random-coefficients-model"><i class="fa fa-check"></i><b>8.2</b> Random Coefficients model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#visualizing-the-within-school-slopes"><i class="fa fa-check"></i><b>8.2.1</b> Visualizing the within-school slopes</a></li>
<li class="chapter" data-level="8.2.2" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#fitting-the-random-coefficients-2-level-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the Random Coefficients 2-level model</a></li>
<li class="chapter" data-level="8.2.3" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#adding-additional-level-1-predictors-to-the-random-coefficients-model"><i class="fa fa-check"></i><b>8.2.3</b> Adding additional level-1 predictors to the random coefficients model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#intercepts-and-slopes-as-outcomes"><i class="fa fa-check"></i><b>8.3</b> Intercepts and Slopes as Outcomes</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#interactions-and-the-iso-model"><i class="fa fa-check"></i><b>8.3.1</b> Interactions and the ISO model</a></li>
<li class="chapter" data-level="8.3.2" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#mean-ses-and-student-ses"><i class="fa fa-check"></i><b>8.3.2</b> Mean SES and Student SES</a></li>
<li class="chapter" data-level="8.3.3" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#sector-and-student-ses"><i class="fa fa-check"></i><b>8.3.3</b> Sector and Student SES</a></li>
<li class="chapter" data-level="8.3.4" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#visualizing-the-mean-ses-effect"><i class="fa fa-check"></i><b>8.3.4</b> Visualizing the mean SES effect</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#model-comparison-with-likelihood-ratios-fixed-and-random"><i class="fa fa-check"></i><b>8.4</b> Model comparison with Likelihood Ratios: Fixed and Random</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#example-1-lrt-for-fixed-effects"><i class="fa fa-check"></i><b>8.4.1</b> Example 1: LRT for fixed effects</a></li>
<li class="chapter" data-level="8.4.2" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#example-2-lrt-for-random-effects"><i class="fa fa-check"></i><b>8.4.2</b> Example 2: LRT for random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="more-on-hierarchical-linear-models.html"><a href="more-on-hierarchical-linear-models.html#diagnostics"><i class="fa fa-check"></i><b>8.5</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html"><i class="fa fa-check"></i><b>9</b> Using lme4 to fit MLM to longitudinal data</a>
<ul>
<li class="chapter" data-level="9.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#data-description-average-reaction-time-per-day-for-subjects-in-a-sleep-deprivation-study-belenky-et-al.-2003"><i class="fa fa-check"></i><b>9.1</b> Data description: average reaction time per day for subjects in a sleep deprivation study (Belenky et al. 2003)</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#visualization-of-the-data"><i class="fa fa-check"></i><b>9.1.1</b> Visualization of the data</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#fitting-the-level-1-model"><i class="fa fa-check"></i><b>9.2</b> Fitting the level-1 model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-equations"><i class="fa fa-check"></i><b>9.2.1</b> Model Equations</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-building"><i class="fa fa-check"></i><b>9.3</b> Model building</a></li>
<li class="chapter" data-level="9.4" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-comparison-and-testing"><i class="fa fa-check"></i><b>9.4</b> Model comparison and testing</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#option-1-using-confidence-intervals"><i class="fa fa-check"></i><b>9.4.1</b> Option 1: using confidence intervals</a></li>
<li class="chapter" data-level="9.4.2" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#tests"><i class="fa fa-check"></i><b>9.4.2</b> Tests</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#quadratic-model-with-lmer"><i class="fa fa-check"></i><b>9.5</b> Quadratic model with lmer</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#a-note-on-quadratic-terms"><i class="fa fa-check"></i><b>9.5.1</b> A note on quadratic terms</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#summary-of-the-sleepstudy-analysis"><i class="fa fa-check"></i><b>9.6</b> Summary of the sleepstudy analysis</a></li>
<li class="chapter" data-level="9.7" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#preview-of-the-blackmore-data-used-for-assignment-7b"><i class="fa fa-check"></i><b>9.7</b> Preview of the Blackmore data used for Assignment 7b</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="using-lme4-to-fit-mlm-to-longitudinal-data.html"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#a-note-on-the-age-variable-in-blackmore"><i class="fa fa-check"></i><b>9.7.1</b> A note on the age variable in Blackmore</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html"><i class="fa fa-check"></i><b>10</b> Longitudinal models with upper-level predictors</a>
<ul>
<li class="chapter" data-level="10.1" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#overview-2"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#part-1-intercepts-and-slopes-as-outcomes"><i class="fa fa-check"></i><b>10.2</b> Part 1: Intercepts and Slopes as Outcomes</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#a-short-tutorial-on-ggplot2"><i class="fa fa-check"></i><b>10.2.1</b> A short tutorial on ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#adding-level-2-predictors"><i class="fa fa-check"></i><b>10.3</b> Adding level 2 predictors</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#transforming-the-exercise-variable"><i class="fa fa-check"></i><b>10.3.1</b> Transforming the Exercise Variable</a></li>
<li class="chapter" data-level="10.3.2" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#steps-1-and-2"><i class="fa fa-check"></i><b>10.3.2</b> Steps 1 and 2:</a></li>
<li class="chapter" data-level="10.3.3" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#step-3"><i class="fa fa-check"></i><b>10.3.3</b> Step 3:</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#summary-1"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="10.5" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#adding-level-2-explanatory-variables"><i class="fa fa-check"></i><b>10.5</b> Adding Level-2 Explanatory variables</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#visualizing-the-transformed-data"><i class="fa fa-check"></i><b>10.5.1</b> Visualizing the transformed data</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#time-dependent-covariates"><i class="fa fa-check"></i><b>10.6</b> Time dependent covariates</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#level-1-time-dependent-sports-predictor"><i class="fa fa-check"></i><b>10.6.1</b> Level-1: Time-dependent sports predictor</a></li>
<li class="chapter" data-level="10.6.2" data-path="longitudinal-models-with-upper-level-predictors.html"><a href="longitudinal-models-with-upper-level-predictors.html#level-2-participant-level-indicator-of-sports-participation"><i class="fa fa-check"></i><b>10.6.2</b> Level-2: Participant-level indicator of sports participation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multilevel-logistic-regression.html"><a href="multilevel-logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Multilevel logistic regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multilevel-logistic-regression.html"><a href="multilevel-logistic-regression.html#unconditional-model"><i class="fa fa-check"></i><b>11.1</b> Unconditional model</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="multilevel-logistic-regression.html"><a href="multilevel-logistic-regression.html#fitting-the-model"><i class="fa fa-check"></i><b>11.1.1</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="multilevel-logistic-regression.html"><a href="multilevel-logistic-regression.html#conditional-model"><i class="fa fa-check"></i><b>11.2</b> Conditional model</a></li>
<li class="chapter" data-level="11.3" data-path="multilevel-logistic-regression.html"><a href="multilevel-logistic-regression.html#interpreting-odds-ratios"><i class="fa fa-check"></i><b>11.3</b> Interpreting odds ratios</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html"><i class="fa fa-check"></i><b>12</b> MLM v. GEE for Binary Outcomes</a>
<ul>
<li class="chapter" data-level="12.1" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#overview-3"><i class="fa fa-check"></i><b>12.1</b> Overview</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#dataset"><i class="fa fa-check"></i><b>12.1.1</b> Dataset</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#hlm-model"><i class="fa fa-check"></i><b>12.2</b> HLM Model</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#interpreting-odds-ratios-1"><i class="fa fa-check"></i><b>12.2.1</b> Interpreting odds ratios</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#population-average-model-with-gee"><i class="fa fa-check"></i><b>12.3</b> Population Average Model with GEE</a></li>
<li class="chapter" data-level="12.4" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#hlm-with-level-2-predictors"><i class="fa fa-check"></i><b>12.4</b> HLM with level-2 predictors</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#random-slopes-1"><i class="fa fa-check"></i><b>12.4.1</b> Random slopes</a></li>
<li class="chapter" data-level="12.4.2" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#level-2-predictors"><i class="fa fa-check"></i><b>12.4.2</b> Level 2 predictors</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#compare-to-gee"><i class="fa fa-check"></i><b>12.5</b> Compare to GEE</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="mlm-v.-gee-for-binary-outcomes.html"><a href="mlm-v.-gee-for-binary-outcomes.html#visualizing-res"><i class="fa fa-check"></i><b>12.5.1</b> Visualizing REs</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Generalized Linear Mixed Models with R: A tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="using-lme4-to-fit-mlm-to-longitudinal-data" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">9</span> Using lme4 to fit MLM to longitudinal data<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#using-lme4-to-fit-mlm-to-longitudinal-data" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Longitudinal data come in all shapes and sizes, but we need the data in a particular form
to be able to fit models using <code>lme4</code></p>
<p><em>Person period</em> refers to a dataset where each row corresponds to an observation of a
person in a particular period of time. This is also called “long” (as opposed to wide) and within the <code>tidyverse</code> it is referred to as <code>tidy</code> data.</p>
<p>For example, we see below a printout of the first 6 rows of the <code>sleepstudy</code> dataset
that comes with the <code>lme4</code> package. As you can see, the first 6 rows all are from Subject 308.</p>
<pre><code>##   Reaction Days Subject
## 1 249.5600    0     308
## 2 258.7047    1     308
## 3 250.8006    2     308
## 4 321.4398    3     308
## 5 356.8519    4     308
## 6 414.6901    5     308</code></pre>
<div id="data-description-average-reaction-time-per-day-for-subjects-in-a-sleep-deprivation-study-belenky-et-al.-2003" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Data description: average reaction time per day for subjects in a sleep deprivation study (Belenky et al. 2003)<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#data-description-average-reaction-time-per-day-for-subjects-in-a-sleep-deprivation-study-belenky-et-al.-2003" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>The response variable, <em>Reaction</em>, represents average reaction times in milliseconds (ms) on a series of tests given each Day to each Subject (Figure 1)</li>
<li>On day <span class="math inline">\(0\)</span> the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night
<ul>
<li>Note how this will affect the model interpretation</li>
</ul></li>
<li>There are no level 2 explanatory variables in this data set, so we’re simply going to model growth as random and take a look at some examples of how to evaluate it</li>
</ul>
<div id="visualization-of-the-data" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Visualization of the data<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#visualization-of-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are only 18 participants in this study, which is typical of a repeated measures / longitudinal lab study in cognitive psychology and cognitive neuroscience. Let’s see whether linear trajectories seem to fit by graphing the data for each participant. The code below uses <code>xyplot</code> a great function for producing multiple scatterplots.</p>
<p>What do you see in this plot? What seems to be the common theme across subjects in terms of the relationship between day in the study (number of days with sleep deprivation) and Reaction time?</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb277-1" tabindex="-1"></a><span class="fu">xyplot</span>(Reaction <span class="sc">~</span> Days <span class="sc">|</span> Subject, <span class="at">data =</span> sleepstudy,</span>
<span id="cb277-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb277-2" tabindex="-1"></a>       <span class="at">panel=</span><span class="cf">function</span>(x, y){</span>
<span id="cb277-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb277-3" tabindex="-1"></a>        <span class="fu">panel.points</span>(x, y)</span>
<span id="cb277-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb277-4" tabindex="-1"></a>    })</span></code></pre></div>
<p><img src="_main_files/figure-html/c209-1.png" width="672" /></p>
</div>
</div>
<div id="fitting-the-level-1-model" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Fitting the level-1 model<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#fitting-the-level-1-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Theory and experience suggest that as people become more cumulatively sleep deprived, cognitive functioning should suffer.</p>
<p>The questions that we can answer with MLM are as follows:</p>
<ol style="list-style-type: decimal">
<li>Does a model with only linear growth (change) fit better than a model with both linear and quadratic growth?</li>
<li>Is there variance in the intercepts?</li>
<li>Is there variance in the slopes?</li>
</ol>
<p>We should answer question 1 first, since there will be more than one “slope” if we fit a model with quadratic growth.</p>
<div id="model-equations" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Model Equations<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-equations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll start with a random intercept model first, so that we can test whether linear slopes should be random using a comparison test.</p>
<p>Level 1:</p>
<p><span class="math display">\[
Y_{ti} = \pi_{0i} + \pi_{1i}(a_{ti}-L) + e_{ij}
\]</span>
Level 2:</p>
<p><span class="math display">\[
\pi_{0i} = \beta_{00} + r_{0i}
\]</span>
<span class="math display">\[
\pi_{1i} = \beta_{10}
\]</span></p>
<p>Combined model:</p>
<p><span class="math display">\[
Y_{ti} = \beta_{00} + \beta_{10}(a_{ti}-L) + r_{0i} +e_{ij}
\]</span></p>
<p>In the equation <span class="math inline">\(L\)</span> stands for “lag” and will be 0 to start. That means that we can just use the raw <span class="math inline">\(a\)</span> variable which is just <code>Days</code> in our example as the time is measured in days since full sleep, starting with zero.</p>
<p>Remember, this coding for time has an effect on the intercept variability. In the models we run today, the intercept variance will be the variance across individuals in their reaction time on the first day of the study (with full sleep).</p>
<p>Below, and for HW we’ll see how changing this “zero point” or “center” of the data changes the intercept variance estimate when we allow different slopes.</p>
</div>
</div>
<div id="model-building" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Model building<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-building" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We use the <code>lmer</code> function exactly as before to fit the intercepts and slopes as outcomes models with cross-sectional data. However, we’ll proceed in two steps this time:</p>
<ol style="list-style-type: decimal">
<li>Fit the linear growth model as described above – <em>without</em> a random slope and examine:</li>
</ol>
<p><em>The variance of the intercepts as <span class="math inline">\(\text{Var}(r_{0i}) = \tau_{00}\)</span>
</em>The coefficient of the linear time (<code>Days</code>) variable</p>
<ol start="2" style="list-style-type: decimal">
<li>Fit a random slopes model and compare to the first</li>
</ol>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb278-1" tabindex="-1"></a>randIntMod <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Reaction <span class="sc">~</span> Days <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Subject), <span class="at">data =</span> sleepstudy)</span>
<span id="cb278-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb278-2" tabindex="-1"></a></span>
<span id="cb278-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb278-3" tabindex="-1"></a><span class="fu">summary</span>(randIntMod)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (1 | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1786.5
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2257 -0.5529  0.0109  0.5188  4.2506 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1378.2   37.12   
##  Residual              960.5   30.99   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 251.4051     9.7467   25.79
## Days         10.4673     0.8042   13.02
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.371</code></pre>
<p>What we see above is that <span class="math inline">\(\tau_{00}\)</span> which is the only variance component at level 2 (the variance of the <span class="math inline">\(r_{0i}\)</span>’s) is 1378.2. That’s a large number because we’re measuring reaction time in milliseconds. The <code>Std.Dev.</code> column shows us that on average, the participants’ reaction time differs from the common intercept <span class="math inline">\(\beta_{00} = 251.41\)</span> by about 37.12 milliseconds.</p>
</div>
<div id="model-comparison-and-testing" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Model comparison and testing<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#model-comparison-and-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Remember, significance testing with multilevel models can be tricky. This data set is actually balanced, so we could use an ANOVA based test, but let’s explore the options we’ve reviewed</p>
<div id="option-1-using-confidence-intervals" class="section level3 hasAnchor" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Option 1: using confidence intervals<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#option-1-using-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Since we might suspect that we need the linear growth term, testing it’s “significance” might be most easily accomplished with the bootstrapping method:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb280-1" tabindex="-1"></a><span class="fu">confint</span>(randIntMod, <span class="at">method =</span> <span class="st">&quot;boot&quot;</span>)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## .sig01       24.242737  48.89273
## .sigma       27.722382  34.27304
## (Intercept) 233.755861 268.33898
## Days          8.876771  11.96578</code></pre>
<p>So we see that a parametric bootstrap <span class="math inline">\(95\%\)</span> CI for the linear days effect is <span class="math inline">\((8.80, 12.03)\)</span></p>
<p>We could also use any number of the “fixes” in the <code>lmerTest</code> or <code>pbkrtest</code> packages to get a p-value</p>
<div id="random-slopes" class="section level4 hasAnchor" number="9.4.1.1">
<h4><span class="header-section-number">9.4.1.1</span> Random slopes<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#random-slopes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>More importantly, we need to determine whether to allow slopes to randomly vary. Again, it might be that we do so by design, but if we were building the model from the ground up, we could test whether <span class="math inline">\(\tau_{10} = 0\)</span> with a model comparison test.</p>
<p>First, we fit the random slopes model to compare with the previous one.</p>
<p>Changing the model to allow slopes to vary changes the equation for <span class="math inline">\(\pi_{1i}\)</span> to</p>
<p><span class="math display">\[
\pi_{1i} = \beta_{10} + r_{1i}
\]</span></p>
<p>The combined model thus is:</p>
<p><span class="math display">\[
Y_{ti} = \beta_{00} + \beta_{10}(a_{ti}-L) + r_{0i} +r_{1i}(a_{ti}-L) +e_{ij}
\]</span></p>
<p>This means that we’re adding 2 new variance components the <span class="math inline">\(\text{Var}(r_{1i}) = \tau_{10}\)</span> and the <span class="math inline">\(\text{Cov}(r_{0i},r_{1i}) = \tau_{01}\)</span></p>
</div>
</div>
<div id="tests" class="section level3 hasAnchor" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Tests<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As an exercise, let’s see how things differ between the ordinary likelihood ratio test and a bootstrap version</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb282-1" tabindex="-1"></a>randSlope <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Reaction <span class="sc">~</span> Days <span class="sc">+</span> (Days<span class="sc">|</span>Subject), sleepstudy)</span>
<span id="cb282-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb282-2" tabindex="-1"></a></span>
<span id="cb282-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb282-3" tabindex="-1"></a><span class="co"># ordinary LRT</span></span>
<span id="cb282-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb282-4" tabindex="-1"></a><span class="fu">anova</span>(randSlope, randIntMod, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## Data: sleepstudy
## Models:
## randIntMod: Reaction ~ Days + (1 | Subject)
## randSlope: Reaction ~ Days + (Days | Subject)
##            npar    AIC    BIC  logLik -2*log(L)  Chisq Df Pr(&gt;Chisq)    
## randIntMod    4 1794.5 1807.2 -893.23    1786.5                         
## randSlope     6 1755.6 1774.8 -871.81    1743.6 42.837  2   4.99e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>With the ordinary LRT we see that the random slopes model has a lower AIC, BIC and deviance. The change in deviance is significant with a <span class="math inline">\(\chi^{2}(2) = 42.14, p &lt; .001\)</span>. These results favor the model with both random intercepts and random slopes.</p>
<p>Now let’s see if this holds up with a bootstrap test</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb284-1" tabindex="-1"></a>pbkrtest<span class="sc">::</span><span class="fu">PBmodcomp</span>(randSlope, randIntMod)</span></code></pre></div>
<pre><code>## Bootstrap test; time: 13.96 sec; samples: 1000; extremes: 0;
## large : Reaction ~ Days + (Days | Subject)
##          stat df   p.value    
## LRT    42.139  2 7.072e-10 ***
## PBtest 42.139     0.000999 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Now let’s see the estimates for <span class="math inline">\(\tau_{10}\)</span> and <span class="math inline">\(\tau_{01}\)</span></p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb286-1" tabindex="-1"></a><span class="fu">summary</span>(randSlope)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1743.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9536 -0.4634  0.0231  0.4634  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 612.10   24.741       
##           Days         35.07    5.922   0.07
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.825  36.838
## Days          10.467      1.546   6.771
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138</code></pre>
<p>The results show us that <span class="math inline">\(\tau_{10} = 35.07\)</span> and that the correlation is small. We will keep this random intercepts and slopes model and add a quadratic predictor for <code>Days.</code></p>
</div>
</div>
<div id="quadratic-model-with-lmer" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Quadratic model with lmer<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#quadratic-model-with-lmer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Note, in this model, we are only going to model the <em>linear slope</em> as random. We’ll keep the quadratic term fixed for now.</p>
<p>The combined equation therefore just adds a fixed effect and looks like this:</p>
<p><span class="math display">\[
Y_{ti} = \beta_{00} + \beta_{10}(a_{ti}-L) + \beta_{20}(a_{ti}-L)^{2}+ r_{0i} +r_{1i}(a_{ti}-L) +e_{ij}
\]</span></p>
<p>Let’s fit the model and compare it to the random slopes model with only a linear predictor</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-1" tabindex="-1"></a>sleepstudy<span class="sc">$</span>Daysquared <span class="ot">&lt;-</span> sleepstudy<span class="sc">$</span>Days<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb288-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-2" tabindex="-1"></a></span>
<span id="cb288-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-3" tabindex="-1"></a><span class="co"># quadmod2 &lt;- lmerTest::lmer(Reaction ~ Days + Daysquared + (Days| Subject), data = sleepstudy)</span></span>
<span id="cb288-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-4" tabindex="-1"></a></span>
<span id="cb288-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-5" tabindex="-1"></a>quadmod <span class="ot">&lt;-</span><span class="fu">lmer</span>(Reaction <span class="sc">~</span> Days <span class="sc">+</span> <span class="fu">I</span>(Days<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> (Days<span class="sc">|</span> Subject), <span class="at">data =</span> sleepstudy)</span>
<span id="cb288-6"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-6" tabindex="-1"></a></span>
<span id="cb288-7"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb288-7" tabindex="-1"></a><span class="fu">anova</span>(randSlope, quadmod)</span></code></pre></div>
<pre><code>## Data: sleepstudy
## Models:
## randSlope: Reaction ~ Days + (Days | Subject)
## quadmod: Reaction ~ Days + I(Days^2) + (Days | Subject)
##           npar    AIC    BIC  logLik -2*log(L)  Chisq Df Pr(&gt;Chisq)
## randSlope    6 1763.9 1783.1 -875.97    1751.9                     
## quadmod      7 1764.3 1786.6 -875.14    1750.3 1.6577  1     0.1979</code></pre>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb290-1" tabindex="-1"></a>pbkrtest<span class="sc">::</span><span class="fu">PBmodcomp</span>(quadmod, randSlope)</span></code></pre></div>
<pre><code>## Bootstrap test; time: 15.86 sec; samples: 1000; extremes: 215;
## large : Reaction ~ Days + I(Days^2) + (Days | Subject)
##          stat df p.value
## LRT    1.6577  1  0.1979
## PBtest 1.6577     0.2158</code></pre>
<p>We can also use the bootstrap confidence interval approach:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb292-1" tabindex="-1"></a><span class="fu">confint</span>(quadmod, <span class="at">method =</span> <span class="st">&quot;boot&quot;</span>)</span></code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## .sig01       10.7899579  35.4070753
## .sig02       -0.5021857   0.9031948
## .sig03        3.4497884   8.2301896
## .sigma       22.8124498  28.5945090
## (Intercept) 240.5315090 271.2280011
## Days          1.8960615  12.3040694
## I(Days^2)    -0.1573193   0.8086611</code></pre>
<p>So as we can see, adding the quadratic term does not yield a better fitting model.</p>
<p>We can also see this within the model:</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb294-1" tabindex="-1"></a><span class="fu">summary</span>(quadmod)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + I(Days^2) + (Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1742.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.0093 -0.4489  0.0422  0.5036  5.2702 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 613.12   24.761       
##           Days         35.11    5.925   0.06
##  Residual             651.97   25.534       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 255.4494     7.5135  33.999
## Days          7.4341     2.8189   2.637
## I(Days^2)     0.3370     0.2619   1.287
## 
## Correlation of Fixed Effects:
##           (Intr) Days  
## Days      -0.418       
## I(Days^2)  0.418 -0.836</code></pre>
<p>So the tests converge, and we don’t seem to have evidence for a quadratic term.</p>
<div id="a-note-on-quadratic-terms" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> A note on quadratic terms<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#a-note-on-quadratic-terms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Technically, there will be a high degree of collinearity between the linear and quadratic terms like those above. To avoid this, we can make orthogonal polynomials – linear and squared variables that are not correlated – using the <code>poly()</code> function.</p>
<p>What is cumbersome about orthogonal polynomial variables like this s is that they’re on weird scales as you can see above. So now the intercept will be meaningless, but we can still test if a quadratic predictor reduces deviance.</p>
<p>We’ll add these to the dataframe to show you how this works</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb296-1" tabindex="-1"></a>sleepstudy2 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(sleepstudy, <span class="fu">poly</span>(sleepstudy<span class="sc">$</span>Days, <span class="dv">2</span>))</span>
<span id="cb296-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb296-2" tabindex="-1"></a></span>
<span id="cb296-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb296-3" tabindex="-1"></a><span class="fu">colnames</span>(sleepstudy2)[<span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;linear&quot;</span>,<span class="st">&quot;quad&quot;</span>)</span>
<span id="cb296-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb296-4" tabindex="-1"></a></span>
<span id="cb296-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb296-5" tabindex="-1"></a><span class="fu">head</span>(sleepstudy2)</span></code></pre></div>
<pre><code>##   Reaction Days Subject linear        quad           2
## 1 249.5600    0     308      0 -0.11677484  0.12309149
## 2 258.7047    1     308      1 -0.09082488  0.04103050
## 3 250.8006    2     308      4 -0.06487491 -0.02051525
## 4 321.4398    3     308      9 -0.03892495 -0.06154575
## 5 356.8519    4     308     16 -0.01297498 -0.08206099
## 6 414.6901    5     308     25  0.01297498 -0.08206099</code></pre>
<p>Now let’s see what the effect is on the model</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-1" tabindex="-1"></a><span class="do">## refit random slopes</span></span>
<span id="cb298-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-2" tabindex="-1"></a>randSlope2 <span class="ot">&lt;-</span> lmerTest<span class="sc">::</span><span class="fu">lmer</span>(Reaction <span class="sc">~</span> Days <span class="sc">+</span> (Days<span class="sc">|</span>Subject), sleepstudy2)</span>
<span id="cb298-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-3" tabindex="-1"></a></span>
<span id="cb298-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-4" tabindex="-1"></a></span>
<span id="cb298-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-5" tabindex="-1"></a>quadmod2 <span class="ot">&lt;-</span> lmerTest<span class="sc">::</span><span class="fu">lmer</span>(Reaction <span class="sc">~</span> linear <span class="sc">+</span> quad <span class="sc">+</span> (linear<span class="sc">|</span> Subject), <span class="at">data =</span> sleepstudy2)</span>
<span id="cb298-6"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb298-6" tabindex="-1"></a><span class="fu">anova</span>(randSlope2, quadmod2)</span></code></pre></div>
<pre><code>## Data: sleepstudy2
## Models:
## randSlope2: Reaction ~ Days + (Days | Subject)
## quadmod2: Reaction ~ linear + quad + (linear | Subject)
##            npar    AIC    BIC  logLik -2*log(L) Chisq Df Pr(&gt;Chisq)
## randSlope2    6 1763.9 1783.1 -875.97    1751.9                    
## quadmod2      7 1768.9 1791.3 -877.45    1754.9     0  1          1</code></pre>
<p>The deviance test generally agrees with the one for the “non-orthogonal” predictors, but the numbers are different.</p>
<p>Within the summary, we’ll see that the new variables yield strange intercepts and variance components (why?)</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb300-1" tabindex="-1"></a><span class="fu">summary</span>(quadmod2)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: Reaction ~ linear + quad + (linear | Subject)
##    Data: sleepstudy2
## 
## REML criterion at convergence: 1740.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.7016 -0.4715 -0.0002  0.5066  5.3026 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 763.3403 27.6286      
##           linear        0.3764  0.6135  0.35
##  Residual             671.2606 25.9087      
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept) 288.9028    10.1738  63.3704  28.397  &lt; 2e-16 ***
## linear        0.3370     0.3026 119.7398   1.114  0.26755    
## quad        286.4777    95.7439 143.0131   2.992  0.00326 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##        (Intr) linear
## linear -0.547       
## quad    0.717 -0.846
## optimizer (nloptwrap) convergence code: 0 (OK)
## Model failed to converge with max|grad| = 0.0055591 (tol = 0.002, component 1)</code></pre>
<p>So if you’re interested in making substantive statements about the intercept and the variance components, use of orthogonal polynomials is somewhat awkward.</p>
</div>
</div>
<div id="summary-of-the-sleepstudy-analysis" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Summary of the sleepstudy analysis<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#summary-of-the-sleepstudy-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What we have just done is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>We fit models with a linear effect of Days on Reaction Time and asked whether there is significant random variation in both intercepts and slopes. This was done by assessing the reduction in deviance in a model with random linear slopes and intercepts compared to the random intercept-only linear growth model. The Deviance test was significant indicating that the model with random intercepts and slopes, and a covariance term between them is to be preferred.</p></li>
<li><p>We added a quadratic term to our model and again used a deviance test to see if the fit was further improved. We did not find justification for keeping the quadratic growth term (since the test was not significant, and the other fit indices favored the linear model).</p></li>
</ol>
<p>Below we have the same data as Figure 1 above, but now we’ve added the within-subject regression lines (approximated). As we can see, the linear growth model is a pretty good model for these data. The fact that the dark grey “loess” lines aren’t much different with the graphed lines illustrates why the quadratic term doesn’t add much.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-1" tabindex="-1"></a><span class="fu">xyplot</span>(Reaction <span class="sc">~</span> Days <span class="sc">|</span> Subject, <span class="at">data =</span> sleepstudy,</span>
<span id="cb302-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-2" tabindex="-1"></a>       <span class="at">panel=</span><span class="cf">function</span>(x, y){</span>
<span id="cb302-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-3" tabindex="-1"></a>        <span class="fu">panel.points</span>(x, y)</span>
<span id="cb302-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-4" tabindex="-1"></a>        <span class="fu">panel.lmline</span>(x, y, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb302-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-5" tabindex="-1"></a>        <span class="fu">panel.loess</span>(x, y, <span class="at">span=</span><span class="dv">1</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb302-6"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb302-6" tabindex="-1"></a>    })</span></code></pre></div>
<p><img src="_main_files/figure-html/c309-1.png" width="672" /></p>
<p>There are no person-level predictors in the sleepstudy dataset, but if there were, we could now ask whether those person-level predictors affect the intercept and/or the slope in the linear growth model. We will cover that next week.</p>
</div>
<div id="preview-of-the-blackmore-data-used-for-assignment-7b" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Preview of the Blackmore data used for Assignment 7b<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#preview-of-the-blackmore-data-used-for-assignment-7b" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>From Fox and Weisberg:</p>
<blockquote>
<p>Davis, Blackmore, Katzman, and Fox (2005) study on the exercise <em>histories</em> of a patient group of 138 teenage girls hospitalized for eating disorders and of 93 comparable control subjects. At the time of data collection, the girls and their parents were interviewed, and based on the interviews, an estimate of the average number of hours per week of exercise was constructed at each subject’s current age, which varied from girl to girl, and in most cases at 2-year intervals in the past, starting at age 8. Thus, the response variable, exercise, was measured at several different ages for each girl, with most subjects measured four or five times and a few measured two or three times. We are interested in modeling change in exercise with age and particularly in examining the potential difference in typical exercise trajectories between patients and control subjects. The data for the study are in the data frame Blackmore (named after the researcher who collected the data) in the carData package:</p>
</blockquote>
<pre><code>## 945 x 4 data.frame (937 rows omitted)
##     subject   age exercise   group
##         [f]   [n]      [n]     [f]
## 1       100  8.00     2.71 patient
## 2       100 10.00     1.94 patient
## 3       100 12.00     2.36 patient
## 4       100 14.00     1.54 patient
## 5       100 15.92     8.63 patient
## . . .                                  
## 770     286 12.00     0.35 control
## 771     286 14.00     0.40 control
## 772     286 17.00     0.29 control</code></pre>
<pre><code>##          agegroup
## group     [8,10] (10,12] (12,14] (14,17.9]
##   control    185      60      58        56
##   patient    275     118      83       110</code></pre>
<p>Let’s visualize these data too. Since there are so many participants. We’ll use the <code>sample()</code> function. I’m also using <code>set.seed</code></p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb305-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-2" tabindex="-1"></a></span>
<span id="cb305-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-3" tabindex="-1"></a>sampBlackmore <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">unique</span>(Blackmore<span class="sc">$</span>subject), <span class="dv">20</span>)</span>
<span id="cb305-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-4" tabindex="-1"></a></span>
<span id="cb305-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-5" tabindex="-1"></a>sampd <span class="ot">&lt;-</span> Blackmore[<span class="fu">is.element</span>(Blackmore<span class="sc">$</span>subject, sampBlackmore), ]</span>
<span id="cb305-6"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-6" tabindex="-1"></a></span>
<span id="cb305-7"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-7" tabindex="-1"></a><span class="fu">xyplot</span>(exercise <span class="sc">~</span> age <span class="sc">|</span> subject, <span class="at">data =</span> sampd,</span>
<span id="cb305-8"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-8" tabindex="-1"></a>       <span class="at">panel=</span><span class="cf">function</span>(x, y){</span>
<span id="cb305-9"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-9" tabindex="-1"></a>        <span class="fu">panel.points</span>(x, y)</span>
<span id="cb305-10"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-10" tabindex="-1"></a>        <span class="fu">panel.lmline</span>(x, y, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb305-11"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb305-11" tabindex="-1"></a>    })</span></code></pre></div>
<p><img src="_main_files/figure-html/blackmore209-1.png" width="672" /></p>
<p>These data are much more typical of longitudinal studies, even though they’re technically event histories. There are differing numbers of observations across participants, and the observations are not equally spaced.</p>
<p>As we’ll see next week, the control group also has differing numbers across the ages. All of this is no good for old-school repeated measures analysis but it is A-OK for MLM.</p>
<div id="a-note-on-the-age-variable-in-blackmore" class="section level3 hasAnchor" number="9.7.1">
<h3><span class="header-section-number">9.7.1</span> A note on the age variable in Blackmore<a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#a-note-on-the-age-variable-in-blackmore" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For this week’s assignment, you will need to create 2 new age variables, both centered at different points. This chunk illustrates how to do that:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-1" tabindex="-1"></a><span class="co"># intercept is the end of the study (current time)</span></span>
<span id="cb306-2"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-2" tabindex="-1"></a>Blackmore<span class="sc">$</span>endcentered <span class="ot">&lt;-</span> Blackmore<span class="sc">$</span>age <span class="sc">-</span> <span class="fu">max</span>(Blackmore<span class="sc">$</span>age)</span>
<span id="cb306-3"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-3" tabindex="-1"></a></span>
<span id="cb306-4"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-4" tabindex="-1"></a><span class="co"># intercept is the average age for the group</span></span>
<span id="cb306-5"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-5" tabindex="-1"></a>Blackmore<span class="sc">$</span>midcentered <span class="ot">&lt;-</span> Blackmore<span class="sc">$</span>age <span class="sc">-</span> <span class="fu">mean</span>(Blackmore<span class="sc">$</span>age)</span>
<span id="cb306-6"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-6" tabindex="-1"></a></span>
<span id="cb306-7"><a href="using-lme4-to-fit-mlm-to-longitudinal-data.html#cb306-7" tabindex="-1"></a><span class="fu">head</span>(Blackmore)</span></code></pre></div>
<pre><code>##   subject   age exercise   group  agegroup endcentered midcentered
## 1     100  8.00     2.71 patient    [8,10]       -9.92  -3.4416614
## 2     100 10.00     1.94 patient    [8,10]       -7.92  -1.4416614
## 3     100 12.00     2.36 patient   (10,12]       -5.92   0.5583386
## 4     100 14.00     1.54 patient   (12,14]       -3.92   2.5583386
## 5     100 15.92     8.63 patient (14,17.9]       -2.00   4.4783386
## 6     101  8.00     0.14 patient    [8,10]       -9.92  -3.4416614</code></pre>
<p>As you can see above, the <code>endcentered</code> variable has values close to zero when the child is older, and the <code>midcentered</code> variable will have values close to zero when the child is at the mean age of approximately 11.5 years. Use both of these variables in your assignment.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="more-on-hierarchical-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="longitudinal-models-with-upper-level-predictors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
